<?xml version="1.0" encoding="utf-8"?><?xml-stylesheet type="text/xsl" href="https://blog.cizai.io/rss.xsl"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/">
  <channel>
    <atom:link href="https://blog.cizai.io/rss.xml" rel="self" type="application/rss+xml"/>
    <title>此在笔记</title>
    <link>https://blog.cizai.io/</link>
    <description>开源工具、效率方法、心理学探索的自我提升笔记 ，记录并输出一切能让自己提升的知识。</description>
    <language>zh-CN</language>
    <pubDate>Tue, 04 Jun 2024 06:57:30 GMT</pubDate>
    <lastBuildDate>Tue, 04 Jun 2024 06:57:30 GMT</lastBuildDate>
    <generator>@vuepress/plugin-feed</generator>
    <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
    <category>工具</category>
    <category>站点收藏</category>
    <category>每日悦读</category>
    <category>数据库</category>
    <item>
      <title>反向代理应用frp</title>
      <link>https://blog.cizai.io/%E7%BC%96%E7%A8%8B/%E5%B7%A5%E5%85%B7/frp.html</link>
      <guid>https://blog.cizai.io/%E7%BC%96%E7%A8%8B/%E5%B7%A5%E5%85%B7/frp.html</guid>
      <source url="https://blog.cizai.io/rss.xml">反向代理应用frp</source>
      <description>反向代理应用frp 拥有公网IP的情况下，可以使用frp来实现内网机器的端口映射和访问。 安装 linux mac 通过tcp访问内网机器端口 通过自定义域名访问内网的 Web 服务 代理上网 （无法打开被强的网站）</description>
      <category>工具</category>
      <pubDate>Tue, 02 Apr 2024 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[
<p>拥有公网IP的情况下，可以使用frp来实现内网机器的端口映射和访问。</p>
<h2>安装</h2>
<p>linux</p>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>wget https://github.com/fatedier/frp/releases/download/v0.57.0/frp_0.57.0_linux_amd64.tar.gz
tar -zxvf frp_0.57.0_linux_amd64.tar.gz
</code></pre></div><p>mac</p>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>wget https://github.com/fatedier/frp/releases/download/v0.57.0/frp_0.57.0_darwin_arm64.tar.gz
tar -zxvf frp_0.57.0_darwin_arm64.tar.gz
</code></pre></div><h2>通过tcp访问内网机器端口</h2>
<div class="language-bash" data-ext="sh" data-title="sh"><pre class="language-bash"><code>公网服务器上编辑frps.toml
bindPort <span class="token operator">=</span> <span class="token number">7000</span>

内网服务器上编辑frpc.toml
serverAddr <span class="token operator">=</span> <span class="token string">"x.x.x.x"</span> <span class="token comment"># 公网服务器的 IP 地址</span>
serverPort <span class="token operator">=</span> <span class="token number">7000</span>

<span class="token punctuation">[</span><span class="token punctuation">[</span>proxies<span class="token punctuation">]</span><span class="token punctuation">]</span>
name <span class="token operator">=</span> <span class="token string">"ssh"</span>
<span class="token builtin class-name">type</span> <span class="token operator">=</span> <span class="token string">"tcp"</span>
localIP <span class="token operator">=</span> <span class="token string">"127.0.0.1"</span>
localPort <span class="token operator">=</span> <span class="token number">22</span>
remotePort <span class="token operator">=</span> <span class="token number">2222</span>

<span class="token punctuation">[</span><span class="token punctuation">[</span>proxies<span class="token punctuation">]</span><span class="token punctuation">]</span>
name <span class="token operator">=</span> <span class="token string">"web"</span>
<span class="token builtin class-name">type</span> <span class="token operator">=</span> <span class="token string">"tcp"</span>
localIP <span class="token operator">=</span> <span class="token string">"127.0.0.1"</span>
localPort <span class="token operator">=</span> <span class="token number">5500</span>
remotePort <span class="token operator">=</span> <span class="token number">5555</span>

<span class="token comment"># localIP 和 localPort 配置为需要从公网访问的内网服务的地址和端口。</span>
<span class="token comment"># remotePort 表示在 frp 服务端监听的端口，访问此端口的流量将被转发到本地服务的相应端口。</span>

启动 frps 和 frpc
./frps <span class="token parameter variable">-c</span> frps.toml
./frpc <span class="token parameter variable">-c</span> frpc.toml

使用以下命令通过 SSH 访问内网机器，假设用户名为 test：
<span class="token function">ssh</span> <span class="token parameter variable">-o</span> <span class="token assign-left variable">Port</span><span class="token operator">=</span><span class="token number">2222</span> test@x.x.x.x

使用以下命令通过 Web 服务访问内网机器，假设服务运行在 <span class="token number">5555</span> 端口：
<span class="token function">curl</span> http://x.x.x.x:5555

</code></pre></div><h2>通过自定义域名访问内网的 Web 服务</h2>
<div class="language-bash" data-ext="sh" data-title="sh"><pre class="language-bash"><code>公网服务器上编辑frps.toml
bindPort <span class="token operator">=</span> <span class="token number">7000</span>

内网服务器上编辑frpc.toml
serverAddr <span class="token operator">=</span> <span class="token string">"x.x.x.x"</span> <span class="token comment"># 公网服务器的 IP 地址</span>
serverPort <span class="token operator">=</span> <span class="token number">7000</span>

<span class="token punctuation">[</span><span class="token punctuation">[</span>proxies<span class="token punctuation">]</span><span class="token punctuation">]</span>
name <span class="token operator">=</span> <span class="token string">"web"</span>
<span class="token builtin class-name">type</span> <span class="token operator">=</span> <span class="token string">"http"</span>
localIP <span class="token operator">=</span> <span class="token string">"127.0.0.1"</span>
localPort <span class="token operator">=</span> <span class="token number">80</span>
customDomains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"www.yourdomain.com"</span><span class="token punctuation">]</span>

启动 frps 和 frpc
./frps <span class="token parameter variable">-c</span> frps.toml
./frpc <span class="token parameter variable">-c</span> frpc.toml

将 www.yourdomain.com的域名 A 记录解析到服务器的 IP 地址 x.x.x.x

访问 http://www.yourdomain.com 即可访问内网的 Web 服务
</code></pre></div><h2>代理上网 （无法打开被强的网站）</h2>
<div class="language-bash" data-ext="sh" data-title="sh"><pre class="language-bash"><code>公网服务器上编辑frps.toml
bindPort <span class="token operator">=</span> <span class="token number">7000</span>

内网服务器上编辑frpc.toml
serverAddr <span class="token operator">=</span> <span class="token string">"x.x.x.x"</span> <span class="token comment"># 公网服务器的 IP 地址</span>
server_port <span class="token operator">=</span> <span class="token number">7000</span> 

<span class="token punctuation">[</span><span class="token punctuation">[</span>proxies<span class="token punctuation">]</span><span class="token punctuation">]</span>
name <span class="token operator">=</span> <span class="token string">"plugin_http_proxy"</span>
<span class="token builtin class-name">type</span> <span class="token operator">=</span> <span class="token string">"tcp"</span>
remotePort <span class="token operator">=</span> <span class="token number">6004</span>
<span class="token punctuation">[</span>proxies.plugin<span class="token punctuation">]</span>
<span class="token builtin class-name">type</span> <span class="token operator">=</span> <span class="token string">"http_proxy"</span>
httpUser <span class="token operator">=</span> <span class="token string">"abc"</span>
httpPassword <span class="token operator">=</span> <span class="token string">"abc"</span>

<span class="token punctuation">[</span><span class="token punctuation">[</span>proxies<span class="token punctuation">]</span><span class="token punctuation">]</span>
name <span class="token operator">=</span> <span class="token string">"plugin_socks5"</span>
<span class="token builtin class-name">type</span> <span class="token operator">=</span> <span class="token string">"tcp"</span>
remotePort <span class="token operator">=</span> <span class="token number">6005</span>
<span class="token punctuation">[</span>proxies.plugin<span class="token punctuation">]</span>
<span class="token builtin class-name">type</span> <span class="token operator">=</span> <span class="token string">"socks5"</span>
username <span class="token operator">=</span> <span class="token string">"abc"</span>
password <span class="token operator">=</span> <span class="token string">"abc"</span>

启动 frps 和 frpc
./frps <span class="token parameter variable">-c</span> frps.toml
./frpc <span class="token parameter variable">-c</span> frpc.toml

<span class="token comment"># 设置代理</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">http_proxy</span><span class="token operator">=</span>http://abc:abc@x.x.x.x:6004
<span class="token builtin class-name">export</span> <span class="token assign-left variable">https_proxy</span><span class="token operator">=</span><span class="token variable">$http_proxy</span>
<span class="token builtin class-name">export</span> <span class="token assign-left variable">all_proxy</span><span class="token operator">=</span>socks5://abc:abc@x.x.x.x:6005
<span class="token builtin class-name">export</span> <span class="token assign-left variable">no_proxy</span><span class="token operator">=</span><span class="token string">"localhost,127.0.0.1,x.x.x.x"</span>

<span class="token function">wget</span> https://www.baidu.com 可以代理访问
<span class="token function">wget</span> https://www.google.com 无法打开被强的网站，因为没有伪装加密

</code></pre></div>]]></content:encoded>
    </item>
    <item>
      <title>内网穿透</title>
      <link>https://blog.cizai.io/%E7%BC%96%E7%A8%8B/%E5%B7%A5%E5%85%B7/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F.html</link>
      <guid>https://blog.cizai.io/%E7%BC%96%E7%A8%8B/%E5%B7%A5%E5%85%B7/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F.html</guid>
      <source url="https://blog.cizai.io/rss.xml">内网穿透</source>
      <description>内网穿透 serveo ssh -R 80:localhost:3000 serveo.net ngrok 启动时需要验证 ngrok http 3000 localtunnel 访问时需要验证 cloudflare tunnel vscode 端口转发 WireGuard frp https://github.com/fatedier/frp 免费域...</description>
      <category>工具</category>
      <pubDate>Tue, 02 Apr 2024 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[
<h2>serveo</h2>
<p>ssh -R 80:localhost:3000 serveo.net</p>
<h2>ngrok</h2>
<h3>启动时需要验证</h3>
<p>ngrok http 3000</p>
<h2>localtunnel</h2>
<h3>访问时需要验证</h3>
<div class="language-bash" data-ext="sh" data-title="sh"><pre class="language-bash"><code>快速开始
npx localtunnel <span class="token parameter variable">--subdomain</span> cizai <span class="token parameter variable">--port</span> <span class="token number">3000</span>

全局安装
<span class="token function">npm</span> <span class="token function">install</span> <span class="token parameter variable">-g</span> localtunnel
lt <span class="token parameter variable">--port</span> <span class="token number">3000</span>

自定义个性前缀
lt <span class="token parameter variable">--subdomain</span> <span class="token operator">&lt;</span>个性前缀<span class="token operator">&gt;</span> <span class="token parameter variable">--port</span> <span class="token operator">&lt;</span>要映射的端口<span class="token operator">&gt;</span>

<span class="token comment"># 获取访问密码</span>
<span class="token function">wget</span> <span class="token parameter variable">-q</span> <span class="token parameter variable">-O</span> - https://loca.lt/mytunnelpassword

</code></pre></div><h2>cloudflare tunnel</h2>
<div class="language-bash" data-ext="sh" data-title="sh"><pre class="language-bash"><code>
https://bra.live/setup-home-server-with-cloudflare-tunnel/

</code></pre></div><h2>vscode 端口转发</h2>
<h2>WireGuard</h2>
<h2>frp</h2>
<p>https://github.com/fatedier/frp</p>
<h2>免费域名</h2>
<p>https://iyideng.net/welfare/best-free-domain-name-registration-platform.html</p>
]]></content:encoded>
    </item>
    <item>
      <title>关于本站</title>
      <link>https://blog.cizai.io/%E5%85%B3%E4%BA%8E%E6%9C%AC%E7%AB%99.html</link>
      <guid>https://blog.cizai.io/%E5%85%B3%E4%BA%8E%E6%9C%AC%E7%AB%99.html</guid>
      <source url="https://blog.cizai.io/rss.xml">关于本站</source>
      <description>关于本站 一个全栈开发者，从事大数据开发。 本站桌面端安装包，支持windows，linux，mac。下载地址 Loading...</description>
      <pubDate>Sun, 17 Mar 2024 17:45:45 GMT</pubDate>
      <content:encoded><![CDATA[
<p>一个全栈开发者，从事大数据开发。</p>
<p>本站桌面端安装包，支持windows，linux，mac。<a href="https://file.cizai.io/wooapp.json" target="_blank" rel="noopener noreferrer">下载地址</a></p>
<div id="dynamic-content">
  <p>Loading...</p>
</div>
]]></content:encoded>
      <enclosure url="https://blog.cizai.io/assets/images/cover3.jpg" type="image/jpeg"/>
    </item>
    <item>
      <title>站点收藏</title>
      <link>https://blog.cizai.io/%E7%AB%99%E7%82%B9%E6%94%B6%E8%97%8F.html</link>
      <guid>https://blog.cizai.io/%E7%AB%99%E7%82%B9%E6%94%B6%E8%97%8F.html</guid>
      <source url="https://blog.cizai.io/rss.xml">站点收藏</source>
      <description>站点收藏 白噪音 独立博客列表</description>
      <category>站点收藏</category>
      <pubDate>Sat, 01 Jan 2022 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[
<h2>白噪音</h2>
<p>| 简介   | 网址                      |
| :</p>
]]></content:encoded>
    </item>
    <item>
      <title>订阅说明</title>
      <link>https://blog.cizai.io/%E6%AF%8F%E6%97%A5%E6%82%A6%E8%AF%BB/</link>
      <guid>https://blog.cizai.io/%E6%AF%8F%E6%97%A5%E6%82%A6%E8%AF%BB/</guid>
      <source url="https://blog.cizai.io/rss.xml">订阅说明</source>
      <description>订阅说明 实现原理 使用ttrss.py启动订阅服务接口，使用rsshub订阅插件，将Tiny Tiny RSS地址改为订阅接口地址，即可直接订阅网站，存入rss.csv。 定时执行write2csv.py，抓取网络上的订阅地址，存入rss.csv。 定时执行write2md.py，读取rss.csv，获取今日新增文章，写入md文档，提交git，自动显...</description>
      <category>每日悦读</category>
      <pubDate>Thu, 15 Jun 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[
<h2>实现原理</h2>
<p>使用ttrss.py启动订阅服务接口，使用rsshub订阅插件，将Tiny Tiny RSS地址改为订阅接口地址，即可直接订阅网站，存入rss.csv。</p>
<p>定时执行write2csv.py<span></span>，抓取网络上的订阅地址，存入rss.csv。</p>
<p>定时执行write2md.py<span></span>，读取rss.csv，获取今日新增文章，写入md文档，提交git，自动显示在每日悦读。</p>
<p>参考代码：
https://github.com/lijc210/lijc210.github.io/blob/main/write2md.py</p>
]]></content:encoded>
    </item>
    <item>
      <title>订阅说明</title>
      <link>https://blog.cizai.io/%E6%AF%8F%E6%97%A5%E6%82%A6%E8%AF%BB/%E8%AE%A2%E9%98%85%E8%AF%B4%E6%98%8E.html</link>
      <guid>https://blog.cizai.io/%E6%AF%8F%E6%97%A5%E6%82%A6%E8%AF%BB/%E8%AE%A2%E9%98%85%E8%AF%B4%E6%98%8E.html</guid>
      <source url="https://blog.cizai.io/rss.xml">订阅说明</source>
      <description>订阅说明 实现原理 使用ttrss.py启动订阅服务接口，使用rsshub订阅插件，将Tiny Tiny RSS地址改为订阅接口地址，即可直接订阅网站，存入rss.csv。 定时执行write2csv.py，抓取网络上的订阅地址，存入rss.csv。 定时执行write2md.py，读取rss.csv，获取今日新增文章，写入md文档，提交git，自动显...</description>
      <category>每日悦读</category>
      <pubDate>Thu, 15 Jun 2023 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[
<h2>实现原理</h2>
<p>使用ttrss.py启动订阅服务接口，使用rsshub订阅插件，将Tiny Tiny RSS地址改为订阅接口地址，即可直接订阅网站，存入rss.csv。</p>
<p>定时执行write2csv.py<span></span>，抓取网络上的订阅地址，存入rss.csv。</p>
<p>定时执行write2md.py<span></span>，读取rss.csv，获取今日新增文章，写入md文档，提交git，自动显示在每日悦读。</p>
<p>参考代码：
https://github.com/lijc210/lijc210.github.io/blob/main/write2md.py</p>
]]></content:encoded>
    </item>
    <item>
      <title>Impala</title>
      <link>https://blog.cizai.io/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E5%BA%93/Impala.html</link>
      <guid>https://blog.cizai.io/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E5%BA%93/Impala.html</guid>
      <source url="https://blog.cizai.io/rss.xml">Impala</source>
      <description>Impala Impala时间戳分组</description>
      <category>数据库</category>
      <pubDate>Sat, 01 Jan 2022 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[
<h2>Impala时间戳分组</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>select   
from_unixtime(cast(siyu_add_time/1000 as int) , 'yyyy-MM-dd') as sdate,
count(1),
count(if(second_id is null,1,null))
from users 
-- 2023-06-14 00:00:00
where siyu_add_time &gt; 1686672000000
group by from_unixtime(cast(siyu_add_time/1000 as int) , 'yyyy-MM-dd')
order by from_unixtime(cast(siyu_add_time/1000 as int) , 'yyyy-MM-dd') desc
</code></pre></div>]]></content:encoded>
    </item>
    <item>
      <title>clickhouse</title>
      <link>https://blog.cizai.io/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E5%BA%93/clickhouse.html</link>
      <guid>https://blog.cizai.io/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E5%BA%93/clickhouse.html</guid>
      <source url="https://blog.cizai.io/rss.xml">clickhouse</source>
      <description>clickhouse clickhouse 常用命令 clickhouse表引擎 clickhouse性能优化 数据类型 建表时能用数值型或日期时间型表示的字段，就不要用字符串——全String类型在以Hive为中心的数仓建设中常见，但CK环境不应受此影响。 虽然clickhouse底层将DateTime存储为时间戳Long类型，但不建议直接存储Lon...</description>
      <category>数据库</category>
      <pubDate>Sat, 01 Jan 2022 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[
<h2>clickhouse 常用命令</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>更新数据
ALTER table ads_sales_item_shop_di_replica ON CLUSTER ck_cluster1 update item_no='' where item_no is null;
ALTER table ads_sales_item_shop_di_replica ON CLUSTER ck_cluster1 update store_shop_code='' where store_shop_code is null;
ALTER table ads_sales_item_shop_di_replica ON CLUSTER ck_cluster1 update unify_goods_code='' where unify_goods_code is null;


重命名表
RENAME TABLE table_A TO table_A_bak, table_B TO table_B_bak;



查看所有表
select *
FROM system.tables t WHERE database ='ads' AND engine &lt;&gt;'Distributed' ORDER by total_rows DESC 


select *
FROM system.tables t WHERE database ='ads'
AND engine &lt;&gt;'Distributed'
and name not like '%del%'
and name not like '%20%'
ORDER by total_rows DESC



自动清理query_log，query_thread_log，trace_log

ALTER TABLE system.query_log on cluster ck_cluster1 MODIFY TTL event_date + INTERVAL 15 DAY

ALTER TABLE system.query_thread_log on cluster ck_cluster1 MODIFY TTL event_date + INTERVAL 15 DAY

ALTER TABLE system.trace_log on cluster ck_cluster1 MODIFY TTL event_date + INTERVAL 15 DAY

立即清理
alter table system.query_thread_log_0 drop partition '202105'
分区名可以用下语句查询
select * from system.parts p where table = '表名'

查看parts  
select * from system.parts  where table = 'abs_activity_item_info_day_replica'
select * from system.parts where active = 0
当前慢查询
SELECT * FROM system.processes limit 100

耗时大于60秒
kill query where elapsed &gt;= 60

clickhouse不能创建等执行操作时（每个节点都要执行）
select * from system.mutations where is_done = 0;
kill mutation ON CLUSTER ck_cluster1 
 where database='ads' and table='ads_jd_erp_sale_outstock_replica' 


进入zk清理任务
deleteall /clickhouse/distributed_ddl/query-0000011932
查询阻塞的任务
select * from system.distributed_ddl_queue where status != 'Finished'


查看表大小
SELECT
    table AS `表名`,
    sum(rows) AS `总行数`,
    formatReadableSize(sum(data_uncompressed_bytes)) AS `原始大小`,
    formatReadableSize(sum(data_compressed_bytes)) AS `压缩大小`,
    round((sum(data_compressed_bytes) / sum(data_uncompressed_bytes)) * 100, 0) AS `压缩率`
FROM system.parts
GROUP BY table
order by sum(data_compressed_bytes) desc


修改字段名
ALTER TABLE visits RENAME COLUMN webBrowser TO browser
分布式集群下用分布式DDL修改字段名
ALTER TABLE visits on cluster shipin_cluster RENAME COLUMN webBrowser TO browser


新增字段
 alter table ads_itemprice_sales_section_replica ON CLUSTER ck_cluster1 add column sort_mark Nullable(int)
 alter table ads_itemprice_sales_section ON CLUSTER ck_cluster1 add column sort_mark Nullable(int)
</code></pre></div><h2>clickhouse表引擎</h2>
<p>| 系列        | 引擎                         | 特点                                                                                                                                                                                                                                    | 场景                                                                                     |
|</p>
]]></content:encoded>
    </item>
    <item>
      <title>elasticsearch</title>
      <link>https://blog.cizai.io/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E5%BA%93/elasticsearch.html</link>
      <guid>https://blog.cizai.io/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E5%BA%93/elasticsearch.html</guid>
      <source url="https://blog.cizai.io/rss.xml">elasticsearch</source>
      <description>elasticsearch 查看集群状态，修复 记录慢日志，重启也生效 记录慢查询日志 批量按条件更新 搜索词分权重 统一更改刷新时间 优化性能 索引复制数据 暂时移除一个节点 搜索结果返回不一致问题 一、背景 这周在使用Elasticsearch搜索的时候遇到一个，对于同一个搜索请求，会出现top50返回结果和排序不一致的问题。那么为什么会出现这样的...</description>
      <category>数据库</category>
      <pubDate>Sat, 01 Jan 2022 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[
<h2>查看集群状态，修复</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>GET _cluster/allocation/explain?pretty

GET /_cluster/allocation/explain

get /_cluster/settings

PUT /_cluster/settings
{
  "transient": {
    "cluster.routing.allocation.enable": "none"
  }
}
#分片配置

PUT /_cluster/settings
{
  "transient": {
    "cluster.routing.allocation.enable": "all"
  }
}

#分片重新均衡分配

PUT /_cluster/settings
{
  "transient": {
    "cluster.routing.rebalance.enable": "all"
  }
}

# 设置副本数量
PUT /aabb/_settings
{
"number_of_replicas" : 2
}

get _cluster/health?level=indices


GET _cat/nodes?v&amp;h=ip,heap.current,heap.percent,heap.max,ram.max,disk.avail,node.role,m

curl http://localhost:9200/_cat/nodes?v&amp;h=ip,heap.current,heap.percent,heap.max,ram.max,disk.avail,node.role,m

get _cat/master

post /_cluster/reroute
{
  "commands": [
    {
      "allocate_empty_primary": {
        "index": "wap_yonghu_v1",
        "shard": 2,
        "node": "Ee6ubnnmT52LJchcw0P-pQ",
        "accept_data_loss": false
      }
    }
  ]
}


#数据丢失
post /_cluster/reroute
{
"commands": [
{
"allocate_empty_primary": {
"index": "aabb_v2",
"shard": 0,
"node": "Ee6ubnnmT52LJchcw0P-pQ",
"accept_data_loss": true
}
}
]
}

#数据不丢失
post /_cluster/reroute
{
"commands" : [ {
"allocate_stale_primary" : {
"index" : "aabb_v2",
"shard" :0,
"node" : "Ee6ubnnmT52LJchcw0P-pQ",
"accept_data_loss" : true
}
}]
}


POST /_cluster/reroute?retry_failed=true


手动迁移分片
POST /_cluster/reroute
{
  "commands": [
    {
      "move": {
        "index": "aabb_v1",
        "shard": 1,
        "from_node": "10.10.20.143",
        "to_node": "10.10.20.153"
      }
    }
  ]
}

</code></pre></div><h2>记录慢日志，重启也生效</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>PUT /_settings
{
"index.search.slowlog.level": "trace",            
"index.search.slowlog.threshold.query.warn": "10s",  
"index.search.slowlog.threshold.query.info": "5s",  
"index.search.slowlog.threshold.query.debug": "2s",  
"index.search.slowlog.threshold.query.trace": "500ms"
}
</code></pre></div><h2>记录慢查询日志</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>curl -XPUT 'http://localhost:9200/_all/_settings?preserve_existing=true' -d '{
  "index.indexing.slowlog.threshold.index.debug" : "500ms",
  "index.indexing.slowlog.threshold.index.info" : "2s",
  "index.indexing.slowlog.threshold.index.warn" : "5s",
  "index.search.slowlog.threshold.fetch.debug" : "500ms",
  "index.search.slowlog.threshold.fetch.info" : "2s",
  "index.search.slowlog.threshold.fetch.warn" : "5s",
  "index.search.slowlog.threshold.query.debug" : "500ms",
  "index.search.slowlog.threshold.query.info" : "2s",
  "index.search.slowlog.threshold.query.warn" : "5s"
}'
</code></pre></div><h2>批量按条件更新</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>POST pyspider/result/_update_by_query
{
  "script": {
    "inline": "ctx._source.result.company_list=0;"
  },
  "query": {
    "term": {
      "_id": {
        "value": "qichacha:ecde53ee4b22383478536ee7d976046b"
      }
    }
  }
}
</code></pre></div><h2>搜索词分权重</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>post aabb/v9_news/_search
{
"query": {
"bool": {
"must": {
"multi_match": {
"query": "温馨的客厅",
"fields": [
"title"
]
}
},
"should": [
{
"match": {
"title": {
"query": "客厅",
"boost": 4
}
}
},
{
"match": {
"title": {
"query": "温馨",
"boost": 2
}
}
}
]
}
},"_source":["title","create_time"]
,"size": 50
}
</code></pre></div><h2>统一更改刷新时间</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>curl -XPUT 'http://10.10.20.165:9200/_all/_settings?preserve_existing=true' -d '{
  "index.refresh_interval" : "15s"
}'
</code></pre></div><h2>优化性能</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>GET _nodes/hot_threads?pretty


PUT /aabb/_settings
{
    "index":{
        "refresh_interval":"30s",
        "translog":{
            "flush_threshold_size":"2048m",
            "sync_interval":"120s",
            "durability":"async"
        },
        "merge":{
            "policy.max_merge_at_once":5,
            "policy.max_merge_at_once_explicit":15,
            "policy.floor_segment":"1mb",
            "scheduler.max_thread_count":"1"
        }
    }
}


PUT /uc/_settings
{
    "index":{
        "refresh_interval":"-1"
        }
}
</code></pre></div><h2>索引复制数据</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>http://localhost:9200/_reindex
{
    "source":{
        "index":"old_index"
    },
    "dest":{
        "index":"new_index",
        "op_type":"create"
    }
}
http://localhost:9200/_reindex
{
    "source":{
        "index":"cut_word_data_v1"
    },
    "dest":{
        "index":"cut_word_data_v2",
        "op_type":"create"
    }
}
curl -l -H "Content-type: application/json" -d '{"source":{"index":"crm-address_v2"},"dest":{"index":"crm-address_v1","op_type":"create" }}'  http://localhost:9200/_reindex


curl -l -H "Content-type: application/json" -d '{"source":{"index":"aabb_v1"},"dest":{"index":"aabb_v2","op_type":"create" }}'  http://localhost:9200/_reindex


curl -l -H "Content-type: application/json" -d '{"source":{"index":"wap_anli_v2"},"dest":{"index":"wap_anli_v1","op_type":"create" }}'  http://localhost:9200/_reindex


curl -l -H "Content-type: application/json" -d '{"source":{"remote":{"host":"http://10.10.20.33:9200"},"index":"kn2_es_v1"},"dest":{"index":"kn2_es_v1","op_type":"create"}}'  http://localhost:9200/_reindex

curl -l -H "Content-type: application/json" -d '{"source":{"remote":{"host":"http://10.10.20.33:9200"},"index":"pyspider"},"dest":{"index":"pyspider_v1","op_type":"create"}}'  http://localhost:9200/_reindex


http://localhost:9200/_reindex
{
    "source":{
        "index":"kn2_es_v1"
    },
    "dest":{
        "index":"kn2_es_v2",
        "op_type":"create"
    }
}


远程复制：

POST _reindex
{
    "source":{
        "remote":{
            "host":"http://10.10.20.33:9200"
        },
        "index":"test1"
    },
    "dest":{
        "index":"test2",
        "op_type":"create"
    }
}
</code></pre></div><h2>暂时移除一个节点</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>
下线：
PUT _cluster/settings
{
"transient" : {
"cluster.routing.allocation.exclude._name" : "node-2"
}
}
注意 这个操作是transient集群重启后，这个设置会失效



上线
PUT _cluster/settings
{
"transient" : {
"cluster.routing.allocation.exclude._name" : ""
}
}
只要让_name匹配不到对用的node即可
</code></pre></div><h2>搜索结果返回不一致问题</h2>
<p>一、背景</p>
<p>这周在使用Elasticsearch搜索的时候遇到一个，对于同一个搜索请求，会出现top50返回结果和排序不一致的问题。那么为什么会出现这样的问题？
后来通过百度和google，发现这是因为Elastcisearch的分布式搜索特性导致。Elasticsearch在搜索时，会循环的选择主分片和其副本中的一个来计算和返回搜索结果，而由于主分片和副本中相关统计信息的不同，从而导致了同一个搜索串的评分的不一致，进而导致排序不一样。而造成这种主分片和副本统计信息不一致的具体原因，是因为文档删除时造成的，具体可以参考官方给出的解释：https://www.elastic.co/guide/en/elasticsearch/reference/current/consistent-scoring.html
二、解决办法
针对上述问题，Elasticsearch官方也给出了解决方案（https://www.elastic.co/guide/en/elasticsearch/guide/2.x/_search_options.html#_preference），即在搜索时设置preference特性。如下：
SearchRequestBuilder builder = client.prepareSearch(offLin.index)
.setTypes(offLin.type)
.setQuery(queryBuilder)
.setFetchSource(fetchFields, null)
.setSize(limit)
.setPreference("_primary_first");
那么preference可以取哪些值，每个值的含义是什么呢，可以参考下面解释：
（1）randomizeacross shards：随机选择分片或其副本查询数据，es的默认方式。
（2）_local：优先在本地节点上的分片查询数据然后再去其他节点上的分片查询，本地节点没有IO问题但有可能造成负载不均问题。
（3）_primary：搜索只在主分片执行搜索请求，副本不参与搜索；性能会打折扣，达不到性能的水平扩展。
（4）_primary_first：优先在主分片执行，如果主分片挂掉，会在副本执行请求。
（5）_only_node:123 ：只在123这个节点执行搜索。
（6）_prefer_node:123：搜索请求优先在节点123执行。
（7）_shards:1,2：搜索只在分片2、3执行，可以与_primary参数一起使用如：_shards:2,3;_primary
（8）随机字符串：指定一个随机字符串，可以保证同样的请求，被分配到同样的副本上面，从而保证同一请求结果的稳定性。我遇到的问题就可以使用这种方式，把搜索串的hash值作为随机字符串，这样可以保证同一个搜索条件的请求的返回结果和排序一致。</p>
]]></content:encoded>
    </item>
    <item>
      <title>guassdb</title>
      <link>https://blog.cizai.io/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E5%BA%93/guassdb.html</link>
      <guid>https://blog.cizai.io/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E5%BA%93/guassdb.html</guid>
      <source url="https://blog.cizai.io/rss.xml">guassdb</source>
      <description>guassdb 优化 1、删除表dim_shop_sales_target在字段target_date上的索引（注：列存表非必要无需创建索引，如创建，可选用btree索引，不要创建默认的psort索引，贵司当前列存表上，基本都是psort索引） 2、dim_jd_erp_shop表，建议修改为复制表（数据总量较小的维度表，建议调整为复制表） 自动更新时...</description>
      <category>数据库</category>
      <pubDate>Sat, 01 Jan 2022 00:00:00 GMT</pubDate>
      <content:encoded><![CDATA[
<h2>优化</h2>
<ul>
<li>1、删除表dim_shop_sales_target在字段target_date上的索引（注：列存表非必要无需创建索引，如创建，可选用btree索引，不要创建默认的psort索引，贵司当前列存表上，基本都是psort索引）</li>
<li>2、dim_jd_erp_shop表，建议修改为复制表（数据总量较小的维度表，建议调整为复制表）</li>
</ul>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>在各DN的数据分布倾斜
select table_skewness('ads_sales_shop_notdis');

</code></pre></div><h2>自动更新时间</h2>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>CREATE TABLE public.ads_order_city_rank (
pkey varchar(50) NOT NULL,
sdate date NOT NULL,
shop_code_inner varchar(255) NOT NULL,
shop_name varchar(200) NULL DEFAULT NULL::character varying,
city varchar(200) NULL DEFAULT NULL::character varying,
city_rank int4 NOT NULL,
city_rank_last float8 NOT NULL,
city_rank_first float8 NOT NULL,
avg_city_sales float8 NOT NULL,
distance_avg_sales float8 NOT NULL,
divided_avg_sales float8 NOT NULL,
city_rank_max int4 NOT NULL,
distance_max_sales float8 NOT NULL,
divided_max_sales float8 NOT NULL,
create_time timestamp NULL DEFAULT now()::timestamp without time zone,
update_time timestamp DEFAULT current_timestamp ON UPDATE current_timestamp,
CONSTRAINT ads_order_city_rank_pkey PRIMARY KEY (pkey)
)
WITH (
orientation=row,
compression=no
);
CREATE INDEX idx_shop_code_inner ON ads_order_city_rank USING btree (shop_code_inner) TABLESPACE pg_default;
</code></pre></div><h2>常用命令</h2>
<p>CREATE TABLE T2
(
id   int not null default nextval('seq1'),
name text
);</p>
<p>CREATE SEQUENCE seq1 cache 100;</p>
<p>查看分布式列的分布
select * from table_skewness('public.ads_order_item_sales','shop_code_inner');</p>
<p>修改分布式列
ALTER TABLE public.ads_order_item_sales DISTRIBUTE BY HASH(shop_code_inner);</p>
<p>查看分布式列
select pg_get_tabledef('ads_order_sales_dws_row')</p>
<p>查看数据倾斜
SELECT a.count,b.node_name FROM (SELECT count(*) AS count,xc_node_id FROM ads_order_item_sales GROUP BY xc_node_id) a, pgxc_node b
WHERE a.xc_node_id=b.node_id ORDER BY a.count desc;</p>
<p>查看数据倾斜
SELECT schemaname,tablename,pg_size_pretty(totalsize),skewratio FROM PGXC_GET_TABLE_SKEWNESS WHERE SKEWRATIO &gt; 0.05 ORDER BY TOTALSIZE DESC;</p>
<p>查看最耗时的10个sql
SELECT * FROM pgxc_wlm_session_info
where start_time &gt;= '2023-03-26 00:00:00'
and query not like 'delete%'
and query not like 'select count%'
and query not like 'CREATE%'
order by duration desc limit 10;</p>
<p>-- 查询指定表占用的磁盘存储空间
select pg_size_pretty(pg_relation_size('public.ads_order_sales'));  -- 99 GB
-- 查询表的脏页率信息
select dirty_page_rate from PGXC_GET_STAT_ALL_TABLES where relname = 'ads_order_sales';  -- 64.68
select * from PGXC_GET_STAT_ALL_TABLES where dirty_page_rate&gt;30;</p>
<h2>Clickhouse bitmap用法</h2>
<p>bitmap主要用于快速去重计算，集合计算，节约空间与时间，典型场景是根据标签来进行用户的圈选。</p>
<p>简单示例：</p>
<p>假如有一张用户标签表</p>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>CREATE TABLE tmp.users_table_replica ON CLUSTER ck_cluster1
(
uid UInt64,
tag1 String,
tag2 String
)
ENGINE = ReplicatedMergeTree
ORDER BY uid;
</code></pre></div><p>分布式表</p>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>CREATE TABLE tmp.users_table
ON CLUSTER ck_cluster1
AS tmp.users_table_replica
ENGINE = Distributed(ck_cluster1, tmp, users_table_replica, rand())
</code></pre></div><p>写入测试数据</p>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>insert into tmp.users_table (uid, tag1, tag2) VALUES
(1, '男','北京'),
(2, '女','天津'),
(3, '男','上海'),
(4, '女','北京')
</code></pre></div><p>如果大数据量的情况下，clickhouse按任意条件做去重查询效率不高，可使用bitmap</p>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>CREATE TABLE tmp.users_table_bitmap_replica ON CLUSTER ck_cluster1

(
tag_id String,
users AggregateFunction(groupBitmap, UInt64)
)
ENGINE = ReplicatedMergeTree
ORDER BY tag_id;
</code></pre></div><p>分布式表</p>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>CREATE TABLE tmp.users_table_bitmap
ON CLUSTER ck_cluster1
AS tmp.users_table_bitmap_replica
ENGINE = Distributed(ck_cluster1, tmp, users_table_bitmap_replica, rand())
</code></pre></div><p>写入数据</p>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>insert into tmp.users_table_bitmap select tag1,groupBitmapState(uid) from tmp.users_table group by tag1;
insert into tmp.users_table_bitmap select tag2,groupBitmapState(uid) from tmp.users_table group by tag2;
</code></pre></div><p>查询性别是男的所有用户（只返回uid，需要明细数据还得再关联）</p>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>SELECT bitmapToArray(users) FROM tmp.users_table_bitmap WHERE tag_id = '男';
</code></pre></div><p>展开成行</p>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>SELECT arrayJoin(bitmapToArray(users)) FROM tmp.users_table_bitmap WHERE tag_id = '男';
</code></pre></div><p>查询性别是男的用户数</p>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>select bitmapCardinality(users) FROM tmp.users_table_bitmap WHERE tag_id = '男';
</code></pre></div><p>以上示例还可以如此建表（如果标签是年龄或者是日期，需要做大于小于等计算，则必须如此建表）</p>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>CREATE TABLE tmp.users_table_bitmap_replica1 ON CLUSTER ck_cluster1
(
tag1 String,
tag2 String,
users AggregateFunction(groupBitmap, UInt64)
)
ENGINE = ReplicatedMergeTree
ORDER BY (tag1,tag2);
</code></pre></div><p>分布式表</p>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>CREATE TABLE tmp.users_table_bitmap1
ON CLUSTER ck_cluster1
AS tmp.users_table_bitmap_replica1
ENGINE = Distributed(ck_cluster1, tmp, users_table_bitmap_replica1, rand())
</code></pre></div><p>写入</p>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>insert into tmp.users_table_bitmap1 select tag1,tag2,groupBitmapState(uid) from tmp.users_table group by tag1,tag2;
</code></pre></div><p>查询性别是男的所有用户</p>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>SELECT tag1,bitmapToArray(users) FROM tmp.users_table_bitmap1 WHERE tag1 = '男';
</code></pre></div><p>展开成行</p>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>SELECT tag1,arrayJoin(bitmapToArray(users)) FROM tmp.users_table_bitmap1 WHERE tag1 = '男';
</code></pre></div><p>查询性别是男的用户数（会返回多条数据）</p>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>select tag1,tag2,bitmapCardinality(users) FROM tmp.users_table_bitmap1 WHERE tag1 = '男';
</code></pre></div><p>查询性别是男的总用户数</p>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>SELECT countDistinct(arrayJoin(bitmapToArray(users))) AS merged_users_count FROM tmp.users_table_bitmap1 WHERE tag1 = '男'
</code></pre></div><p>如有多张bitmap表可以进行交并计算（要比普通的用户表进行JOIN或者IN计算要高效很多）
clickhouse同样提供了一系列函数来进行bitmap之间的集合运算，包括并集、交集、差集、补集等。
具体使用可查阅官方文档：bitmap函数https://clickhouse.com/docs/zh/sql-reference/functions/bitmap-functions/</p>
<p>arrayJoin                宽表转Bitmap表需要行转列，要用arrayJoin把多列数组炸成行。
bitmapAnd             求两个Bitmap值的交集
bitmapOr                求两个Bitmap值的并集
bitmapXor              求两个Bitmap值的差集(异或)
bitmapToArray      把Bitmap转换成数值数组
bitmapToArray      把Bitmap转换成数值数组
bitmapCardinality 返回一个bitmap数据的个数</p>
<h3>bitmap性能测试:</h3>
<p>-- 创建分布式表</p>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>CREATE TABLE tmp.member_order_bitmap_replica ON CLUSTER ck_cluster1
(
sdate String,
store_shop_code String,
users AggregateFunction(groupBitmap, UInt64)
)
ENGINE = ReplicatedMergeTree
ORDER BY (sdate, store_shop_code);
</code></pre></div><p>-- 创建分布式表</p>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>CREATE TABLE tmp.member_order_bitmap ON CLUSTER ck_cluster1
AS tmp.member_order_bitmap_replica
ENGINE = Distributed(ck_cluster1, tmp, member_order_bitmap_replica, rand());
</code></pre></div><p>-- 插入 6800 万数据（耗时十秒）</p>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>INSERT INTO tmp.member_order_bitmap
SELECT
sdate,
store_shop_code,
groupBitmapState(toUInt64(coalesce(user_id, 0))) AS bitmap_result
FROM
bas.abs_member_order_lastyear
WHERE
store_shop_code IS NOT NULL
-- and sdate &gt;= '2023-10-15'
GROUP BY
sdate,
store_shop_code;
</code></pre></div><p>-- 最近一年明细数据量为 3400 万条
-- 查询最近一年用户明细（耗时442毫秒）</p>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>SELECT sdate, bitmapToArray(users) FROM tmp.member_order_bitmap
WHERE sdate BETWEEN '2022-11-17' AND '2023-11-17';
</code></pre></div><p>-- 查询最近一年用户明细（展开成行，耗时382毫秒）</p>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>SELECT sdate, arrayJoin(bitmapToArray(users)) FROM tmp.member_order_bitmap
WHERE sdate BETWEEN '2022-11-17' AND '2023-11-17';
</code></pre></div><p>-- 按日期、门店分组查询最近一年用户数（耗时285毫秒）</p>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>SELECT sdate, store_shop_code, bitmapCardinality(users) FROM tmp.member_order_bitmap
WHERE sdate BETWEEN '2022-11-17' AND '2023-11-17';
</code></pre></div><p>-- 按日期分组查询最近一年用户数（耗时1.3秒）</p>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>SELECT sdate, countDistinct(arrayJoin(bitmapToArray(users))) AS merged_users_count
FROM tmp.member_order_bitmap
WHERE sdate BETWEEN '2022-11-17' AND '2023-11-17'
GROUP BY sdate;
</code></pre></div><p>或者（建议用这个，性能更快）</p>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>SELECT sdate, bitmapCardinality(groupBitmapMergeState(users)) AS merged_users_count

FROM tmp.member_order_bitmap

WHERE sdate BETWEEN '2022-11-17' AND '2023-11-17'

GROUP BY sdate;
</code></pre></div><p>-- 查询最近一年总用户数（耗时2秒）</p>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>SELECT countDistinct(arrayJoin(bitmapToArray(users))) AS merged_users_count
FROM tmp.member_order_bitmap
WHERE sdate BETWEEN '2022-11-17' AND '2023-11-17';
</code></pre></div><p>或者（性能略微快一点）</p>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>select bitmapCardinality(groupBitmapOrState(users)) from(
select users from tmp.member_order_bitmap where sdate BETWEEN '2022-11-17' AND '2023-11-17'
)
</code></pre></div><p>或者（性能快一倍多）</p>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>select bitmapCardinality(groupBitmapMergeState(users))
from tmp.member_order_bitmap where sdate BETWEEN '2022-11-17' AND '2023-11-17';
</code></pre></div><p>--查询2022-11-15和2022-11-16连续两天消费的用户数（交集），将bitmapToArray改为bitmapCardinality即返回用户数</p>
<div class="language-text" data-ext="text" data-title="text"><pre class="language-text"><code>SELECT
bitmapToArray(bitmapAnd(r1.users_bitmap, r2.users_bitmap)) AS res
FROM
(
SELECT groupBitmapMergeState(users) AS users_bitmap
FROM tmp.member_order_bitmap
WHERE sdate = '2023-11-15'
) AS r1,
(
SELECT groupBitmapMergeState(users) AS users_bitmap
FROM tmp.member_order_bitmap
WHERE sdate = '2023-11-16'
) AS r2;
</code></pre></div>]]></content:encoded>
    </item>
  </channel>
</rss>