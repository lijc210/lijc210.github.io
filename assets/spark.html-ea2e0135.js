const e=JSON.parse('{"key":"v-e4559fa8","path":"/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%BB%84%E4%BB%B6/spark.html","title":"spark","lang":"zh-CN","frontmatter":{"icon":"edit","date":"2022-01-01T00:00:00.000Z","category":["组件"],"tag":["spark"],"description":"spark spark面试问题 1、spark中的RDD是什么，有哪些特性 RDD（Resilient Distributed Dataset）叫做分布式数据集，是Spark中最基本的数据抽象，它代表一个不可变、可分区、里面的元素可并行计算的集合。 *Dataset：就是一个集合，用于存放数据的 *Distributed：分布式，可以并行在集群计算 *Resilient：表示弹性的 *弹性表示 *1、RDD中的数据可以存储在内存或者是磁盘 *2、RDD中的分区是可以改变的 五大特性： *A list of partitions 一个分区列表，RDD中的数据都存在一个分区列表里面 *A function for computing each split 作用在每一个分区中的函数 *A list of dependencies on other RDDs 一个RDD依赖于其他多个RDD，这个点很重要，RDD的容错机制就是依据这个特性而来的 *Optionally, a Partitioner for key-value RDDs (e.g. to say that the RDD ishash-partitioned) 可选的，针对于kv类型的RDD才具有这个特性，作用是决定了数据的来源以及数据处理后的去向 *Optionally, a list of preferred locations to compute each split on (e.g. blocklocations for an HDFS file) 可选项，数据本地性，数据位置最优","head":[["meta",{"property":"og:url","content":"https://www.cizai.io/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%BB%84%E4%BB%B6/spark.html"}],["meta",{"property":"og:site_name","content":"此在笔记"}],["meta",{"property":"og:title","content":"spark"}],["meta",{"property":"og:description","content":"spark spark面试问题 1、spark中的RDD是什么，有哪些特性 RDD（Resilient Distributed Dataset）叫做分布式数据集，是Spark中最基本的数据抽象，它代表一个不可变、可分区、里面的元素可并行计算的集合。 *Dataset：就是一个集合，用于存放数据的 *Distributed：分布式，可以并行在集群计算 *Resilient：表示弹性的 *弹性表示 *1、RDD中的数据可以存储在内存或者是磁盘 *2、RDD中的分区是可以改变的 五大特性： *A list of partitions 一个分区列表，RDD中的数据都存在一个分区列表里面 *A function for computing each split 作用在每一个分区中的函数 *A list of dependencies on other RDDs 一个RDD依赖于其他多个RDD，这个点很重要，RDD的容错机制就是依据这个特性而来的 *Optionally, a Partitioner for key-value RDDs (e.g. to say that the RDD ishash-partitioned) 可选的，针对于kv类型的RDD才具有这个特性，作用是决定了数据的来源以及数据处理后的去向 *Optionally, a list of preferred locations to compute each split on (e.g. blocklocations for an HDFS file) 可选项，数据本地性，数据位置最优"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2023-07-13T06:58:32.000Z"}],["meta",{"property":"article:author","content":"cizai"}],["meta",{"property":"article:tag","content":"spark"}],["meta",{"property":"article:published_time","content":"2022-01-01T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2023-07-13T06:58:32.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"spark\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2022-01-01T00:00:00.000Z\\",\\"dateModified\\":\\"2023-07-13T06:58:32.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"cizai\\",\\"url\\":\\"https://www.cizai.io\\"}]}"]]},"headers":[{"level":2,"title":"spark面试问题","slug":"spark面试问题","link":"#spark面试问题","children":[{"level":3,"title":"1、spark中的RDD是什么，有哪些特性","slug":"_1、spark中的rdd是什么-有哪些特性","link":"#_1、spark中的rdd是什么-有哪些特性","children":[]},{"level":3,"title":"2、概述一下spark中的常用算子区别（map、mapPartitions、foreach、foreachPartition）","slug":"_2、概述一下spark中的常用算子区别-map、mappartitions、foreach、foreachpartition","link":"#_2、概述一下spark中的常用算子区别-map、mappartitions、foreach、foreachpartition","children":[]},{"level":3,"title":"3、谈谈spark中的宽窄依赖","slug":"_3、谈谈spark中的宽窄依赖","link":"#_3、谈谈spark中的宽窄依赖","children":[]},{"level":3,"title":"4、spark中如何划分stage","slug":"_4、spark中如何划分stage","link":"#_4、spark中如何划分stage","children":[]},{"level":3,"title":"5、spark-submit的时候如何引入外部jar包","slug":"_5、spark-submit的时候如何引入外部jar包","link":"#_5、spark-submit的时候如何引入外部jar包","children":[]},{"level":3,"title":"6、spark 如何防止内存溢出","slug":"_6、spark-如何防止内存溢出","link":"#_6、spark-如何防止内存溢出","children":[]},{"level":3,"title":"7、spark中cache和persist的区别","slug":"_7、spark中cache和persist的区别","link":"#_7、spark中cache和persist的区别","children":[]},{"level":3,"title":"8、简要描述Spark分布式集群搭建的步骤","slug":"_8、简要描述spark分布式集群搭建的步骤","link":"#_8、简要描述spark分布式集群搭建的步骤","children":[]},{"level":3,"title":"9、spark中的数据倾斜的现象、原因、后果","slug":"_9、spark中的数据倾斜的现象、原因、后果","link":"#_9、spark中的数据倾斜的现象、原因、后果","children":[]},{"level":3,"title":"10、如何解决spark中的数据倾斜问题","slug":"_10、如何解决spark中的数据倾斜问题","link":"#_10、如何解决spark中的数据倾斜问题","children":[]},{"level":3,"title":"11、flume整合sparkStreaming问题","slug":"_11、flume整合sparkstreaming问题","link":"#_11、flume整合sparkstreaming问题","children":[]},{"level":3,"title":"12、kafka整合sparkStreaming问题","slug":"_12、kafka整合sparkstreaming问题","link":"#_12、kafka整合sparkstreaming问题","children":[]},{"level":3,"title":"13、利用scala语言实现排序","slug":"_13、利用scala语言实现排序","link":"#_13、利用scala语言实现排序","children":[]}]}],"git":{"createdTime":1689218642000,"updatedTime":1689231512000,"contributors":[{"name":"lijc210","email":"lijc210@163.com","commits":2}]},"readingTime":{"minutes":20.38,"words":6115},"filePathRelative":"大数据/组件/spark.md","localizedDate":"2022年1月1日","excerpt":"<h1> spark</h1>\\n<h2> spark面试问题</h2>\\n<h3> 1、spark中的RDD是什么，有哪些特性</h3>\\n<ul>\\n<li>\\n<pre><code>RDD（Resilient Distributed Dataset）叫做分布式数据集，是Spark中最基本的数据抽象，它代表一个不可变、可分区、里面的元素可并行计算的集合。\\n *Dataset：就是一个集合，用于存放数据的\\n *Distributed：分布式，可以并行在集群计算\\n *Resilient：表示弹性的\\n        *弹性表示\\n               *1、RDD中的数据可以存储在内存或者是磁盘\\n               *2、RDD中的分区是可以改变的\\n</code></pre>\\n</li>\\n<li>\\n<pre><code>五大特性：\\n *A list of partitions\\n        一个分区列表，RDD中的数据都存在一个分区列表里面\\n *A function for computing each split\\n        作用在每一个分区中的函数\\n *A list of dependencies on other RDDs\\n        一个RDD依赖于其他多个RDD，这个点很重要，RDD的容错机制就是依据这个特性而来的\\n *Optionally, a Partitioner for key-value RDDs (e.g. to say that the RDD ishash-partitioned)\\n        可选的，针对于kv类型的RDD才具有这个特性，作用是决定了数据的来源以及数据处理后的去向\\n *Optionally, a list of preferred locations to compute each split on (e.g. blocklocations for an HDFS file)\\n        可选项，数据本地性，数据位置最优\\n</code></pre>\\n</li>\\n</ul>","autoDesc":true}');export{e as data};
