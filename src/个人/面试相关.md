---
icon: edit
date: 2022-01-01
category:
  - 面试相关
tag:
  # - 红
  # - 大
  # - 圆
---

# 面试相关

## 米哈游面试题

拉链表的设计
流水表很大，每日新增数据很多，可以用拉链表来节省存储空间
先初始化全量数据到当日表中，然后每天把更新的数据查到临时表中，
两表进行关联，union all全量表中未更新的数据和新增的数据，保持记录唯一
将未变化的结束时间置为昨日时间，将有变化且状态不为结束的结束时间置为9999


缓慢变化维 SCD
维度的属性随着时间变化发生缓慢的变化，比如一张员工信息表中，员工的职位发生了变化，从开发者变为管理者
解决办法有，1、直接更新原来的维度。2、新增一条记录。3、新加一个新的维度


sql题说思路

CBO优化
查询优化器分类有两种， 基于规则的优化器 RBO，一个是 基于代价的优化器 CBO，CBO比RBO更高级，基于规则是基于查询语法，基于代价就考虑执行的代码，选择代价最低的方式执行
比如大小表关联，基于代价的优化器就可以自动判断

kafka架构
从头开始消费，从当前的offset消费
可以设置取到数据就提交offset，也可以手动提交，这样保证数据都被消费到


python装饰器
python装饰器可以修改函数的功能，代码简洁美观，本质是将函数作为参赛传递到下一个函数中执行



谓词下推

## 面试常见问题
工作上的问题（缺点）：
说实话很多东西我只是会用，出现问题能解决问题，但是不是非常清楚原理，比如hdfs文件系统，Elasticsearch倒排索引具体的实现是怎么样的，各种数据库底层实现等等，我希望后面自己能更深入底层，更好的了解这些工具，这样或许能做一些开源贡献。

生活上的问题（缺点）：
比较宅，对陌生的人很慢热。


优点：
善于解决程序问题，有时候公司有一二十年开发经验的同事解决不了的问题，我能解决。另外我认为我很好相处。


除了薪资，还可以问什么？
请问薪资结构是怎么样的，还有什么其他福利吗，社保公积金缴纳比例，
数据部门现在有多少人？
我总听同事说外部公司不好，但是我没实际待过外包公司，你能不能说一个您觉得不好的点，我看我能不能接受
你们加班多吗
上班时间是几点到几点
服务器规模，hadoop集群规模
工作职责
团队人员构成


你并非名牌院校毕业？
是否毕业于名校不重要，重要的是有能力完成您交给我的工作，而且我知道我在学历方面的不足，所以在工作时比名校毕业的人更努力，业余时间更愿意学习


工作中最突出的成绩
其实在简历中您可以看到，每一个项目都是我的工作成绩，要说最突出的就是，和几位同事开发了全公司所有产品的搜索、个性化推荐需求，我是主力开发，架构都是我设计的，70%以上代码是我写的，其他同事主要做算法设计相关的工作。


当初为什么要离开，又为什么回来，现在为什么走
        去中通是因为部门总监先过去，然后在那边组建团队，然后给我的岗位是大数据开发，所以我就过去了。
        回来也是因为那个总监回来，然后邀请了三次让我回来，我想认识这么好的一个总监也不容易，就又跟着回来，还是做大数据开发。
        

部门团队构成：
齐家，数据部门有大数据开发、ETL、数据分析、算法、JAVA、Python开发、总计20多人
中通数据部有30多人，不过一直在扩招，现在好像有60-70人
我在大数据开发组


服务器规模
大数据平台的服务器有20多台，搜索、推荐的服务器有十几台左右
中通的服务器资源就很丰富，开发测试分离得很好，像在齐家想在测试服务器搭一套hadoop集群就没有这样的资源
flink集群是4台


有没有其他offer
因为我这也是这周才刚面试，有不少面试邀请，虽说您这是外包公司，但是贝宝外包，工作地点又不错，所以还是挺想去你们公司的。


职位发展规划
我个人是偏技术的，兴趣就是大数据，高性能，分布式，未来想往大数据架构师方式发展，深入大数据架构底层


薪资构成
加班有调休吗
社保公积金比例


## 总结
被卡住的问题：
flink项目中的具体实现
实时处理商户提报需求通过店铺id、城市、区域、户型关联spl配置表，加上相应的spl量，更新到spl配置表
实时处理订单通过店铺id、城市、区域、户型关联spl配置表，减掉相应的spl量，更新到spl配置表



工作中遇到印象深刻的问题
做搜索推荐的时候，有八九种召回数据，最开始数据是存在hbase，测试的时候没问题，但是hbase在大量导数据压力一大的时候，接口查询就慢，从而影响推荐的性能，并且python的hbase客户端还不成熟，在并行查询的时候，数据偶尔会发送错乱，数据量又太大，放redis放不下，然后就调研各种其他kv数据库，然后发现了360开源pick，基于facebook的rocksdb，功能覆盖redis的90%，性能是redis的一半，但是value是存在磁盘的，所以对内存的消耗极小。
后来就将推荐用到的各种数据从hbase迁移的pika了，性能稳定。


java基础，go基础


最近在做的项目
报表不支持明细查询，presto又较慢，所以最近在搭一套最新版本的ES集群，支持sql，会将部分流量数据导入ES，以后会导其他类型的数据，然后会有查询页面，供市场部等查询

## flink面试题
flink中遇到什么问题，
因为我们数据量不大，flink还挺稳定的，就是学习成本有点高，花了比较久时间，比如怎么样分时间窗口运行，或者没到时间窗口，积累到一定数据量后怎么运行，怎么批量将结果存入mysql，而不是一条条写入

## paypal
1.    Jvm内存模型，举例说明内存泄漏

一、JVM内存模型及垃圾收集算法

1.根据Java虚拟机规范，JVM将内存划分为：

New（年轻代）
Tenured（年老代）
永久代（Perm）
其中New和Tenured属于堆内存，堆内存会从JVM启动参数（-Xmx:3G）指定的内存中分配，Perm不属于堆内存，有虚拟机直接分配，但可以通过-XX:PermSize -XX:MaxPermSize 等参数调整其大小。

 

年轻代（New）：年轻代用来存放JVM刚分配的Java对象
年老代（Tenured)：年轻代中经过垃圾回收没有回收掉的对象将被Copy到年老代
永久代（Perm）：永久代存放Class、Method元信息，其大小跟项目的规模、类、方法的量有关，一般设置为128M就足够，设置原则是预留30%的空间。
New又分为几个部分：

Eden：Eden用来存放JVM刚分配的对象
Survivor1
Survivro2：两个Survivor空间一样大，当Eden中的对象经过垃圾回收没有被回收掉时，会在两个Survivor之间来回Copy，当满足某个条件，比如Copy次数，就会被Copy到Tenured。显然，Survivor只是增加了对象在年轻代中的逗留时间，增加了被垃圾回收的可能性。
 

2.垃圾回收算法

垃圾回收算法可以分为三类，都基于标记-清除（复制）算法：

Serial算法（单线程）
并行算法
并发算法
JVM会根据机器的硬件配置对每个内存代选择适合的回收算法，比如，如果机器多于1个核，会对年轻代选择并行算法，关于选择细节请参考JVM调优文档。

稍微解释下的是，并行算法是用多线程进行垃圾回收，回收期间会暂停程序的执行，而并发算法，也是多线程回收，但期间不停止应用执行。所以，并发算法适用于交互性高的一些程序。经过观察，并发算法会减少年轻代的大小，其实就是使用了一个大的年老代，这反过来跟并行算法相比吞吐量相对较低。

 

还有一个问题是，垃圾回收动作何时执行？

当年轻代内存满时，会引发一次普通GC，该GC仅回收年轻代。需要强调的时，年轻代满是指Eden代满，Survivor满不会引发GC
当年老代满时会引发Full GC，Full GC将会同时回收年轻代、年老代
当永久代满时也会引发Full GC，会导致Class、Method元信息的卸载
另一个问题是，何时会抛出OutOfMemoryException，并不是内存被耗空的时候才抛出

JVM98%的时间都花费在内存回收
每次回收的内存小于2%
满足这两个条件将触发OutOfMemoryException，这将会留给系统一个微小的间隙以做一些Down之前的操作，比如手动打印Heap Dump。




2.    多线程synchronized的使用

3.    数据库 sql join的类型，大小两个表join如何优化
inner join 只连接匹配的行
LEFT JOIN 返回左表的全部行和右表满足ON条件的行
RIGHT JOIN
FULL OUTER JOIN 两边都返回，相当于并集


4.    kafka生产者 消费者分别如何保证不丢消息

5.    shell如何捕获异常，多个shell调用如何捕获异常
使用命令返回值判断，$?!=0 就是异常，多个调用，就在每个调用下都用$?判断一下，如果调用太多可以写个shell函数，在函数里面判断


6.    算法，几种排序都说一下
冒泡排序，相邻的两两排序，然后纠正位置，直到没有反序为止    时间复杂度：O(n^2)
插入排序，将一个记录插入到已经排序的序列中，插入的时候可以用二分查找   时间复杂度：O(n^2)
归并排序，将一个序列分成n/2个子序列，每个序列包含2个元素，子序列两两归并排序，直到完毕

Python和java都是 快速排序或者插入排序，当数据量小时使用插入排序，数据量大时使用快速排序 每次都选一个基准值，将所有元素和基准值比较，分成2部分，其中的一部分总数小于另外一部分，然后继续选基准值，继续分区，直到排序完毕，在小规模数据上性能不好，需要额外的空间        O(nlogn)        当对象为object时采用归并排序


7.    Spark 的RDD



8.    性能问题如何优化？

9.    数据倾斜？
表现：绝大多数任务执行很快，但个别任务执行极慢。原来正常执行的程序，不能正常执行，内存溢出
原因：单个值有大量记录（调整key）或者唯一值较多（增加reduce个数，增加分区数）

或者过滤导致倾斜的key


10.    选spark的原因？
即支持批又支持实时，速度又比hive快很多，开发相对简单


11.    Java collection 有哪些？--hashMap的实现原理，list， 如何实现堆(heap)?
（1）list：list接口包含ArrayList，Vector，LinkedList。
（2）set包含HashSet，TreeSet，EnumSet。
（3）Queueu包含LinkedList，PriorityQueue


12.    如何实现一次hive表的多个分区插入数据？
设置动态分区


队列和栈，队列先进先出，栈先进后出




复试前建议:kafka优化，spark优化，Hive优化，spark shuffer，什么是rdd， java集合 jvm 线程，锁。多关注算法题。


## 面试问题
创建执行环境有三种方式
StreamExecutionEnvironment.getExecutionEnvironment
StreamExecutionEnvironment.createLocalEnvironment
StreamExecutionEnvironment.createRemoteEnvironment


flink状态存储有哪几种方式
* MemoryStateBackend 内存存储
* FsStateBackend 文件系统存储
* RocksDBStateBackend RocksDB存储



Java 容器分为 Collection 和 Map 两大类，其下又有很多子类，如下所示：
* Collection
* List
    * ArrayList
    * LinkedList
    * Vector
    * Stack
* Set
    * HashSet
    * LinkedHashSet
    * TreeSet
* Map
* HashMap
    * LinkedHashMap
* TreeMap
* ConcurrentHashMap
* Hashtable

## 大数据面试题100道
1、HashMap 和 Hashtable 区别
1.相同点：
（1）都是基于哈希表实现的，都是键值对集合；
（2）里边的元素都是无序的，跟添加顺序无关；
2.不同点：
（1）HashMap允许有一个null键和多个null值；
（2）HashMap不是线程安全的，HashTable是线程安全的。

2、Java 垃圾回收机制和生命周期
判断对象是否已死的方法：引用计数算法和可达性分析算法。
当内存不够会自动回收和定时回收，还是不够会报内存溢出

3、怎么解决 Kafka 数据丢失的问题
关闭自动提交offset，处理完数据之后手动提交。

4、zookeeper 是如何保证数据一致性的
数据一致性是靠Paxos（帕克索斯）算法保证的， Paxos算法比较复杂，为了简化实现，Zookeeper使用了一种叫ZAB（原子消息广播协议）的算法协议

5、hadoop 和 spark 在处理数据时，处理出现内存溢出的方法有哪些？
一般情况下是数据倾斜导致的，解决数据倾斜就可以了
处理内存溢出的一般方法，先优化程序，再不行加大内存配置

6、java 实现快速排序
快速排序是选一个基准值，将数据一分为二，其中一部分数据总数小于另一份数据，如此循环，直到排序完毕，时间复杂度是nlogn


7、设计微信群发红包数据库表结构（包含表名称、字段名称、类型）
红包id，红包金额，红包类型，红包人数，剩余金额，剩余人数，创建时间，更新时间

8、如何选型：
业务场景、性能要求、维护和扩展性、成本、开源活跃度


9、spark 调优
减少数据倾斜，调整参数，如提高内存，提高执行数

10、Flink和spark的 通信框架
pas

11、java 代理
是一种设计模式

12、java的内存溢出和内存泄漏
pass

13、hadoop 的组件有哪些？Yarn 的调度器有哪些？
分布式文件系统（HDFS）
资源管理调度框架Yarn
分布式协调服务ZooKeeper
数据仓库工具Hive，kylin
实时计算框架Spark、flink
数据同步sqoop、datax
分布式数据库HBase

先进先出调度器
优点：简单，不需要配置。
缺点：不适合共享集群。如果有大的app需要很多资源，那么其他app可能会一直等待。

容量调度器
CapacityScheduler允许将整个集群的资源分成多个部分，每个组织使用其中的一部分，即每个组织有一个专门的队列，每个组织的队列还可以进一步划分成层次结构（Hierarchical Queues），从而允许组织内部的不同用户组的使用。
每个队列内部，按照FIFO的方式调度Applications。当某个队列的资源空闲时，可以将它的剩余资源共享给其他队列。

公平调度器
所谓的公平调度器指的是，旨在让每个用户公平的共享集群的能力。如果是只有一个作业在运行的话，就会得到集群中所有的资源。随着提交的作业越来越多，限制的任务槽会以“让每个用户公平共享集群”这种方式进行分配。某个用户的好事短的作业将在合理的时间内完成，即便另一个用户的长时间作业正在运行而且还在运行过程中。

14、hadoop 的 shuffle 过程
1. Map:数据输入,做初步的处理,输出形式的中间结果；
2. Shuffle:按照partition、key对中间结果进行排序合并,输出给reduce线程；
3. Reduce:对相同key的输入进行最终的处理,并将结果写入到文件中。


15、简述 spark 集群运行的几种模式
* local(本地模式)：常用于本地开发测试，本地还分为local单线程和local-cluster多线程;
* standalone(集群模式)(脱机)：典型的Mater/slave模式，不过也能看出Master是有单点故障的；Spark支持ZooKeeper来实现 HA
* on yarn(集群模式)： 运行在 yarn 资源管理器框架之上，由 yarn 负责资源管理，Spark 负责任务调度和计算


16、RDD 中的 reducebyKey 与 groupByKey 哪个性能高？
groupByKey的性能，相对来说，是有问题的
因为，它是不会进行本地聚合的，而是原封不动的，把ShuffleMapTask的输出，拉取到ResultTask的内存中，所以这样的话，会导致，所有的数据，都要进行网络传输，从而导致网络传输的性能开销很大
但是，有些场景下，用其他算法实现不了的，比如reduceByKey,sortByKey,countByKey实现不了的话，还是只能用groupByKey().map()来实现，比如可能你需要拿到某个key对应的所有的value，进行自定义的业务逻辑处理
如果能用reduceByKey，那就用reduceByKey，因为它会在map端，先进行本地combine，可以大大减少要传输到reduce端的数据量，减小网络传输的开销。
只有在reduceByKey处理不了时，才用groupByKey().map()来替代。


17、简述 HBase 的读写过程
1.1 读流程
* 客户端与zk进行连接；从zk找到meta表的region的位置，即meta表的数据存储在某个HReginServer上；客户端与这个HRegionServer建立连接，然后读取meta表中的数据；
* 根据要查询的namespace、表名、rowkey信息。找到对应的的region信息
* 找到相应的HRegionServer
* 找到对应的region
* 先从memstore里面查找数据，如果没有再到BlockCache上读取
* 如果BlockCache上也没有找到再到StoreFile上仅从读取
* 从StoreFile中读取数据到数据后，先写入到BlockCache中然后再返回给客户端
1.2 写流程
* client与zk建立链接，从zookeeper中找到meta表中region的位置，然后读取meta表中的数据
* meta表中存储了用户表的region信息，根据要查询的namespace、表名、rowkey信息。找到写入数据对应的的region信息
* 找到对应的HRegionServer然后发送写请求
* 把数据写入到HLog和memstore中
* memstore中的数据到达阀值后会把数据刷写到磁盘，生成一个storeFile，即一个HFile
* 当达到一定条件后，会把小的HFile合并成大的HFile，避免hdfs有大量的小文件


18、在 2.5亿个整数中，找出不重复的整数，注意：内存不足以容纳 2.5亿个整数。
如果使用数组表示，则一个整数需要4个字节，每个字节8个bit，1kb可以存储1024/4，2.5亿需953.7M
如果使用bitmap表示，则另一个字节可以表示8个数，4个字节可以表示32个数，节约32倍，1kb可以存储8*1024，2.5亿只需29.8M
确定数组大小，2.5亿/8向上取整，生成这个长度的字节，每个字节值为0
遍历2.5亿个数，把相应位置的bit上设置1，就可以判断某个数是否在2.5亿个数之中
要实现“找出不重复的整数”，则采用2-Bitmap，每个正整数用两个bit的标志位， （每个数分配2bit，00表示不存在，01表示出现一次，10表示多次，11无意义）
然后扫描这2.5亿个整数，查看Bitmap中相对应位，如果是00变01，01变10，10保持 不变。扫描后，查看bitmap，把对应位是01的整数输出即可。


19、CDH 和 HDP 的区别
都是不收费的，HDP版本更新较快， CDH版本更新比Apache版本慢。国内CDH用的更多


20、java 原子操作
atomic 包提供基本类型原子操作

21、Java 封装、继承和多态
pass

22、JVM 模型
pass

23、Flume taildirSorce 重复读取数据解决方法
pass

24、Flume 如何保证数据不丢
pass

25、Java 类加载过程
pass

26、Spark Task 运行原理
Job、stage和task是spark任务执行流程中的三个基本单位。其中job是最大的单位，Job是spark应用的action算子催生的；stage是由job拆分，在单个job内是根据shuffle算子来拆分stage的，单个stage内部可根据操作数据的分区数划分成多个task。


27、手写一个线程安全的单例
pass

28、设计模式
工厂模式： 定义一个创建对象的接口，让其子类自己决定实例化哪一个工厂类
单例模式： 单例类只能有一个实例。
生产消费模式：

29、impala 和 kudu 的适用场景，读写性能如何
impala使用hive的元数据, 完全在内存中计算
kudu和Hbase类似也是一个分布式数据库

30、kafka ack
ack=1，简单来说就是，producer只要收到一个分区副本成功写入的通知就认为推送消息成功了。这里有一个地方需要注意，这个副本必须是leader副本。只有leader副本成功写入了，producer才会认为消息发送成功。
注意，ack的默认值就是1。这个默认值其实就是吞吐量与可靠性的一个折中方案。生产上我们可以根据实际情况进行调整，比如如果你要追求高吞吐量，那么就要放弃可靠性。
ack=0，简单来说就是，producer发送一次就不再发送了，不管是否发送成功。
ack=-1，简单来说就是，producer只有收到分区内所有副本的成功写入的通知才认为推送消息成功了。
-1的可靠性最好，0的可靠性最差


31、phoenix 创建索引的方式及区别
pass

32、Flink TaskManager 和 Job Manager 通信
pass

33、Flink 双流 join方式
pass

34、Flink state 管理和 checkpoint 的流程
Flink基于Checkpoint机制实现容错，它的原理是不断地生成分布式Streaming数据流Snapshot。


35、Flink 分层架构
pass

36、Flink 窗口
* time  - 根据时间划分窗口
    #时间类型:
    * EventTime 数据本身携带的时间
    * ProcessingTime 处理时间
* count - 根据数据量划分窗口

37、Flink watermark 如何处理乱序数据
watermark是用来处理乱序数据的

38、Flink time
    * EventTime 数据本身携带的时间
    * ProcessingTime 处理时间

39、Flink 支持exactly-once 的 sink 和 source
pass

40、Flink 提交作业的流程
pass

41、Flink connect 和 join 区别
connect只能连接两个流，而union可以连接多于两个流 。
connect连接的两个流类型可以不一致，而union连接的流的类型必须一致。

42、重启 task 的策略
pass

43、hive 的锁
show locks extended; 查找到具体哪些语句加了锁；
先查看哪些sql有锁，然后解锁。


44、hive sql 优化方式
能加分区就一定加分区，避免全表扫描
关联的时候小表放在左边
避免数据倾斜
优化写法减少job数。


45、hadoop shuffle 过程和架构
shuffle是map和reduced的中间阶段

46、如何优化 shuffle过程
通过一些配置参数优化

47、冒泡排序和快速排序
冒泡排序的原理：重复的遍历要排序的数组，每次遍历过程中从头至尾比较两个相邻的元素，若顺序错误则交换两个元素 ，直到排序完成。 时间复杂度：O(n^2)， 空间复杂度：O(1)
快速排序的原理：通过一趟排序将要排序的数据分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据都要小，然后再按同样的方法对这两部分数据分别进行快速排序。
"保证列表的前半部分都小于后半部分"就使得前半部分的任何一个数从此以后都不再跟后半部分的数进行比较了，大大减少了数字间的比较次数。
时间复杂度：O(nlog2n)，  空间复杂度：O(1)， 快速是不稳定的
（1）先从数列中取出一个数作为基准数。
（2）分区过程，将比这个数大的数全放到它的右边，小于或等于它 的数全放到它的左边。
（3）再对左右区间重复第二步，直到各区间只有一个数


48、Spark stage
Job、stage和task是spark任务执行流程中的三个基本单位。其中job是最大的单位，Job是spark应用的action算子催生的；stage是由job拆分，在单个job内是根据shuffle算子来拆分stage的，单个stage内部可根据操作数据的分区数划分成多个task。

49、spark mkrdd和Parrallilaze函数区别

50、Spark checkpoint 过程
pass

51、二次排序
  默认情况下，Map输出的结果会对Key进行默认的排序，但是有时候需要对Key排序的同时还需要对Value进行排序，这时候就要用到二次排序了。下面我们来说说二次排序


52、注册 hive udf
jar拷到指定位置，重启hive，可以永久注册udf


53、SQL 去重方法
group by 、distinct、窗口函数

54、Hive 分析和窗口函数
ROW_NUMBER， RANK

55、Hadoop 容错，一个节点挂掉然后又上线
pass

56、掌握 JVM 原理
pass

57、Java 并发原理
pass

58、多线程的实现方法
pass

59、RocksDBStatebackend实现（源码级别）
pass

60、HashMap、ConcurrentMap和 Hashtable 区别：https://www.jianshu.com/p/a91f72310545
pass

61、Flink Checkpoint 是怎么做的，作用到算子还是chain
分布式快照，作用到算子

62、Checkpoint失败了的监控
pass

63、String、StringBuffer和 StringBuilder的区别
StringBuffer和 StringBuilder可进行修改，String
StringBuilder性能更好，但是线程不安全，StringBuffer线程安全

64、Kafka存储流程，为什么高吞吐
顺序读写，批量读写，零拷贝

65、Spark 优化方法举例
预处理的数据缓存到内存中
避免数据倾斜调优
配置合理的参数如执行器个数，执行器内存等

66、keyby 的最大并行度
设置合适的并行度，能提高运算效率
parallelism不能于与slot个数。


67、Flink 优化方法
pass

68、kafka isr 机制
pass

69、kafka partition 的 4个状态
* NonExistent：表明不存在的分区或已删除的分区。
* NewPartition：一旦被创建，分区便处于该状态。此时，Kafka已经为分区确定了副本列表，但尚未选举出leader和ISR。
* OnlinePartition：一旦该分区的leader被选出，则进入此状态。这也是分区正常工作时的状态。
* OfflinePartition：在成功选举出leader后，若leader所在的broker宕机，则分区将进入该状态，表明无法正常工作了。


70、kafka 副本的 7个状态
1、NewReplica：当分区重分配时，控制器可以创建一个新副本。这种状态下该副本只能作为follower，它可以是 Replica 删除后的一个临时状态，有效前置状态是 NonExistentReplica；
2、OnlineReplica：当副本被分配到指定的Partition上，并且副本完成创建，那么它将会被置为这个状态。在这个状态下，分区既可以作为Leader也可以作为Follower，有效前置状态是 NewReplica、OnlineReplica 或 OfflineReplica；
3、OfflineReplica：如果副本所在的Broker挂掉，副本将会置为这个状态。有效前置状态是 NewReplica、OfflineReplica 或 OnlineReplica；
4、ReplicaDeletionStarted：副本开始删除时被置为的状态，有效前置状态是 OfflineReplica；
5、ReplicaDeletionSuccessful：如果部分在删除时没有错误信息，它将被置为这个状态。表示该副本的数据已经从Broker清除了，有效前置状态是 ReplicaDeletionStarted；
6、ReplicaDeletionIneligible：如果副本删除失败，会转移到这个状态。表示非法删除，也就是删除不成功，有效前置状态是 ReplicaDeletionStarted；
7、NonExistentReplica：如果副本删除成功，将被转移到这个状态。有效前置状态是：ReplicaDeletionSuccessful。


71、taskmanager
pass

72、if 和 switch 的性能及 switch 支持的参数
pass

73、kafka 零拷贝
因为网卡是直接去访问系统主内存的，不需要经过cpu

74、hadoop 节点容错机制
HDFS数据块副本机制

75、HDFS 的副本分布策略
我们是三副本，块大小为256M，块越小，文件越多，启动的map数越多

76、hadoop 汇总
pass

77、Kudu 和Impala 权限控制
pass

78、Time_wait状态？
当server处理完client的请求后立刻closesocket此时会出现time_wait状态.


79、三次握手交换了什么？ SYN,ACK,SEQ,窗口大小
三次握手的目的是同步连接双方的序列号和确认号并交换TCP 窗口大小信息。
3次握手建立链接，4次握手断开链接。

80、hashmap 1.7和1.8 的区别？ ：https://blog.csdn.net/qq_36520235/article/details/82417949
1.7 是 数组+链表；1.8 是数组+链表+红黑树，为了避免死循环、提高插入效率 log(N)

81、concurrenthashmap 1.7和1.8？
分段锁，属于细粒度，比 hashtable 效率高， cas
为了保证原子操作和线程安全的

82、Kafka 的ack
-1 producer 只有收到分区内所有副本的成功写入的通知才认为推送消息成功了。
0 producer 发送一次就不再发送了，不管是否发送成功
1 producer 只要收到一个分区副本(leader的)成功写入的通知就认为推送消息成功了

83、sql 去重方法
group by 、distinct、窗口函数

84、哪些 hive sql 不能在 spark sql 上运行
pass

85、 什么情况下发生死锁？（pass）
多个进程在运行过程中因争夺资源而造成的一种僵局，当进程处于这种僵持状态时，若无外力作用，它们都将无法再向前推进。

86、事务隔离级别？
 可重复读、不可重复读、读未提交、串行化

87、spark shuffle 和 hadoop shuffle
pas

88、spark 静态内存和动态内存
在spark1.6版本之前就是用的静态内存模型。
动态内存的存储内存和执行内存可以互相借用

89、mysql btree 和 hash tree 的区别。
btree 需要唯一主键，hash tree 适合>= 等，精确匹配，不适合 范围检索

90、udf、udtf和 udaf 的区别
UDF：用户定义（普通）函数，只对单行数值产生作用；
UDAF：User- Defined Aggregation Funcation；用户定义聚合函数，可对多行数据产生作用；等同与SQL中常用的SUM()，AVG()，也是聚合函数；
UDTF：User-Defined Table-Generating Functions，用户定义表生成函数，用来解决输入一行输出多行；


91、hive sql 的执行过程
语法解析， 逻辑计划生成，优化，转换mapreduce，发布到hadoop集群，执行

92、client 端，spark sql 的执行过程
pass

93、找出数组中最长的 top10 字符串
pass

94、Flink 数据处理流程
批量处理：
读取数据，转换rdd，分发任务，处理完成，再收集结果，存储
实时处理：
读取kafka数据，来一条数据处理一条，支持数据消费与输出，转换操作，滚动聚合，窗口操作


95、Flink 与 Spark streaming 对比
spark streaming是时间窗口，还是批处理，只是最短的间隔时间可以设置到1秒
flink是事件驱动，来一条处理一条
Flink 使用异步的 checkpoint 机制来达到任务状态的可恢复性，以保证处理的一致性，很多时候数据不用落盘
所以flink有更高的性能和更低的延迟


96、Flink watermark 使用
watermark是用来处理乱序数据的


97、窗口与流的结合
窗口可以是时间驱动的（Time Window，例如：每30秒钟），也可以是数据驱动的（Count Window，例如：每一百个元素）。
滚动窗口，无重叠
滑动窗口，时间有重叠
会话窗口，无重叠


98、Flink 实时告警设计
pass

99、Java：面向对象、容器、多线程、单例
pass

100、Flink：部署、API、状态、checkpoint、savepoint、watermark、重启策略、datastream 算子和优化、job和task状态
pass

101、Spark：原理、部署、优化
pass

102、Kafka：读写原理、使用、优化
pass

103、hive的外部表问题
外部表只会删除元数据，不会删除表数据，例如hbase外部表，ES外部表

104、spark的函数式编程
pass

105、线性数据结构和数据结构
线性数据结构以有序的方式保存它们的数据。
栈，队列

106、映射，rdd。
RDD：弹性分布式数据集
高效的容错性
中间结果持久化到内存
存放的数据可以是Java对象，避免了不必要的对象序列化和反序列化开销。


## 视野-HR告诉你如何回答“为什么从上家公司离职”
关键字：HR,职业规划
首先，作为一个从事招聘的HR，并不认为追问面试者为什么从上一家公司离职是个明智的做法起码不应该在面试一开始就抛出这个问题，一个较为明显的原因是因为这会引起面试者的防御心理，甚至是敌对心理。最终导致双方的不欢而散。当然，“赚的少“”干得不爽”也不是明智的回答，除非你或你的面试官是马云，否则这个回答将非常容易毁掉这次面试。
其次，需要承认的是这个问题对于一些公司(尤其是创业公司)或者一些重要的职位是必须要面对的问题。所以，在你下一次面试之前，我们有必要认真的探讨一下这个问题的答案。

你在寻找新机会或新的平台
不要诋毁你的老东家相信很少会有人犯这样的错误。这的确是一个不可取的方式。你应该把你的离职原因集中表述在“寻找新机会或新的平台”以及尝试在新的岗位上提升自己。
当然，这样的回答对于一般职位的应聘者来说不会造成减分，但却不足以成为加分项。并且这个回答的最大问题是会引发如下问题的连锁反应：那么你走之后原来的同事们怎么办?你在新的岗位上会不会因为短期的能力难以提升就拍拍屁股走人呢?要知道，相比于能力，有些公司更看重的是忠诚度以及责任感。
如何体现你的忠诚度和责任感。
如果你轻描淡写地就离开了之前的团队，那么面试官会觉得你在新公司也可能会轻易走人。所以，在体现忠诚度的时候，你可以试着谈谈你离开上一家公司时有多么痛苦依依不舍(即使并没有)，聊聊如果有办法使你能在原来的岗位上持续得到提升或者如果不是因为股东之间的权利斗争(可适当显得痛心疾首些)，你肯定不会离开。
而在体现责任感时，你需要表达两层意思。
首先，你从上家公司离职时已经为继任者做了充分的交接。你需要清楚地表明：你在上家公司也很认真尽职，并且同事之间一直保持互助互利的工作氛围。也许你可以说说你也想过要早些辞职，但是考虑某个未完成的重要项目、或是继任者短期内还不能胜任角色所以晚了一些。
其次，就是你很期望承担新的职责，并表现出你的热忱，这种热忱除了对工作的热忱之外，也可以适当的通过向你的面试官(不仅是HR)提问表现出来对面试官的兴趣、对他们技能的认可以及共鸣。例如，“那么，你是如何做到现任职位的?”或：“如果我有幸担任这个职位，你会给我哪些建议?”我们大多数人总是更容易答应自己认识和喜爱的人所提出的要求，反之，我们也会因为别人提出了自己感兴趣的问题而喜欢上这个人。通过这些问题不仅传递一些良好的信号，同时，如果对方的回答可能会与你的背景(比如校友或老乡等)、经历、目标有相似之处，这时你就有机会表达共鸣感，也更加理解新的工作中你们共同面临的挑战。寻求建议、承认自己职责内内不知道的事物反而会令你显得既热忱又能干。
最后，需要说明的是，以上所有内容，都是建立在一个基础之上的，这个基础可以用《贞观政要》中说的一个故事来说明：
贞观初年，有人上书，建议赶走奸臣。唐太宗就召见这个人，说：“老子选的人，都是老子认为牛逼的人，你怎么知道谁是奸臣呢”
这个人就回答说：“我一个草根，不知道谁是奸臣，但我有一妙计，你可以假装发怒，对着干的就是忠臣，顺着说的就是奸臣”。
听了这话之后，太宗转头和旁边的大臣说：流水是清还是混，取决于他的源头。现在我就是源头，你们就是流水，我撒谎却让你诚实，这不就跟源头是混的却希望流水是清的一样吗?老子一生中最鄙视的就是曹操这种贼奸贼奸的人。
最后，太宗和上书的这个人说：老子是希望天下的人都诚信，但绝不会用这种奸诈的方式，你的方法虽然有可取之处，但老子是不会用的。
这个道理告诉我们一个道理就是：用谎言去验证谎言，得到的一定是谎言。与应聘者及面试官们共勉。

## 职业规划提示
职业规划提示
* 
九项重要的职业规划提示。
1. 学习的步伐不停止
古人说，活到老，学到老。终身学习应该是您的座右铭。
世界在不断变化，每个人都在寻找各自的事业途径。
您只有保证了足够的技能储备，才能确保能够得到一份足够满意的工作。
为了保证您的职业发展，您应当定期地更新您的技能和知识。
2. 学会问、学会听，学会学习
一个好的倾听者可以习得更多。
多听取来自同事、老板以及上级的声音。您可以从他们的经历中学到更多。
问一些您感兴趣的话题，然后听听他们怎么说。让他们告诉您事业如何运作，以及如何可以做得更好。
大多数都是乐意帮助您的。
3. 为目前的工作全力以赴
您目前的工作可能是开始您职业生涯的最好起点。
从本职工作做起，从现在做起，做好当前的工作，没有保留地尽到自己的职责，证明自己是一名有价值的员工。
您所做的工作终究会得到回报。
4. 构建人际网络
您的下一个职业阶段很可能得益于您的人际网络。
您知道吗，超过50%的工作都是通过关系网络获得的。
如果您拥有一张良好的人际网络，那么它会助您发现未来的职业，开拓新的方向，获得新的机会。
请在新的关系上多花些时间吧，同时请不要忽略对已有关系的保持。
从您的人际网络获得有价值信息的最佳途径之一是，定期地问候您的交际人，他们正在做什么，以及有关其职业的新情况。
5. 识别你的工作
识别真正重要的工作，而不是去假设。
一定要确定你目前所做的工作不是因假设得来的。那样会浪费您很多时间和才华。
当您着手一份新的工作时，一定要和主管聊聊首要的那些工作。如果您无法确定哪方面是重要的，就去询问他吧。多谈几次也没关系。您会经常对事实上的重要任务与您所作的假设之间差距感到惊讶。
6. 慎重决定下一个工作
在您开始未来的职业生涯之前，一定要认真考虑您理想中的工作。
您理想的职业应该是什么样的呢？ 最关键的是，您一定要乐在其中。
您是否乐于为其它的同事承担责任？您喜欢和人打交道还是摆弄技术？你希望自己创业吗？您希望成为一位艺术家、一位设计师、一名熟练的工程师，还是一名管理人员？
在您为构建未来的职业生涯之前，请明确您的目标。
7. 为未来做准备
为了明天的梦想，今天就要进行准备。
一刻也不要耽搁。现在就更新您的履历，并且定期持续对其更新。
明天您也许就会看到梦想实现的曙光。为此，您需要准备一份专业的履历，准备好为您的雇主展现潜力无穷的你吧！
如果您不清楚如何写一份履历，或者任何描述自己，请现在就开始学习吧。
8. 量力而行
选择适合个人能力的任务。
您可以通过不同的方式来构建未来的职业生涯。在 W3School 学习是件容易的事情。而获得硕士学位则会困难一些。
您可以通过学习各类型的书籍和教程（比如您在 W3School 所找到的）来为职业添砖加瓦。参加一些带有认证测试的短期培训应该可以为您的履历增加不少分量。同时不要忘了：培养新技术所需要的最具价值的资源是您目前从事的工作。
不要为自己设置不可能完成的任务！
9. 实现您的梦想
把梦想落实为行动！
不要让繁忙的工作扼杀您的梦想。假如您有着更高远的目标，请现在就付诸行动吧！
如果您计划接受更高的教育，获得更好的工作，或者开一间属于自己的公司等等，请不要以日常的工作作为等待的借口。您的日常工作会变得越来越忙，您会陷入激烈的竞争中，并耗尽自己的能量。
如果您此刻就存有能量，那么现在就使用它去实现您的梦想吧！
* 

## 职业履历（CV）
职业履历（CV）
* 
履历（CV）是向雇主推销自己的“广告”。
什么是 CV ？
* CV 指的是 "Curriculum Vitae"
* Curriculum vitae 在拉丁语中的意思是“生命的故事”
* CV 经常被称为 "Resume"
一份 CV 中包含哪些内容？
一份 CV 至少要包含下列内容：
* 个人信息
* 工作经历
* 技能
* 教育水平
* 个人简介和兴趣
* 推荐
您的个人信息
个人信息应该包括姓名、住址、电话和电子邮件。我建议您把这些信息放到 CV 的顶部，让它看上去像信笺的抬头。
您的工作经历
列出你做过的工作 - 在开头列出您最近的工作经历。
以及简短的工作描述和您的职责。
确保工作经历位于 CV 的第一页。这些些信息概括了您的技能和优势。其它附加的信息应当位于后面的位置。
您的技能
技能最好使用列表来描述。
列出您的技能 - 最重要的和最相关的。
您的教育水平
教育最好使用列表来描述。
列出您学习的内容 - 在开头列出您最近所受的教育。
不要忘记学科选项、特殊的项目、课程或者荣誉证书。
您的推荐
列出一些人的名字 - 比如您学习所在学校的教授、公司的主管 - 确保可以很容易地联系到他们，并且他们愿意为你作积极的推荐。
您的个人简介
个人简介应包括有关年龄、兴趣爱好以及其它相关信息的的附加信息，且这些信息有助于塑造您的正面形象。我建议您把这些内容放到 CV 的最后。
由于这些内容可以展现您的特质，所以雇主会有兴趣了解这些内容。但需要小心，不要过度地描述您的兴趣，也不要描述那些可能影响到工作的兴趣。假设您正在为一个足球队作教练，不要写赢得比赛的次数。如果他们感兴趣的话，让他们在以后的面试中与您聊这些好了。


## 作为面试官可问的非技术问题
1. 先自我介绍一下；
2. 对未来有什么规划；
3. 说说你的优缺点；
4. 认为自己是一个怎样性格的人；
5. 平时的爱好；
6. 你能给公司带来什么；
7. 为什么从上家公司离职；
8. 你的期望薪资是多少；
9. 为什么选择我们公司；
10. 你还有什么问题吗。


实时同步用的什么工具
集群规模
有做过业务相关的flink开发吗
平台组件是什么样的




1、
您好！我叫李继聪。我是湖北人，15年毕业来到上海，待过3家公司，属于比较稳定的员工，而且都是做大数据开发，第一家公司是齐家网，做互联网家装的，属于这个领域头部，待了2年，后来去了中通快递半年，又跟着领导回到齐家网，又待了2年，现在这份工作是锅圈供应链，接近2年时间。你看我的简历上写的技能，比较多和杂，大概就知道我是个热爱编程技术的人，我认为我工作上最大的优点是善于解决程序问题，经常有时候开发资历比我老得多的同事，解决不了的问题，我能解决。另外我觉得我性格还挺好和同事相处的。介绍完毕


2、
积累大数据方面的技术经验，成为大数据专家，可以独立承接项目

3、
就是比较擅长解决技术问题，而且锲而不舍，就是遇到很紧急的问题，不吃饭不睡觉也要解决
确定是不善于表达

4、
不喜欢勾心斗角，待朋友真诚，另外自认为比较敬业，对工作尽职尽责

5、
喜欢爬山，运动，释放压力，有那么一点点文艺，比较喜欢电影和看书

6、
兢兢业业，保质保量的完成领导安排的工作，问心无愧对得起工资

7、
目前这家工作待了近2年，公司在虹桥商务区，环境还是挺好的，公司业务也一直在增长，本没有离职打算，想来贵公司是因为前同事介绍推荐，而且有一点比较吸引我，就是相对自由，可以远程办公，毕竟来上海6,7年，一直在外，很少回家，后面想稍微自由一点，偶尔想回家可以回个家几天

8、
贵公司的工资构成，五险一金如何缴纳，希望能有个20%的增幅

9、
如7

10
公司规模，办公方式，负责事项，公司福利

## flink数据延迟的怎么处理
flink数据延迟的怎么处理



kafka配置了几个分区，多个分区会产生什么问题（数据乱序，在源头把同一个数据发到同一分区）
加水印为什么可以解决乱序

数据延迟（加水印）


同一笔订单有多条数据，如何计算金额
21. HashMap 和 Hashtable 有什么区别？

* 存储：HashMap 允许 key 和 value 为 null，而 Hashtable 不允许。
* 线程安全：Hashtable 是线程安全的，而 HashMap 是非线程安全的。
* 推荐使用：在 Hashtable 的类注释可以看到，Hashtable 是保留类不建议使用，推荐在单线程环境下使用 HashMap 替代，如果需要多线程使用则用 ConcurrentHashMap 替代。


背压

如果一个 Subtask 的发送端 Buffer 占用率很高，则表明它被下游反压限速了；如果一个 Subtask 的接受端 Buffer 占用很高，则表明它将反压传导至上游。

## spark特点

spark特点：
1、运行速度快
2、 容易使用
3、 通用性
4、 支持实时

* spark:
join 实现有几种呢，源码有研究过吗？底层是怎么实现的
没有研究过，平时上班太忙，我对这个挺感兴趣的，我希望后面有机会研究

* shuffle形式有几种？都做哪些优化
* 是通过什么管理shuffle中的内存，磁盘的
* 讲讲spark内存模型？说说你了解这些，对实际的工作有什么帮助？
* rdd有哪些特性？
高效的容错性
中间结果持久化到内存
存放的数据可以是Java对象，不必序列化和反序列化

* 讲讲spark的高可用和高容错
* 宽依赖，窄依赖都是什么？有什么不同？除了大家都认为的不同点以外，还有哪些不同？
* sql运行过程
* full outer join原理
* spark为什么比hive快
* 讲讲sparksql优化
* 讲讲RDD, DAG, Stage
RDD：是弹性分布式数据集（Resilient Distributed Dataset）的简称，是分布式内存的一个抽象概念，
DAG：是Directed Acyclic Graph（有向无环图）的简称，反映RDD之间的依赖关系；
Stage：Stage是每一个job处理过程要分为的几个阶段。 Stage的数量是由输入文件的切片个数来决定的，
Executor：是运行在工作节点（Worker Node）上的一个进程，负责运行任务，并为应用程序存储数据；
* 说说groupByKey, reduceByKey
groupByKey不能自定义函数，能现在本地进行合并操作，减少了磁盘io和网络io，性能更好
reduceByKey 可以自定义函数
* spark是怎么读取文件的？
spark支持读本地文件，也支持读hdfs文件
* 有没有遇到过spark读取文件，有一些task空跑的现象？
* 窗口函数中几个rank函数有啥不同
* parquet文件和orc文件有啥不同
Spark运行基本流程
首先提交spark应用，任务控制节点driver和资源管理器进行通信，申请资源，资源管理器分配资源，启动执行进程，最终将结果反馈给调度器，运行完毕写入数据并释放资源


* hive
mr shuffle 是什么样子？具体原理是什么？为什么要排序？
* mr map，reduce数量都什么相关
* hdfs存放副本的算法是什么样的？
* 讲讲hive sql优化
hive数据倾斜参数原理及解决方案
* sql
* 花样写sql，跟实际业务有关的
* 一般情况下，写出一个，然后，他就会问还有没有更优化的方式？
* 窗口函数，groupingsets cube这些都会用到。有好多是计算滑动的那种
* 这个sql 在hive中起几个job，为什么是这么几个job？
* 建模
方法论，数据仓库怎么构建？你是怎么分主题域的？对现在的业务有什么看法？现在的仓库是个什么情况，各个分层有什么特点？为什么这么分？
* 讲讲三范式
* 拉链表，缓慢变化维
* 给你一个新业务，怎么开展？
* 数据治理
数据质量，口径一致
* 基础
* 谈对jvm的理解
* 链表删除算法
* 排序算法
* Btree简单讲讲
B树（英语：B-tree）是一种自平衡的树，能够保持数据有序。这种数据结构能够让查找数据、顺序访问、插入数据及删除的动作，都在对数时间内完成。B树，概括来说是一个一般化的二叉查找树（binary search tree）一个节点可以拥有2个以上的子节点。与自平衡二叉查找树不同，B树适用于读写相对大的数据块的存储系统，例如磁盘。B树减少定位记录时所经历的中间过程，从而加快存取速度。B树这种数据结构可以用来描述外部存储。这种数据结构常被应用在数据库和文件系统的实现上。
* 项目
* 说说项目中你做的比较有价值的东西
简历中几个项目，我认为最有价值的是开发了搜索，相关阅读，内容标签，个性化推荐等接口，pc，m站，app，小程序的文章，帖子，图片，问答等内容全走我这边的接口，对于结果要求准确，定制性较强的学前走自己的切词程序和算法，缺点是开发和维护，扩展性稍微差点。否则用es实现，从拉取数据到开发完接口，一般一天就可以实现，当然再加一些联调的时间，产品就可以上线。
* 你做过印象最深刻的项目，为什么？你在中承担什么角色，发挥了什么作用？还可以优化吗？
影响中最深的是做APP首页个性化推荐，除了一些算法和模型训练代码，其他代码都是我写的，代码量约占90%。印象深刻一是时间比较长，第一版开发到上线大约3个月，持续不断的优化升级了接近一年；二是个性化推荐是非常复杂的，有接近10种召回方法，ABtest了6种排序算法，要分析用户，要提升点击率。三是代码量多，数据量大，机器资源有限，要设计合适的架构，保证接口性能，还要保证数据更新的性能。所以挑战还是蛮大的。代码、架构方面，已经花了大半年的时间优化，所以已经稳定，性能在200毫秒左右。



DataFrame与RDD的区别

RDD是分布式的 Java对象的集合
DataFrame分布式数据集
