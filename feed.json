{
  "version": "https://jsonfeed.org/version/1.1",
  "title": "此在笔记",
  "home_page_url": "https://blog.cizai.io/",
  "feed_url": "https://blog.cizai.io/feed.json",
  "description": "开源工具、效率方法、心理学探索的自我提升笔记 ，记录并输出一切能让自己提升的知识。",
  "items": [
    {
      "title": "内网穿透",
      "url": "https://blog.cizai.io/%E7%BC%96%E7%A8%8B/%E5%B7%A5%E5%85%B7/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F.html",
      "id": "https://blog.cizai.io/%E7%BC%96%E7%A8%8B/%E5%B7%A5%E5%85%B7/%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F.html",
      "summary": "内网穿透 serveo ssh -R 80:localhost:3000 serveo.net ngrok 启动时需要验证 ngrok http 3000 localtunnel 访问时需要验证",
      "content_html": "\n<h2>serveo</h2>\n<p>ssh -R 80:localhost:3000 serveo.net</p>\n<h2>ngrok</h2>\n<h3>启动时需要验证</h3>\n<p>ngrok http 3000</p>\n<h2>localtunnel</h2>\n<h3>访问时需要验证</h3>\n<div class=\"language-bash\" data-ext=\"sh\" data-title=\"sh\"><pre class=\"language-bash\"><code>快速开始\nnpx localtunnel <span class=\"token parameter variable\">--subdomain</span> cizai <span class=\"token parameter variable\">--port</span> <span class=\"token number\">3000</span>\n\n全局安装\n<span class=\"token function\">npm</span> <span class=\"token function\">install</span> <span class=\"token parameter variable\">-g</span> localtunnel\nlt <span class=\"token parameter variable\">--port</span> <span class=\"token number\">3000</span>\n\n自定义个性前缀\nlt <span class=\"token parameter variable\">--subdomain</span> <span class=\"token operator\">&lt;</span>个性前缀<span class=\"token operator\">&gt;</span> <span class=\"token parameter variable\">--port</span> <span class=\"token operator\">&lt;</span>要映射的端口<span class=\"token operator\">&gt;</span>\n\n<span class=\"token comment\"># 获取访问密码</span>\n<span class=\"token function\">wget</span> <span class=\"token parameter variable\">-q</span> <span class=\"token parameter variable\">-O</span> - https://loca.lt/mytunnelpassword\n\n</code></pre></div>",
      "date_published": "2024-04-02T00:00:00.000Z",
      "date_modified": "2024-04-02T07:47:11.000Z",
      "authors": [],
      "tags": [
        "工具"
      ]
    },
    {
      "title": "关于本站",
      "url": "https://blog.cizai.io/%E5%85%B3%E4%BA%8E%E6%9C%AC%E7%AB%99.html",
      "id": "https://blog.cizai.io/%E5%85%B3%E4%BA%8E%E6%9C%AC%E7%AB%99.html",
      "summary": "关于本站 一个全栈开发者，从事大数据开发。 本站桌面端安装包，支持windows，linux，mac。下载地址",
      "content_html": "\n<p>一个全栈开发者，从事大数据开发。</p>\n<p>本站桌面端安装包，支持windows，linux，mac。<a href=\"https://file.cizai.io/wooapp.json\" target=\"_blank\" rel=\"noopener noreferrer\">下载地址</a></p>\n",
      "image": "https://blog.cizai.io/assets/images/cover3.jpg",
      "date_published": "2024-03-17T17:45:45.000Z",
      "date_modified": "2024-03-17T17:45:45.000Z",
      "authors": [],
      "tags": []
    },
    {
      "title": "站点收藏",
      "url": "https://blog.cizai.io/%E7%AB%99%E7%82%B9%E6%94%B6%E8%97%8F.html",
      "id": "https://blog.cizai.io/%E7%AB%99%E7%82%B9%E6%94%B6%E8%97%8F.html",
      "summary": "站点收藏 白噪音 独立博客列表",
      "content_html": "\n<h2>白噪音</h2>\n<p>| 简介   | 网址                      |\n| :</p>\n",
      "date_published": "2022-01-01T00:00:00.000Z",
      "date_modified": "2024-03-17T17:45:45.000Z",
      "authors": [],
      "tags": [
        "站点收藏"
      ]
    },
    {
      "title": "订阅说明",
      "url": "https://blog.cizai.io/%E6%AF%8F%E6%97%A5%E6%82%A6%E8%AF%BB/",
      "id": "https://blog.cizai.io/%E6%AF%8F%E6%97%A5%E6%82%A6%E8%AF%BB/",
      "summary": "订阅说明 实现原理 使用ttrss.py启动订阅服务接口，使用rsshub订阅插件，将Tiny Tiny RSS地址改为订阅接口地址，即可直接订阅网站，存入rss.csv。 定时执行write2csv.py，抓取网络上的订阅地址，存入rss.csv。 定时执行write2md.py，读取rss.csv，获取今日新增文章，写入md文档，提交git，自动显...",
      "content_html": "\n<h2>实现原理</h2>\n<p>使用ttrss.py启动订阅服务接口，使用rsshub订阅插件，将Tiny Tiny RSS地址改为订阅接口地址，即可直接订阅网站，存入rss.csv。</p>\n<p>定时执行write2csv.py<span></span>，抓取网络上的订阅地址，存入rss.csv。</p>\n<p>定时执行write2md.py<span></span>，读取rss.csv，获取今日新增文章，写入md文档，提交git，自动显示在每日悦读。</p>\n<p>参考代码：\nhttps://github.com/lijc210/lijc210.github.io/blob/main/write2md.py</p>\n",
      "date_published": "2023-06-15T00:00:00.000Z",
      "date_modified": "2024-03-17T17:45:45.000Z",
      "authors": [],
      "tags": [
        "每日悦读"
      ]
    },
    {
      "title": "订阅说明",
      "url": "https://blog.cizai.io/%E6%AF%8F%E6%97%A5%E6%82%A6%E8%AF%BB/%E8%AE%A2%E9%98%85%E8%AF%B4%E6%98%8E.html",
      "id": "https://blog.cizai.io/%E6%AF%8F%E6%97%A5%E6%82%A6%E8%AF%BB/%E8%AE%A2%E9%98%85%E8%AF%B4%E6%98%8E.html",
      "summary": "订阅说明 实现原理 使用ttrss.py启动订阅服务接口，使用rsshub订阅插件，将Tiny Tiny RSS地址改为订阅接口地址，即可直接订阅网站，存入rss.csv。 定时执行write2csv.py，抓取网络上的订阅地址，存入rss.csv。 定时执行write2md.py，读取rss.csv，获取今日新增文章，写入md文档，提交git，自动显...",
      "content_html": "\n<h2>实现原理</h2>\n<p>使用ttrss.py启动订阅服务接口，使用rsshub订阅插件，将Tiny Tiny RSS地址改为订阅接口地址，即可直接订阅网站，存入rss.csv。</p>\n<p>定时执行write2csv.py<span></span>，抓取网络上的订阅地址，存入rss.csv。</p>\n<p>定时执行write2md.py<span></span>，读取rss.csv，获取今日新增文章，写入md文档，提交git，自动显示在每日悦读。</p>\n<p>参考代码：\nhttps://github.com/lijc210/lijc210.github.io/blob/main/write2md.py</p>\n",
      "date_published": "2023-06-15T00:00:00.000Z",
      "date_modified": "2024-03-17T17:45:45.000Z",
      "authors": [],
      "tags": [
        "每日悦读"
      ]
    },
    {
      "title": "Impala",
      "url": "https://blog.cizai.io/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E5%BA%93/Impala.html",
      "id": "https://blog.cizai.io/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E5%BA%93/Impala.html",
      "summary": "Impala Impala时间戳分组",
      "content_html": "\n<h2>Impala时间戳分组</h2>\n<div class=\"language-text\" data-ext=\"text\" data-title=\"text\"><pre class=\"language-text\"><code>select   \nfrom_unixtime(cast(siyu_add_time/1000 as int) , 'yyyy-MM-dd') as sdate,\ncount(1),\ncount(if(second_id is null,1,null))\nfrom users \n-- 2023-06-14 00:00:00\nwhere siyu_add_time &gt; 1686672000000\ngroup by from_unixtime(cast(siyu_add_time/1000 as int) , 'yyyy-MM-dd')\norder by from_unixtime(cast(siyu_add_time/1000 as int) , 'yyyy-MM-dd') desc\n</code></pre></div>",
      "date_published": "2022-01-01T00:00:00.000Z",
      "date_modified": "2024-03-17T17:45:45.000Z",
      "authors": [],
      "tags": [
        "数据库"
      ]
    },
    {
      "title": "clickhouse",
      "url": "https://blog.cizai.io/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E5%BA%93/clickhouse.html",
      "id": "https://blog.cizai.io/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E5%BA%93/clickhouse.html",
      "summary": "clickhouse clickhouse 常用命令 clickhouse表引擎 clickhouse性能优化 数据类型 建表时能用数值型或日期时间型表示的字段，就不要用字符串——全String类型在以Hive为中心的数仓建设中常见，但CK环境不应受此影响。 虽然clickhouse底层将DateTime存储为时间戳Long类型，但不建议直接存储Lon...",
      "content_html": "\n<h2>clickhouse 常用命令</h2>\n<div class=\"language-text\" data-ext=\"text\" data-title=\"text\"><pre class=\"language-text\"><code>更新数据\nALTER table ads_sales_item_shop_di_replica ON CLUSTER ck_cluster1 update item_no='' where item_no is null;\nALTER table ads_sales_item_shop_di_replica ON CLUSTER ck_cluster1 update store_shop_code='' where store_shop_code is null;\nALTER table ads_sales_item_shop_di_replica ON CLUSTER ck_cluster1 update unify_goods_code='' where unify_goods_code is null;\n\n\n重命名表\nRENAME TABLE table_A TO table_A_bak, table_B TO table_B_bak;\n\n\n\n查看所有表\nselect *\nFROM system.tables t WHERE database ='ads' AND engine &lt;&gt;'Distributed' ORDER by total_rows DESC \n\n\nselect *\nFROM system.tables t WHERE database ='ads'\nAND engine &lt;&gt;'Distributed'\nand name not like '%del%'\nand name not like '%20%'\nORDER by total_rows DESC\n\n\n\n自动清理query_log，query_thread_log，trace_log\n\nALTER TABLE system.query_log on cluster ck_cluster1 MODIFY TTL event_date + INTERVAL 15 DAY\n\nALTER TABLE system.query_thread_log on cluster ck_cluster1 MODIFY TTL event_date + INTERVAL 15 DAY\n\nALTER TABLE system.trace_log on cluster ck_cluster1 MODIFY TTL event_date + INTERVAL 15 DAY\n\n立即清理\nalter table system.query_thread_log_0 drop partition '202105'\n分区名可以用下语句查询\nselect * from system.parts p where table = '表名'\n\n查看parts  \nselect * from system.parts  where table = 'abs_activity_item_info_day_replica'\nselect * from system.parts where active = 0\n当前慢查询\nSELECT * FROM system.processes limit 100\n\n耗时大于60秒\nkill query where elapsed &gt;= 60\n\nclickhouse不能创建等执行操作时（每个节点都要执行）\nselect * from system.mutations where is_done = 0;\nkill mutation ON CLUSTER ck_cluster1 \n where database='ads' and table='ads_jd_erp_sale_outstock_replica' \n\n\n进入zk清理任务\ndeleteall /clickhouse/distributed_ddl/query-0000011932\n查询阻塞的任务\nselect * from system.distributed_ddl_queue where status != 'Finished'\n\n\n查看表大小\nSELECT\n    table AS `表名`,\n    sum(rows) AS `总行数`,\n    formatReadableSize(sum(data_uncompressed_bytes)) AS `原始大小`,\n    formatReadableSize(sum(data_compressed_bytes)) AS `压缩大小`,\n    round((sum(data_compressed_bytes) / sum(data_uncompressed_bytes)) * 100, 0) AS `压缩率`\nFROM system.parts\nGROUP BY table\norder by sum(data_compressed_bytes) desc\n\n\n修改字段名\nALTER TABLE visits RENAME COLUMN webBrowser TO browser\n分布式集群下用分布式DDL修改字段名\nALTER TABLE visits on cluster shipin_cluster RENAME COLUMN webBrowser TO browser\n\n\n新增字段\n alter table ads_itemprice_sales_section_replica ON CLUSTER ck_cluster1 add column sort_mark Nullable(int)\n alter table ads_itemprice_sales_section ON CLUSTER ck_cluster1 add column sort_mark Nullable(int)\n</code></pre></div><h2>clickhouse表引擎</h2>\n<p>| 系列        | 引擎                         | 特点                                                                                                                                                                                                                                    | 场景                                                                                     |\n|</p>\n",
      "date_published": "2022-01-01T00:00:00.000Z",
      "date_modified": "2024-03-17T17:45:45.000Z",
      "authors": [],
      "tags": [
        "数据库"
      ]
    },
    {
      "title": "elasticsearch",
      "url": "https://blog.cizai.io/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E5%BA%93/elasticsearch.html",
      "id": "https://blog.cizai.io/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E5%BA%93/elasticsearch.html",
      "summary": "elasticsearch 查看集群状态，修复 记录慢日志，重启也生效 记录慢查询日志 批量按条件更新 搜索词分权重 统一更改刷新时间 优化性能 索引复制数据 暂时移除一个节点 搜索结果返回不一致问题 一、背景 这周在使用Elasticsearch搜索的时候遇到一个，对于同一个搜索请求，会出现top50返回结果和排序不一致的问题。那么为什么会出现这样的...",
      "content_html": "\n<h2>查看集群状态，修复</h2>\n<div class=\"language-text\" data-ext=\"text\" data-title=\"text\"><pre class=\"language-text\"><code>GET _cluster/allocation/explain?pretty\n\nGET /_cluster/allocation/explain\n\nget /_cluster/settings\n\nPUT /_cluster/settings\n{\n  \"transient\": {\n    \"cluster.routing.allocation.enable\": \"none\"\n  }\n}\n#分片配置\n\nPUT /_cluster/settings\n{\n  \"transient\": {\n    \"cluster.routing.allocation.enable\": \"all\"\n  }\n}\n\n#分片重新均衡分配\n\nPUT /_cluster/settings\n{\n  \"transient\": {\n    \"cluster.routing.rebalance.enable\": \"all\"\n  }\n}\n\n# 设置副本数量\nPUT /aabb/_settings\n{\n\"number_of_replicas\" : 2\n}\n\nget _cluster/health?level=indices\n\n\nGET _cat/nodes?v&amp;h=ip,heap.current,heap.percent,heap.max,ram.max,disk.avail,node.role,m\n\ncurl http://localhost:9200/_cat/nodes?v&amp;h=ip,heap.current,heap.percent,heap.max,ram.max,disk.avail,node.role,m\n\nget _cat/master\n\npost /_cluster/reroute\n{\n  \"commands\": [\n    {\n      \"allocate_empty_primary\": {\n        \"index\": \"wap_yonghu_v1\",\n        \"shard\": 2,\n        \"node\": \"Ee6ubnnmT52LJchcw0P-pQ\",\n        \"accept_data_loss\": false\n      }\n    }\n  ]\n}\n\n\n#数据丢失\npost /_cluster/reroute\n{\n\"commands\": [\n{\n\"allocate_empty_primary\": {\n\"index\": \"aabb_v2\",\n\"shard\": 0,\n\"node\": \"Ee6ubnnmT52LJchcw0P-pQ\",\n\"accept_data_loss\": true\n}\n}\n]\n}\n\n#数据不丢失\npost /_cluster/reroute\n{\n\"commands\" : [ {\n\"allocate_stale_primary\" : {\n\"index\" : \"aabb_v2\",\n\"shard\" :0,\n\"node\" : \"Ee6ubnnmT52LJchcw0P-pQ\",\n\"accept_data_loss\" : true\n}\n}]\n}\n\n\nPOST /_cluster/reroute?retry_failed=true\n\n\n手动迁移分片\nPOST /_cluster/reroute\n{\n  \"commands\": [\n    {\n      \"move\": {\n        \"index\": \"aabb_v1\",\n        \"shard\": 1,\n        \"from_node\": \"10.10.20.143\",\n        \"to_node\": \"10.10.20.153\"\n      }\n    }\n  ]\n}\n\n</code></pre></div><h2>记录慢日志，重启也生效</h2>\n<div class=\"language-text\" data-ext=\"text\" data-title=\"text\"><pre class=\"language-text\"><code>PUT /_settings\n{\n\"index.search.slowlog.level\": \"trace\",            \n\"index.search.slowlog.threshold.query.warn\": \"10s\",  \n\"index.search.slowlog.threshold.query.info\": \"5s\",  \n\"index.search.slowlog.threshold.query.debug\": \"2s\",  \n\"index.search.slowlog.threshold.query.trace\": \"500ms\"\n}\n</code></pre></div><h2>记录慢查询日志</h2>\n<div class=\"language-text\" data-ext=\"text\" data-title=\"text\"><pre class=\"language-text\"><code>curl -XPUT 'http://localhost:9200/_all/_settings?preserve_existing=true' -d '{\n  \"index.indexing.slowlog.threshold.index.debug\" : \"500ms\",\n  \"index.indexing.slowlog.threshold.index.info\" : \"2s\",\n  \"index.indexing.slowlog.threshold.index.warn\" : \"5s\",\n  \"index.search.slowlog.threshold.fetch.debug\" : \"500ms\",\n  \"index.search.slowlog.threshold.fetch.info\" : \"2s\",\n  \"index.search.slowlog.threshold.fetch.warn\" : \"5s\",\n  \"index.search.slowlog.threshold.query.debug\" : \"500ms\",\n  \"index.search.slowlog.threshold.query.info\" : \"2s\",\n  \"index.search.slowlog.threshold.query.warn\" : \"5s\"\n}'\n</code></pre></div><h2>批量按条件更新</h2>\n<div class=\"language-text\" data-ext=\"text\" data-title=\"text\"><pre class=\"language-text\"><code>POST pyspider/result/_update_by_query\n{\n  \"script\": {\n    \"inline\": \"ctx._source.result.company_list=0;\"\n  },\n  \"query\": {\n    \"term\": {\n      \"_id\": {\n        \"value\": \"qichacha:ecde53ee4b22383478536ee7d976046b\"\n      }\n    }\n  }\n}\n</code></pre></div><h2>搜索词分权重</h2>\n<div class=\"language-text\" data-ext=\"text\" data-title=\"text\"><pre class=\"language-text\"><code>post aabb/v9_news/_search\n{\n\"query\": {\n\"bool\": {\n\"must\": {\n\"multi_match\": {\n\"query\": \"温馨的客厅\",\n\"fields\": [\n\"title\"\n]\n}\n},\n\"should\": [\n{\n\"match\": {\n\"title\": {\n\"query\": \"客厅\",\n\"boost\": 4\n}\n}\n},\n{\n\"match\": {\n\"title\": {\n\"query\": \"温馨\",\n\"boost\": 2\n}\n}\n}\n]\n}\n},\"_source\":[\"title\",\"create_time\"]\n,\"size\": 50\n}\n</code></pre></div><h2>统一更改刷新时间</h2>\n<div class=\"language-text\" data-ext=\"text\" data-title=\"text\"><pre class=\"language-text\"><code>curl -XPUT 'http://10.10.20.165:9200/_all/_settings?preserve_existing=true' -d '{\n  \"index.refresh_interval\" : \"15s\"\n}'\n</code></pre></div><h2>优化性能</h2>\n<div class=\"language-text\" data-ext=\"text\" data-title=\"text\"><pre class=\"language-text\"><code>GET _nodes/hot_threads?pretty\n\n\nPUT /aabb/_settings\n{\n    \"index\":{\n        \"refresh_interval\":\"30s\",\n        \"translog\":{\n            \"flush_threshold_size\":\"2048m\",\n            \"sync_interval\":\"120s\",\n            \"durability\":\"async\"\n        },\n        \"merge\":{\n            \"policy.max_merge_at_once\":5,\n            \"policy.max_merge_at_once_explicit\":15,\n            \"policy.floor_segment\":\"1mb\",\n            \"scheduler.max_thread_count\":\"1\"\n        }\n    }\n}\n\n\nPUT /uc/_settings\n{\n    \"index\":{\n        \"refresh_interval\":\"-1\"\n        }\n}\n</code></pre></div><h2>索引复制数据</h2>\n<div class=\"language-text\" data-ext=\"text\" data-title=\"text\"><pre class=\"language-text\"><code>http://localhost:9200/_reindex\n{\n    \"source\":{\n        \"index\":\"old_index\"\n    },\n    \"dest\":{\n        \"index\":\"new_index\",\n        \"op_type\":\"create\"\n    }\n}\nhttp://localhost:9200/_reindex\n{\n    \"source\":{\n        \"index\":\"cut_word_data_v1\"\n    },\n    \"dest\":{\n        \"index\":\"cut_word_data_v2\",\n        \"op_type\":\"create\"\n    }\n}\ncurl -l -H \"Content-type: application/json\" -d '{\"source\":{\"index\":\"crm-address_v2\"},\"dest\":{\"index\":\"crm-address_v1\",\"op_type\":\"create\" }}'  http://localhost:9200/_reindex\n\n\ncurl -l -H \"Content-type: application/json\" -d '{\"source\":{\"index\":\"aabb_v1\"},\"dest\":{\"index\":\"aabb_v2\",\"op_type\":\"create\" }}'  http://localhost:9200/_reindex\n\n\ncurl -l -H \"Content-type: application/json\" -d '{\"source\":{\"index\":\"wap_anli_v2\"},\"dest\":{\"index\":\"wap_anli_v1\",\"op_type\":\"create\" }}'  http://localhost:9200/_reindex\n\n\ncurl -l -H \"Content-type: application/json\" -d '{\"source\":{\"remote\":{\"host\":\"http://10.10.20.33:9200\"},\"index\":\"kn2_es_v1\"},\"dest\":{\"index\":\"kn2_es_v1\",\"op_type\":\"create\"}}'  http://localhost:9200/_reindex\n\ncurl -l -H \"Content-type: application/json\" -d '{\"source\":{\"remote\":{\"host\":\"http://10.10.20.33:9200\"},\"index\":\"pyspider\"},\"dest\":{\"index\":\"pyspider_v1\",\"op_type\":\"create\"}}'  http://localhost:9200/_reindex\n\n\nhttp://localhost:9200/_reindex\n{\n    \"source\":{\n        \"index\":\"kn2_es_v1\"\n    },\n    \"dest\":{\n        \"index\":\"kn2_es_v2\",\n        \"op_type\":\"create\"\n    }\n}\n\n\n远程复制：\n\nPOST _reindex\n{\n    \"source\":{\n        \"remote\":{\n            \"host\":\"http://10.10.20.33:9200\"\n        },\n        \"index\":\"test1\"\n    },\n    \"dest\":{\n        \"index\":\"test2\",\n        \"op_type\":\"create\"\n    }\n}\n</code></pre></div><h2>暂时移除一个节点</h2>\n<div class=\"language-text\" data-ext=\"text\" data-title=\"text\"><pre class=\"language-text\"><code>\n下线：\nPUT _cluster/settings\n{\n\"transient\" : {\n\"cluster.routing.allocation.exclude._name\" : \"node-2\"\n}\n}\n注意 这个操作是transient集群重启后，这个设置会失效\n\n\n\n上线\nPUT _cluster/settings\n{\n\"transient\" : {\n\"cluster.routing.allocation.exclude._name\" : \"\"\n}\n}\n只要让_name匹配不到对用的node即可\n</code></pre></div><h2>搜索结果返回不一致问题</h2>\n<p>一、背景</p>\n<p>这周在使用Elasticsearch搜索的时候遇到一个，对于同一个搜索请求，会出现top50返回结果和排序不一致的问题。那么为什么会出现这样的问题？\n后来通过百度和google，发现这是因为Elastcisearch的分布式搜索特性导致。Elasticsearch在搜索时，会循环的选择主分片和其副本中的一个来计算和返回搜索结果，而由于主分片和副本中相关统计信息的不同，从而导致了同一个搜索串的评分的不一致，进而导致排序不一样。而造成这种主分片和副本统计信息不一致的具体原因，是因为文档删除时造成的，具体可以参考官方给出的解释：https://www.elastic.co/guide/en/elasticsearch/reference/current/consistent-scoring.html\n二、解决办法\n针对上述问题，Elasticsearch官方也给出了解决方案（https://www.elastic.co/guide/en/elasticsearch/guide/2.x/_search_options.html#_preference），即在搜索时设置preference特性。如下：\nSearchRequestBuilder builder = client.prepareSearch(offLin.index)\n.setTypes(offLin.type)\n.setQuery(queryBuilder)\n.setFetchSource(fetchFields, null)\n.setSize(limit)\n.setPreference(\"_primary_first\");\n那么preference可以取哪些值，每个值的含义是什么呢，可以参考下面解释：\n（1）randomizeacross shards：随机选择分片或其副本查询数据，es的默认方式。\n（2）_local：优先在本地节点上的分片查询数据然后再去其他节点上的分片查询，本地节点没有IO问题但有可能造成负载不均问题。\n（3）_primary：搜索只在主分片执行搜索请求，副本不参与搜索；性能会打折扣，达不到性能的水平扩展。\n（4）_primary_first：优先在主分片执行，如果主分片挂掉，会在副本执行请求。\n（5）_only_node:123 ：只在123这个节点执行搜索。\n（6）_prefer_node:123：搜索请求优先在节点123执行。\n（7）_shards:1,2：搜索只在分片2、3执行，可以与_primary参数一起使用如：_shards:2,3;_primary\n（8）随机字符串：指定一个随机字符串，可以保证同样的请求，被分配到同样的副本上面，从而保证同一请求结果的稳定性。我遇到的问题就可以使用这种方式，把搜索串的hash值作为随机字符串，这样可以保证同一个搜索条件的请求的返回结果和排序一致。</p>\n",
      "date_published": "2022-01-01T00:00:00.000Z",
      "date_modified": "2024-03-17T17:45:45.000Z",
      "authors": [],
      "tags": [
        "数据库"
      ]
    },
    {
      "title": "guassdb",
      "url": "https://blog.cizai.io/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E5%BA%93/guassdb.html",
      "id": "https://blog.cizai.io/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E5%BA%93/guassdb.html",
      "summary": "guassdb 优化 1、删除表dim_shop_sales_target在字段target_date上的索引（注：列存表非必要无需创建索引，如创建，可选用btree索引，不要创建默认的psort索引，贵司当前列存表上，基本都是psort索引） 2、dim_jd_erp_shop表，建议修改为复制表（数据总量较小的维度表，建议调整为复制表） 自动更新时...",
      "content_html": "\n<h2>优化</h2>\n<ul>\n<li>1、删除表dim_shop_sales_target在字段target_date上的索引（注：列存表非必要无需创建索引，如创建，可选用btree索引，不要创建默认的psort索引，贵司当前列存表上，基本都是psort索引）</li>\n<li>2、dim_jd_erp_shop表，建议修改为复制表（数据总量较小的维度表，建议调整为复制表）</li>\n</ul>\n<div class=\"language-text\" data-ext=\"text\" data-title=\"text\"><pre class=\"language-text\"><code>在各DN的数据分布倾斜\nselect table_skewness('ads_sales_shop_notdis');\n\n</code></pre></div><h2>自动更新时间</h2>\n<div class=\"language-text\" data-ext=\"text\" data-title=\"text\"><pre class=\"language-text\"><code>CREATE TABLE public.ads_order_city_rank (\npkey varchar(50) NOT NULL,\nsdate date NOT NULL,\nshop_code_inner varchar(255) NOT NULL,\nshop_name varchar(200) NULL DEFAULT NULL::character varying,\ncity varchar(200) NULL DEFAULT NULL::character varying,\ncity_rank int4 NOT NULL,\ncity_rank_last float8 NOT NULL,\ncity_rank_first float8 NOT NULL,\navg_city_sales float8 NOT NULL,\ndistance_avg_sales float8 NOT NULL,\ndivided_avg_sales float8 NOT NULL,\ncity_rank_max int4 NOT NULL,\ndistance_max_sales float8 NOT NULL,\ndivided_max_sales float8 NOT NULL,\ncreate_time timestamp NULL DEFAULT now()::timestamp without time zone,\nupdate_time timestamp DEFAULT current_timestamp ON UPDATE current_timestamp,\nCONSTRAINT ads_order_city_rank_pkey PRIMARY KEY (pkey)\n)\nWITH (\norientation=row,\ncompression=no\n);\nCREATE INDEX idx_shop_code_inner ON ads_order_city_rank USING btree (shop_code_inner) TABLESPACE pg_default;\n</code></pre></div><h2>常用命令</h2>\n<p>CREATE TABLE T2\n(\nid   int not null default nextval('seq1'),\nname text\n);</p>\n<p>CREATE SEQUENCE seq1 cache 100;</p>\n<p>查看分布式列的分布\nselect * from table_skewness('public.ads_order_item_sales','shop_code_inner');</p>\n<p>修改分布式列\nALTER TABLE public.ads_order_item_sales DISTRIBUTE BY HASH(shop_code_inner);</p>\n<p>查看分布式列\nselect pg_get_tabledef('ads_order_sales_dws_row')</p>\n<p>查看数据倾斜\nSELECT a.count,b.node_name FROM (SELECT count(*) AS count,xc_node_id FROM ads_order_item_sales GROUP BY xc_node_id) a, pgxc_node b\nWHERE a.xc_node_id=b.node_id ORDER BY a.count desc;</p>\n<p>查看数据倾斜\nSELECT schemaname,tablename,pg_size_pretty(totalsize),skewratio FROM PGXC_GET_TABLE_SKEWNESS WHERE SKEWRATIO &gt; 0.05 ORDER BY TOTALSIZE DESC;</p>\n<p>查看最耗时的10个sql\nSELECT * FROM pgxc_wlm_session_info\nwhere start_time &gt;= '2023-03-26 00:00:00'\nand query not like 'delete%'\nand query not like 'select count%'\nand query not like 'CREATE%'\norder by duration desc limit 10;</p>\n<p>-- 查询指定表占用的磁盘存储空间\nselect pg_size_pretty(pg_relation_size('public.ads_order_sales'));  -- 99 GB\n-- 查询表的脏页率信息\nselect dirty_page_rate from PGXC_GET_STAT_ALL_TABLES where relname = 'ads_order_sales';  -- 64.68\nselect * from PGXC_GET_STAT_ALL_TABLES where dirty_page_rate&gt;30;</p>\n<h2>Clickhouse bitmap用法</h2>\n<p>bitmap主要用于快速去重计算，集合计算，节约空间与时间，典型场景是根据标签来进行用户的圈选。</p>\n<p>简单示例：</p>\n<p>假如有一张用户标签表</p>\n<div class=\"language-text\" data-ext=\"text\" data-title=\"text\"><pre class=\"language-text\"><code>CREATE TABLE tmp.users_table_replica ON CLUSTER ck_cluster1\n(\nuid UInt64,\ntag1 String,\ntag2 String\n)\nENGINE = ReplicatedMergeTree\nORDER BY uid;\n</code></pre></div><p>分布式表</p>\n<div class=\"language-text\" data-ext=\"text\" data-title=\"text\"><pre class=\"language-text\"><code>CREATE TABLE tmp.users_table\nON CLUSTER ck_cluster1\nAS tmp.users_table_replica\nENGINE = Distributed(ck_cluster1, tmp, users_table_replica, rand())\n</code></pre></div><p>写入测试数据</p>\n<div class=\"language-text\" data-ext=\"text\" data-title=\"text\"><pre class=\"language-text\"><code>insert into tmp.users_table (uid, tag1, tag2) VALUES\n(1, '男','北京'),\n(2, '女','天津'),\n(3, '男','上海'),\n(4, '女','北京')\n</code></pre></div><p>如果大数据量的情况下，clickhouse按任意条件做去重查询效率不高，可使用bitmap</p>\n<div class=\"language-text\" data-ext=\"text\" data-title=\"text\"><pre class=\"language-text\"><code>CREATE TABLE tmp.users_table_bitmap_replica ON CLUSTER ck_cluster1\n\n(\ntag_id String,\nusers AggregateFunction(groupBitmap, UInt64)\n)\nENGINE = ReplicatedMergeTree\nORDER BY tag_id;\n</code></pre></div><p>分布式表</p>\n<div class=\"language-text\" data-ext=\"text\" data-title=\"text\"><pre class=\"language-text\"><code>CREATE TABLE tmp.users_table_bitmap\nON CLUSTER ck_cluster1\nAS tmp.users_table_bitmap_replica\nENGINE = Distributed(ck_cluster1, tmp, users_table_bitmap_replica, rand())\n</code></pre></div><p>写入数据</p>\n<div class=\"language-text\" data-ext=\"text\" data-title=\"text\"><pre class=\"language-text\"><code>insert into tmp.users_table_bitmap select tag1,groupBitmapState(uid) from tmp.users_table group by tag1;\ninsert into tmp.users_table_bitmap select tag2,groupBitmapState(uid) from tmp.users_table group by tag2;\n</code></pre></div><p>查询性别是男的所有用户（只返回uid，需要明细数据还得再关联）</p>\n<div class=\"language-text\" data-ext=\"text\" data-title=\"text\"><pre class=\"language-text\"><code>SELECT bitmapToArray(users) FROM tmp.users_table_bitmap WHERE tag_id = '男';\n</code></pre></div><p>展开成行</p>\n<div class=\"language-text\" data-ext=\"text\" data-title=\"text\"><pre class=\"language-text\"><code>SELECT arrayJoin(bitmapToArray(users)) FROM tmp.users_table_bitmap WHERE tag_id = '男';\n</code></pre></div><p>查询性别是男的用户数</p>\n<div class=\"language-text\" data-ext=\"text\" data-title=\"text\"><pre class=\"language-text\"><code>select bitmapCardinality(users) FROM tmp.users_table_bitmap WHERE tag_id = '男';\n</code></pre></div><p>以上示例还可以如此建表（如果标签是年龄或者是日期，需要做大于小于等计算，则必须如此建表）</p>\n<div class=\"language-text\" data-ext=\"text\" data-title=\"text\"><pre class=\"language-text\"><code>CREATE TABLE tmp.users_table_bitmap_replica1 ON CLUSTER ck_cluster1\n(\ntag1 String,\ntag2 String,\nusers AggregateFunction(groupBitmap, UInt64)\n)\nENGINE = ReplicatedMergeTree\nORDER BY (tag1,tag2);\n</code></pre></div><p>分布式表</p>\n<div class=\"language-text\" data-ext=\"text\" data-title=\"text\"><pre class=\"language-text\"><code>CREATE TABLE tmp.users_table_bitmap1\nON CLUSTER ck_cluster1\nAS tmp.users_table_bitmap_replica1\nENGINE = Distributed(ck_cluster1, tmp, users_table_bitmap_replica1, rand())\n</code></pre></div><p>写入</p>\n<div class=\"language-text\" data-ext=\"text\" data-title=\"text\"><pre class=\"language-text\"><code>insert into tmp.users_table_bitmap1 select tag1,tag2,groupBitmapState(uid) from tmp.users_table group by tag1,tag2;\n</code></pre></div><p>查询性别是男的所有用户</p>\n<div class=\"language-text\" data-ext=\"text\" data-title=\"text\"><pre class=\"language-text\"><code>SELECT tag1,bitmapToArray(users) FROM tmp.users_table_bitmap1 WHERE tag1 = '男';\n</code></pre></div><p>展开成行</p>\n<div class=\"language-text\" data-ext=\"text\" data-title=\"text\"><pre class=\"language-text\"><code>SELECT tag1,arrayJoin(bitmapToArray(users)) FROM tmp.users_table_bitmap1 WHERE tag1 = '男';\n</code></pre></div><p>查询性别是男的用户数（会返回多条数据）</p>\n<div class=\"language-text\" data-ext=\"text\" data-title=\"text\"><pre class=\"language-text\"><code>select tag1,tag2,bitmapCardinality(users) FROM tmp.users_table_bitmap1 WHERE tag1 = '男';\n</code></pre></div><p>查询性别是男的总用户数</p>\n<div class=\"language-text\" data-ext=\"text\" data-title=\"text\"><pre class=\"language-text\"><code>SELECT countDistinct(arrayJoin(bitmapToArray(users))) AS merged_users_count FROM tmp.users_table_bitmap1 WHERE tag1 = '男'\n</code></pre></div><p>如有多张bitmap表可以进行交并计算（要比普通的用户表进行JOIN或者IN计算要高效很多）\nclickhouse同样提供了一系列函数来进行bitmap之间的集合运算，包括并集、交集、差集、补集等。\n具体使用可查阅官方文档：bitmap函数https://clickhouse.com/docs/zh/sql-reference/functions/bitmap-functions/</p>\n<p>arrayJoin                宽表转Bitmap表需要行转列，要用arrayJoin把多列数组炸成行。\nbitmapAnd             求两个Bitmap值的交集\nbitmapOr                求两个Bitmap值的并集\nbitmapXor              求两个Bitmap值的差集(异或)\nbitmapToArray      把Bitmap转换成数值数组\nbitmapToArray      把Bitmap转换成数值数组\nbitmapCardinality 返回一个bitmap数据的个数</p>\n<h3>bitmap性能测试:</h3>\n<p>-- 创建分布式表</p>\n<div class=\"language-text\" data-ext=\"text\" data-title=\"text\"><pre class=\"language-text\"><code>CREATE TABLE tmp.member_order_bitmap_replica ON CLUSTER ck_cluster1\n(\nsdate String,\nstore_shop_code String,\nusers AggregateFunction(groupBitmap, UInt64)\n)\nENGINE = ReplicatedMergeTree\nORDER BY (sdate, store_shop_code);\n</code></pre></div><p>-- 创建分布式表</p>\n<div class=\"language-text\" data-ext=\"text\" data-title=\"text\"><pre class=\"language-text\"><code>CREATE TABLE tmp.member_order_bitmap ON CLUSTER ck_cluster1\nAS tmp.member_order_bitmap_replica\nENGINE = Distributed(ck_cluster1, tmp, member_order_bitmap_replica, rand());\n</code></pre></div><p>-- 插入 6800 万数据（耗时十秒）</p>\n<div class=\"language-text\" data-ext=\"text\" data-title=\"text\"><pre class=\"language-text\"><code>INSERT INTO tmp.member_order_bitmap\nSELECT\nsdate,\nstore_shop_code,\ngroupBitmapState(toUInt64(coalesce(user_id, 0))) AS bitmap_result\nFROM\nbas.abs_member_order_lastyear\nWHERE\nstore_shop_code IS NOT NULL\n-- and sdate &gt;= '2023-10-15'\nGROUP BY\nsdate,\nstore_shop_code;\n</code></pre></div><p>-- 最近一年明细数据量为 3400 万条\n-- 查询最近一年用户明细（耗时442毫秒）</p>\n<div class=\"language-text\" data-ext=\"text\" data-title=\"text\"><pre class=\"language-text\"><code>SELECT sdate, bitmapToArray(users) FROM tmp.member_order_bitmap\nWHERE sdate BETWEEN '2022-11-17' AND '2023-11-17';\n</code></pre></div><p>-- 查询最近一年用户明细（展开成行，耗时382毫秒）</p>\n<div class=\"language-text\" data-ext=\"text\" data-title=\"text\"><pre class=\"language-text\"><code>SELECT sdate, arrayJoin(bitmapToArray(users)) FROM tmp.member_order_bitmap\nWHERE sdate BETWEEN '2022-11-17' AND '2023-11-17';\n</code></pre></div><p>-- 按日期、门店分组查询最近一年用户数（耗时285毫秒）</p>\n<div class=\"language-text\" data-ext=\"text\" data-title=\"text\"><pre class=\"language-text\"><code>SELECT sdate, store_shop_code, bitmapCardinality(users) FROM tmp.member_order_bitmap\nWHERE sdate BETWEEN '2022-11-17' AND '2023-11-17';\n</code></pre></div><p>-- 按日期分组查询最近一年用户数（耗时1.3秒）</p>\n<div class=\"language-text\" data-ext=\"text\" data-title=\"text\"><pre class=\"language-text\"><code>SELECT sdate, countDistinct(arrayJoin(bitmapToArray(users))) AS merged_users_count\nFROM tmp.member_order_bitmap\nWHERE sdate BETWEEN '2022-11-17' AND '2023-11-17'\nGROUP BY sdate;\n</code></pre></div><p>或者（建议用这个，性能更快）</p>\n<div class=\"language-text\" data-ext=\"text\" data-title=\"text\"><pre class=\"language-text\"><code>SELECT sdate, bitmapCardinality(groupBitmapMergeState(users)) AS merged_users_count\n\nFROM tmp.member_order_bitmap\n\nWHERE sdate BETWEEN '2022-11-17' AND '2023-11-17'\n\nGROUP BY sdate;\n</code></pre></div><p>-- 查询最近一年总用户数（耗时2秒）</p>\n<div class=\"language-text\" data-ext=\"text\" data-title=\"text\"><pre class=\"language-text\"><code>SELECT countDistinct(arrayJoin(bitmapToArray(users))) AS merged_users_count\nFROM tmp.member_order_bitmap\nWHERE sdate BETWEEN '2022-11-17' AND '2023-11-17';\n</code></pre></div><p>或者（性能略微快一点）</p>\n<div class=\"language-text\" data-ext=\"text\" data-title=\"text\"><pre class=\"language-text\"><code>select bitmapCardinality(groupBitmapOrState(users)) from(\nselect users from tmp.member_order_bitmap where sdate BETWEEN '2022-11-17' AND '2023-11-17'\n)\n</code></pre></div><p>或者（性能快一倍多）</p>\n<div class=\"language-text\" data-ext=\"text\" data-title=\"text\"><pre class=\"language-text\"><code>select bitmapCardinality(groupBitmapMergeState(users))\nfrom tmp.member_order_bitmap where sdate BETWEEN '2022-11-17' AND '2023-11-17';\n</code></pre></div><p>--查询2022-11-15和2022-11-16连续两天消费的用户数（交集），将bitmapToArray改为bitmapCardinality即返回用户数</p>\n<div class=\"language-text\" data-ext=\"text\" data-title=\"text\"><pre class=\"language-text\"><code>SELECT\nbitmapToArray(bitmapAnd(r1.users_bitmap, r2.users_bitmap)) AS res\nFROM\n(\nSELECT groupBitmapMergeState(users) AS users_bitmap\nFROM tmp.member_order_bitmap\nWHERE sdate = '2023-11-15'\n) AS r1,\n(\nSELECT groupBitmapMergeState(users) AS users_bitmap\nFROM tmp.member_order_bitmap\nWHERE sdate = '2023-11-16'\n) AS r2;\n</code></pre></div>",
      "date_published": "2022-01-01T00:00:00.000Z",
      "date_modified": "2024-03-17T17:45:45.000Z",
      "authors": [],
      "tags": [
        "数据库"
      ]
    },
    {
      "title": "hbase",
      "url": "https://blog.cizai.io/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E5%BA%93/hbase.html",
      "id": "https://blog.cizai.io/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E6%95%B0%E6%8D%AE%E5%BA%93/hbase.html",
      "summary": "hbase HBase 常用Shell命令 hbase scan limit hbase建表 hbase启动命令 https://blog.csdn.net/kelonsen/article/details/78477152",
      "content_html": "\n<h2>HBase 常用Shell命令</h2>\n<p>| hbase shell命令 | 描述                                                                   |\n|</p>\n",
      "date_published": "2022-01-01T00:00:00.000Z",
      "date_modified": "2024-03-17T17:45:45.000Z",
      "authors": [],
      "tags": [
        "数据库"
      ]
    }
  ]
}