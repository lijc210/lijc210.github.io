{
  "version": "https://jsonfeed.org/version/1.1",
  "title": "此在笔记",
  "home_page_url": "https://www.cizai.io/",
  "feed_url": "https://www.cizai.io/feed.json",
  "description": "开源工具、效率方法、心理学探索的自我提升笔记，记录并输出一切能让自己提升的知识。",
  "items": [
    {
      "title": "算法",
      "url": "https://www.cizai.io/%E7%BC%96%E7%A8%8B/%E7%AE%97%E6%B3%95/%E7%AE%97%E6%B3%95.html",
      "id": "https://www.cizai.io/%E7%BC%96%E7%A8%8B/%E7%AE%97%E6%B3%95/%E7%AE%97%E6%B3%95.html",
      "summary": "算法 标题 2 这里是内容。 标题 3 这里是内容。",
      "content_html": "<h1> 算法</h1>\n<h2> 标题 2</h2>\n<p>这里是内容。</p>\n<h3> 标题 3</h3>\n<p>这里是内容。</p>\n",
      "date_published": "2022-01-01T00:00:00.000Z",
      "date_modified": "2023-07-13T06:58:32.000Z",
      "authors": [],
      "tags": [
        "算法"
      ]
    },
    {
      "title": "template",
      "url": "https://www.cizai.io/template.html",
      "id": "https://www.cizai.io/template.html",
      "summary": "template",
      "content_html": "<h1> template</h1>\n",
      "date_published": "2022-01-01T00:00:00.000Z",
      "date_modified": "2023-07-13T07:56:00.000Z",
      "authors": [],
      "tags": [
        "文章"
      ]
    },
    {
      "title": "关于本站",
      "url": "https://www.cizai.io/%E5%85%B3%E4%BA%8E%E6%9C%AC%E7%AB%99.html",
      "id": "https://www.cizai.io/%E5%85%B3%E4%BA%8E%E6%9C%AC%E7%AB%99.html",
      "summary": "关于本站 一个全栈开发者，从事大数据开发。 本站桌面端安装包，支持windows，linux，mac。下载地址",
      "content_html": "<h1> 关于本站</h1>\n<p>一个全栈开发者，从事大数据开发。</p>\n<p>本站桌面端安装包，支持windows，linux，mac。<a href=\"https://file.cizai.io/wooapp.json\" target=\"_blank\" rel=\"noopener noreferrer\">下载地址</a></p>\n",
      "image": "https://www.cizai.io/assets/images/cover3.jpg",
      "date_published": "2023-07-13T03:24:02.000Z",
      "date_modified": "2023-07-13T10:08:29.000Z",
      "authors": [],
      "tags": []
    },
    {
      "title": "站点收藏",
      "url": "https://www.cizai.io/%E7%AB%99%E7%82%B9%E6%94%B6%E8%97%8F.html",
      "id": "https://www.cizai.io/%E7%AB%99%E7%82%B9%E6%94%B6%E8%97%8F.html",
      "summary": "站点收藏 白噪音 简介 网址 下雨声 http://www.rainymood.com/ 下雨声 http://mostlyrain.com/ 下雨声 https://www.calm.com/",
      "content_html": "<h1> 站点收藏</h1>\n<h2> 白噪音</h2>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">简介</th>\n<th style=\"text-align:left\">网址</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">下雨声</td>\n<td style=\"text-align:left\"><a href=\"http://www.rainymood.com/\" target=\"_blank\" rel=\"noopener noreferrer\">http://www.rainymood.com/</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">下雨声</td>\n<td style=\"text-align:left\"><a href=\"http://mostlyrain.com/\" target=\"_blank\" rel=\"noopener noreferrer\">http://mostlyrain.com/</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">下雨声</td>\n<td style=\"text-align:left\"><a href=\"https://www.calm.com/\" target=\"_blank\" rel=\"noopener noreferrer\">https://www.calm.com/</a></td>\n</tr>\n</tbody>\n</table>\n<h2> 独立博客列表</h2>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">简介</th>\n<th style=\"text-align:left\">网址</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">中文独立博客列表</td>\n<td style=\"text-align:left\"><a href=\"https://github.com/timqian/chinese-independent-blogs\" target=\"_blank\" rel=\"noopener noreferrer\">https://github.com/timqian/chinese-independent-blogs</a></td>\n</tr>\n<tr>\n<td style=\"text-align:left\">中国独立开发者项目列表</td>\n<td style=\"text-align:left\"><a href=\"https://github.com/1c7/chinese-independent-developer\" target=\"_blank\" rel=\"noopener noreferrer\">https://github.com/1c7/chinese-independent-developer</a></td>\n</tr>\n</tbody>\n</table>\n",
      "date_published": "2022-01-01T00:00:00.000Z",
      "date_modified": "2023-07-13T03:24:02.000Z",
      "authors": [],
      "tags": [
        "站点收藏"
      ]
    },
    {
      "title": "订阅说明",
      "url": "https://www.cizai.io/%E6%AF%8F%E6%97%A5%E6%82%A6%E8%AF%BB/%E8%AE%A2%E9%98%85%E8%AF%B4%E6%98%8E.html",
      "id": "https://www.cizai.io/%E6%AF%8F%E6%97%A5%E6%82%A6%E8%AF%BB/%E8%AE%A2%E9%98%85%E8%AF%B4%E6%98%8E.html",
      "summary": "订阅说明 实现原理 使用ttrss.py启动订阅服务接口，使用rsshub订阅插件，将Tiny Tiny RSS地址改为订阅接口地址，即可直接订阅网站，存入rss.csv。 定时执行write2csv.py，抓取网络上的订阅地址，存入rss.csv。 定时执行write2md.py，读取rss.csv，获取今日新增文章，写入md文档，提交git，自动显示在每日悦读。 参考代码： ttrss.py # coding: utf-8 \"\"\" @File : main.py @Time : 2023/05/05 18:46:35 @Author : lijc210@163.com @Desc : 模拟rsshub订阅插件，将Tiny Tiny RSS订阅到此地址 依赖模块 pip install fastapi,feedparser,uvicorn,requests 订阅请求地址 http://localhost:8000/public.php?op=bookmarklets--subscribe&amp;feed_url=https://rustcc.cn/rss \"\"\" import time import traceback import uvicorn from datetime import datetime, timedelta from typing import Union from fastapi import FastAPI from write2csv import write2csv app = FastAPI() order: str = time.strftime(\"%Y%m%d\", time.localtime(time.time())) date: str = time.strftime(\"%Y-%m-%d\", time.localtime(time.time())) tomorrow = (datetime.now() + timedelta(days=1)).strftime(\"%Y-%m-%d\") @app.get(\"/\") def read_root(): return {\"Hello\": \"World\"} @app.get(\"/items/{item_id}\") def read_item(item_id: int, q: Union[str, None] = None): return {\"item_id\": item_id, \"q\": q} @app.get(\"/public.php\") def public(op: str, feed_url: str): try: # print(op) # print(feed_url) success, msg = write2csv(feed_url) except Exception: print(traceback.format_exc()) success, msg = False, traceback.format_exc() return {\"success\": success, \"msg\": msg} if __name__ == \"__main__\": uvicorn.run(app=\"ttrss:app\", host=\"0.0.0.0\", port=8000, reload=True)",
      "content_html": "<h1> 订阅说明</h1>\n<h2> 实现原理</h2>\n<p>使用ttrss.py启动订阅服务接口，使用rsshub订阅插件，将Tiny Tiny RSS地址改为订阅接口地址，即可直接订阅网站，存入rss.csv。</p>\n<p>定时执行write2csv.py<span></span>，抓取网络上的订阅地址，存入rss.csv。</p>\n<p>定时执行write2md.py<span></span>，读取rss.csv，获取今日新增文章，写入md文档，提交git，自动显示在每日悦读。</p>\n<p>参考代码：</p>\n<h2> ttrss.py<span></span></h2>\n<div class=\"language-python line-numbers-mode\" data-ext=\"py\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><h2> write2md.py<span></span></h2>\n<div class=\"language-python line-numbers-mode\" data-ext=\"py\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><h2> write2csv.py<span></span></h2>\n<div class=\"language-python line-numbers-mode\" data-ext=\"py\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><h2> utils.py<span></span></h2>\n<div class=\"language-python line-numbers-mode\" data-ext=\"py\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div>",
      "date_published": "2023-06-15T00:00:00.000Z",
      "date_modified": "2023-07-13T10:52:36.000Z",
      "authors": [],
      "tags": [
        "每日悦读"
      ]
    },
    {
      "title": "debezium",
      "url": "https://www.cizai.io/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%BB%84%E4%BB%B6/debezium.html",
      "id": "https://www.cizai.io/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%BB%84%E4%BB%B6/debezium.html",
      "summary": "debezium 配置示例 为了方便起见，先编辑一个文件 mysql10.250.43.107-connector.json： { \"name\":\"mysql10_250_43_107-connector\", \"config\":{ \"connector.class\":\"io.debezium.connector.mysql.MySqlConnector\", \"database.hostname\":\"10.250.43.107\", \"database.port\":\"3306\", \"database.user\":\"root\", \"database.password\":\"qmPeZR38bffnG1KsRafb\", \"database.server.id\":\"2385205150\", \"database.server.name\":\"mysql10_250_43_107\", \"database.history.kafka.bootstrap.servers\":\"hwtest-data1:9092\", \"database.history.kafka.topic\":\"ods_fin_settlement_fin_cs_withdraw_kafka\", \"include.schema.changes\":\"true\", \"database.whitelist\":\"fin_settlement\", \"table.whitlelist\":\"fin_cs_withdraw\" } }",
      "content_html": "<h1> debezium</h1>\n<h2> 配置示例</h2>\n<p>为了方便起见，先编辑一个文件 mysql10.250.43.107-connector.json：</p>\n<div class=\"language-text line-numbers-mode\" data-ext=\"text\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><figure><img src=\"/assets/images/042CDA8A-7327-4E97-A135-ABA3D3BDAF94.png\" alt=\"\" tabindex=\"0\" loading=\"lazy\"><figcaption></figcaption></figure>\n<ul>\n<li>通过 Http Post 请求新增 connector 连接器实例：</li>\n</ul>\n<div class=\"language-text line-numbers-mode\" data-ext=\"text\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div></div></div><ul>\n<li>通过 Http Post 请求删除 connector 连接器实例：</li>\n</ul>\n<div class=\"language-text line-numbers-mode\" data-ext=\"text\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div></div></div><ul>\n<li>查看新增的连接器实例：</li>\n</ul>\n<div class=\"language-text line-numbers-mode\" data-ext=\"text\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div></div></div><ul>\n<li>查看连接器实例运行状态：</li>\n</ul>\n<div class=\"language-text line-numbers-mode\" data-ext=\"text\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div></div></div><h2> kafka connet  sql server从指定位置修复</h2>\n<p transaction_id:null,event_serial_no:2,commit_lsn:000f9f22:00001660:0003,change_lsn:000f9f22:00001220:0003=\"\">发送一条数据到connect-offsets<br>\nkey：<br>\n[\"sqlserver-cdc-source-AIS20201114225525\",{\"server\":\"AIS20201114225525\"}]<br>\nvalue：</p>\n<h2> snapshot.mode参数</h2>\n<ul>\n<li>\n<p>snapshot.mode<br>\nDebezium 支持五种模式:</p>\n<ol>\n<li>initial ：默认模式，在没有找到 offset 时(记录在 Kafka topic 的 connect-offsets 中，Kafka connect 框架维护)，做一次 snapshot——遍历有 SELECT 权限的表，收集列名，并且将每个表的所有行 select 出来写入 Kafka；</li>\n<li>when_needed: 跟 initial 类似，只是增加了一种情况，当记录的 offset 对应的 binlog 位置已经在 MySQL 服务端被 purge 了时，就重新做一个 snapshot。</li>\n<li>never: 不做 snapshot，也就是不拿所有表的列名，也不导出表数据到 Kafka，这个模式下，要求从最开头消费 binlog，以获取完整的 DDL 信息，MySQL 服务端的 binlog 不能被 purge 过，否则由于 DML binlog 里只有 database name、table name、column type 却没有 column name，Debezium 会报错 Encountered change event for table some_db.some_table whose schema isn't known to this connector；</li>\n<li>schema_only: 这种情况下会拿所有表的列名信息，但不会导出表数据到 Kafka，而且只从 Debezium 启动那刻起的 binlog 末尾开始消费，所以很适合不关心历史数据，只关心最近变更的场合。</li>\n<li>schema_only_recovery: 在 Debezium 的 schema_only 模式出错时，用这个模式恢复，一般不会用到。</li>\n</ol>\n</li>\n<li>\n<p>snapshot.locking.mode<br>\n设置为 “none” 是为了避免获取表的元信息时锁表（要么是 RELOAD 权限用 flush tables with read lock，要么是 LOCK TABLES 权限锁单个表），此时要求 Debezium 启动或者重启时没有 DDL 语句执行，否则 Debezium 抓取到的元信息跟并发执行的 DML 之间不一致。<br>\nsqlserver 只支持<br>\ninitial_only, initial, schema_only</p>\n</li>\n<li>\n<p>initial: Takes a snapshot of structure and data of captured tables; useful if topics should be populated with a complete representation of the data from the captured tables.全量+增量</p>\n</li>\n<li>\n<p>initial_only: Takes a snapshot of structure and data like initial but instead does not transition into streaming changes once the snapshot has completed.全量</p>\n</li>\n<li>\n<p>schema_only: Takes a snapshot of the structure of captured tables only; useful if only changes happening from now onwards should be propagated to topics.从启动消费</p>\n</li>\n</ul>\n<h3> 默认都是 initial</h3>\n<h3> mysql</h3>\n<p>Specifies the criteria for running a snapshot when the connector starts. Possible settings are:</p>\n<ul>\n<li>\n<p>initial - the connector runs a snapshot only when no offsets have been recorded for the logical server name.</p>\n</li>\n<li>\n<p>initial_only - the connector runs a snapshot only when no offsets have been recorded for the logical server name and then stops; i.e. it will not read change events from the binlog.</p>\n</li>\n<li>\n<p>when_needed - the connector runs a snapshot upon startup whenever it deems it necessary. That is, when no offsets are available, or when a previously recorded offset specifies a binlog location or GTID that is not available in the server.</p>\n</li>\n<li>\n<p>never - the connector never uses snapshots. Upon first startup with a logical server name, the connector reads from the beginning of the binlog. Configure this behavior with care. It is valid only when the binlog is guaranteed to contain the entire history of the database.</p>\n</li>\n<li>\n<p>schema_only - the connector runs a snapshot of the schemas and not the data. This setting is useful when you do not need the topics to contain a consistent snapshot of the data but need them to have only the changes since the connector was started.</p>\n</li>\n<li>\n<p>schema_only_recovery - this is a recovery setting for a connector that has already been capturing changes. When you restart the connector, this setting enables recovery of a corrupted or lost database schema history topic. You might set it periodically to \"clean up\" a database schema history topic that has been growing unexpectedly. Database schema history topics require infinite retention.</p>\n</li>\n</ul>\n",
      "image": "https://www.cizai.io/assets/images/042CDA8A-7327-4E97-A135-ABA3D3BDAF94.png",
      "date_published": "2022-01-01T00:00:00.000Z",
      "date_modified": "2023-07-13T06:58:32.000Z",
      "authors": [],
      "tags": [
        "组件"
      ]
    },
    {
      "title": "flink",
      "url": "https://www.cizai.io/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%BB%84%E4%BB%B6/flink.html",
      "id": "https://www.cizai.io/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%BB%84%E4%BB%B6/flink.html",
      "summary": "flink flink优化参数 table.exec.state.ttl=172800000 table.exec.mini-batch.enabled=true table.exec.mini-batch.allow-latency=10s table.exec.mini-batch.size=10000 table.exec.topn.cache-size=100000 table.optimizer.agg-phase-strategy=TWO_PHASE state.backend.rocksdb.block.cache-size=512m 'sink.buffer-flush.max-rows' = '500', 'sink.buffer-flush.interval' = '5s'",
      "content_html": "<h1> flink</h1>\n<h2> flink优化参数</h2>\n<div class=\"language-text line-numbers-mode\" data-ext=\"text\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><h2> SavePoint</h2>\n<ul>\n<li>SavePoint的路径需要在flink-conf.yaml中配置。</li>\n</ul>\n<blockquote>\n<p>state.savepoints.dir: hdfs://node01:8020/flink/state/savepoint</p>\n</blockquote>\n<ul>\n<li>两种savepoint方式:</li>\n</ul>\n<div class=\"language-text line-numbers-mode\" data-ext=\"text\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><ul>\n<li>以指定savepoint方式启动:</li>\n</ul>\n<blockquote>\n<p>flink run -s file:/home/hadoop/flink-1.12.0/rocksdb/savepoint-8ca381-918c260bd48f -c com.guoquan.flink_dwd_gqsh_order.dwdOrderHbase flink_dwd_gqsh_order-<br>\n1.0-SNAPSHOT.jar</p>\n</blockquote>\n<ul>\n<li>-n 忽略不可恢复的算子</li>\n</ul>\n<blockquote>\n<p>flink run -s file:/home/hadoop/flink-1.12.0/rocksdb/savepoint-8ca381-918c260bd48f -n -c com.guoquan.flink_dwd_gqsh_order.dwdOrderHbase flink_dwd_gqsh_order-<br>\n1.0-SNAPSHOT.jar</p>\n</blockquote>\n<p>从checkpoint恢复启动时，中断期间源中积累的数据并未立即计算，当新数据进来时会自动触发中断期间积累数据的计算。</p>\n<h2> Flink面试，看这篇就足够了</h2>\n<h2> 概述</h2>\n<p>2019 年是大数据实时计算领域最不平凡的一年，2019 年 1 月阿里巴巴 Blink （内部的 Flink 分支版本）开源，大数据领域一夜间从 Spark 独步天下走向了两强争霸的时代。Flink 因为其天然的流式计算特性以及强大的处理性能成为炙手可热的大数据处理框架。</p>\n<p>时至今日，Flink 已经发展到 1.9 版本，在大数据开发领域，面试中对于 Flink 的考察已经是大数据开发求职者必须面对的，本文结合自己作为面试官过程中的经验详细总结了近 50 个关于 Flink 的面试考察点。</p>\n<p>在本文中，分为以下几个部分：</p>\n<p>第一部分：Flink 中的核心概念和基础篇，包含了 Flink 的整体介绍、核心概念、算子等考察点。</p>\n<p>第二部分：Flink 进阶篇，包含了 Flink 中的数据传输、容错机制、序列化、数据热点、反压等实际生产环境中遇到的问题等考察点。</p>\n<p>第三部分：Flink 源码篇，包含了 Flink 的核心代码实现、Job 提交流程、数据交换、分布式快照机制、Flink SQL 的原理等考察点。</p>\n<h2> 第一部分：Flink 中的核心概念和基础考察</h2>\n<p>一、 简单介绍一下 Flink</p>\n<p>Flink 是一个框架和分布式处理引擎，用于对无界和有界数据流进行有状态计算。并且 Flink 提供了数据分布、容错机制以及资源管理等核心功能。</p>\n<p>Flink提供了诸多高抽象层的API以便用户编写分布式任务：</p>\n<ul>\n<li>\n<p>DataSet API， 对静态数据进行批处理操作，将静态数据抽象成分布式的数据集，用户可以方便地使用Flink提供的各种操作符对分布式数据集进行处理，支持Java、Scala和Python。</p>\n</li>\n<li>\n<p>DataStream API，对数据流进行流处理操作，将流式的数据抽象成分布式的数据流，用户可以方便地对分布式数据流进行各种操作，支持Java和Scala。</p>\n</li>\n<li>\n<p>Table API，对结构化数据进行查询操作，将结构化数据抽象成关系表，并通过类SQL的DSL对关系表进行各种查询操作，支持Java和Scala。</p>\n</li>\n</ul>\n<p>此外，Flink 还针对特定的应用领域提供了领域库，例如：Flink ML，Flink 的机器学习库，提供了机器学习Pipelines API并实现了多种机器学习算法。Gelly，Flink 的图计算库，提供了图计算的相关API及多种图计算算法实现。</p>\n<p>根据官网的介绍，Flink 的特性包含：</p>\n<div class=\"language-text line-numbers-mode\" data-ext=\"text\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div></div></div><p>二、 Flink 相比传统的 Spark Streaming 有什么区别?</p>\n<p>这个问题是一个非常宏观的问题，因为两个框架的不同点非常之多。但是在面试时有非常重要的一点一定要回答出来：Flink 是标准的实时处理引擎，基于事件驱动。而 Spark Streaming 是微批（Micro-Batch）的模型。</p>\n<p>下面我们就分几个方面介绍两个框架的主要区别：</p>\n<p>1. 架构模型</p>\n<p>Spark Streaming 在运行时的主要角色包括：Master、Worker、Driver、Executor，Flink 在运行时主要包含：Jobmanager、Taskmanager和Slot。</p>\n<p>2. 任务调度</p>\n<p>Spark Streaming 连续不断的生成微小的数据批次，构建有向无环图DAG，Spark Streaming 会依次创建 DStreamGraph、JobGenerator、JobScheduler。</p>\n<p>Flink 根据用户提交的代码生成 StreamGraph，经过优化生成 JobGraph，然后提交给 JobManager进行处理，JobManager 会根据 JobGraph 生成 ExecutionGraph，ExecutionGraph 是 Flink 调度最核心的数据结构，JobManager 根据 ExecutionGraph 对 Job 进行调度。</p>\n<p>3. 时间机制</p>\n<p>Spark Streaming 支持的时间机制有限，只支持处理时间。Flink 支持了流处理程序在时间上的三个定义：处理时间、事件时间、注入时间。同时也支持&nbsp;watermark&nbsp;机制来处理滞后数据。</p>\n<p>4. 容错机制</p>\n<p>对于 Spark Streaming 任务，我们可以设置 checkpoint，然后假如发生故障并重启，我们可以从上次 checkpoint 之处恢复，但是这个行为只能使得数据不丢失，可能会重复处理，不能做到恰好一次处理语义。</p>\n<p>Flink 则使用两阶段提交协议来解决这个问题。</p>\n<p>三、 Flink 的组件栈有哪些？</p>\n<p>根据 Flink 官网描述，Flink 是一个分层架构的系统，每一层所包含的组件都提供了特定的抽象，用来服务于上层组件。</p>\n<figure><img src=\"https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy9VZEs5QnlmTVQyT0tvRHA3T3VRUUUwZmNjUVFyTllYTWNReWZxN0h6ZnVIV1FCWEF0NlJabjlWejd6cEZoWU5kWnhkNFdrd2ljSmljdFdsQ0JKSGUxSk9RLzY0MA?x-oss-process=image/format,png\" alt=\"\" tabindex=\"0\" loading=\"lazy\"><figcaption></figcaption></figure>\n<p>图片来源于：<a href=\"https://flink.apache.org\" target=\"_blank\" rel=\"noopener noreferrer\">https://flink.apache.org</a></p>\n<p>自下而上，每一层分别代表：Deploy 层：该层主要涉及了Flink的部署模式，在上图中我们可以看出，Flink 支持包括local、Standalone、Cluster、Cloud等多种部署模式。Runtime 层：Runtime层提供了支持 Flink 计算的核心实现，比如：支持分布式 Stream 处理、JobGraph到ExecutionGraph的映射、调度等等，为上层API层提供基础服务。API层：API 层主要实现了面向流（Stream）处理和批（Batch）处理API，其中面向流处理对应DataStream API，面向批处理对应DataSet API，后续版本，Flink有计划将DataStream和DataSet API进行统一。Libraries层：该层称为Flink应用框架层，根据API层的划分，在API层之上构建的满足特定应用的实现计算框架，也分别对应于面向流处理和面向批处理两类。面向流处理支持：CEP（复杂事件处理）、基于SQL-like的操作（基于Table的关系操作）；面向批处理支持：FlinkML（机器学习库）、Gelly（图处理）。</p>\n<p>四、Flink 的运行必须依赖 Hadoop组件吗？</p>\n<p>Flink可以完全独立于Hadoop，在不依赖Hadoop组件下运行。但是做为大数据的基础设施，Hadoop体系是任何大数据框架都绕不过去的。Flink可以集成众多Hadooop 组件，例如Yarn、Hbase、HDFS等等。例如，Flink可以和Yarn集成做资源调度，也可以读写HDFS，或者利用HDFS做检查点。</p>\n<p>五、你们的Flink集群规模多大？</p>\n<p>大家注意，这个问题看起来是问你实际应用中的Flink集群规模，其实还隐藏着另一个问题：Flink可以支持多少节点的集群规模？</p>\n<p>在回答这个问题时候，可以将自己生产环节中的集群规模、节点、内存情况说明，同时说明部署模式（一般是Flink on Yarn），除此之外，用户也可以同时在小集群（少于5个节点）和拥有 TB 级别状态的上千个节点上运行 Flink 任务。</p>\n<p>六、Flink的基础编程模型了解吗？</p>\n<figure><img src=\"https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy9VZEs5QnlmTVQyT0tvRHA3T3VRUUUwZmNjUVFyTllYTVN2OUx6eUZ3aWFoUnhWUzBVNDlpYUg2dkVodk53OEhPbGJLNGliVzc4N3BUaEdNaWN5ZFEyYXR5cEEvNjQw?x-oss-process=image/format,png\" alt=\"\" tabindex=\"0\" loading=\"lazy\"><figcaption></figcaption></figure>\n<p>上图是来自Flink官网的运行流程图。通过上图我们可以得知，Flink 程序的基本构建是数据输入来自一个 Source，Source 代表数据的输入端，经过 Transformation 进行转换，然后在一个或者多个Sink接收器中结束。数据流（stream）就是一组永远不会停止的数据记录流，而转换（transformation）是将一个或多个流作为输入，并生成一个或多个输出流的操作。执行时，Flink程序映射到 streaming dataflows，由流（streams）和转换操作（transformation operators）组成。</p>\n<p>七、Flink集群有哪些角色？各自有什么作用？</p>\n<figure><img src=\"https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X2pwZy9VZEs5QnlmTVQyT0tvRHA3T3VRUUUwZmNjUVFyTllYTTVkRm5lRlpDQlhPUlJTaWFpY2w0dlBuVlJINTdpYU92Qmpyd0hxOFFpY1haNW9SY1VqcG9hMk00V0EvNjQw?x-oss-process=image/format,png\" alt=\"\" tabindex=\"0\" loading=\"lazy\"><figcaption></figcaption></figure>\n<p>Flink 程序在运行时主要有 TaskManager，JobManager，Client三种角色。其中JobManager扮演着集群中的管理者Master的角色，它是整个集群的协调者，负责接收Flink Job，协调检查点，Failover 故障恢复等，同时管理Flink集群中从节点TaskManager。</p>\n<p>TaskManager是实际负责执行计算的Worker，在其上执行Flink Job的一组Task，每个TaskManager负责管理其所在节点上的资源信息，如内存、磁盘、网络，在启动的时候将资源的状态向JobManager汇报。</p>\n<p>Client是Flink程序提交的客户端，当用户提交一个Flink程序时，会首先创建一个Client，该Client首先会对用户提交的Flink程序进行预处理，并提交到Flink集群中处理，所以Client需要从用户提交的Flink程序配置中获取JobManager的地址，并建立到JobManager的连接，将Flink Job提交给JobManager。</p>\n<p>八、说说 Flink 资源管理中 Task Slot 的概念</p>\n<figure><img src=\"https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X2pwZy9VZEs5QnlmTVQyT0tvRHA3T3VRUUUwZmNjUVFyTllYTVBSbEZ5Z0dXdUdvMHJjaWJBZk5PWVNlNE5HVW1sU3FpY3R4OVp1SmlhM0NBTnhpY3VTU2ljcHl6ZEtBLzY0MA?x-oss-process=image/format,png\" alt=\"\" tabindex=\"0\" loading=\"lazy\"><figcaption></figcaption></figure>\n<p>在Flink架构角色中我们提到，TaskManager是实际负责执行计算的Worker，TaskManager 是一个 JVM 进程，并会以独立的线程来执行一个task或多个subtask。为了控制一个 TaskManager 能接受多少个 task，Flink 提出了 Task Slot 的概念。</p>\n<p>简单的说，TaskManager会将自己节点上管理的资源分为不同的Slot：固定大小的资源子集。这样就避免了不同Job的Task互相竞争内存资源，但是需要主要的是，Slot只会做内存的隔离。没有做CPU的隔离。</p>\n<p>九、说说 Flink 的常用算子？</p>\n<p>Flink 最常用的常用算子包括：Map：DataStream → DataStream，输入一个参数产生一个参数，map的功能是对输入的参数进行转换操作。Filter：过滤掉指定条件的数据。KeyBy：按照指定的key进行分组。Reduce：用来进行结果汇总合并。Window：窗口函数，根据某些特性将每个key的数据进行分组（例如：在5s内到达的数据）</p>\n<p>十、说说你知道的Flink分区策略？</p>\n<p>什么要搞懂什么是分区策略。分区策略是用来决定数据如何发送至下游。目前 Flink 支持了8中分区策略的实现。</p>\n<figure><img src=\"https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X2pwZy9VZEs5QnlmTVQyT0tvRHA3T3VRUUUwZmNjUVFyTllYTTVYUkgyeXB4QUFHa3d0MWlhSktlbHBZVkM5anEyc01HYUZGaWFNSDBYODdLWmNiNkgzcWtYQlpBLzY0MA?x-oss-process=image/format,png\" alt=\"\" tabindex=\"0\" loading=\"lazy\"><figcaption></figcaption></figure>\n<p>上图是整个Flink实现的分区策略继承图：</p>\n<p>GlobalPartitioner&nbsp;数据会被分发到下游算子的第一个实例中进行处理。</p>\n<p>ShufflePartitioner&nbsp;数据会被随机分发到下游算子的每一个实例中进行处理。</p>\n<p>RebalancePartitioner&nbsp;数据会被循环发送到下游的每一个实例中进行处理。</p>\n<p>RescalePartitioner&nbsp;这种分区器会根据上下游算子的并行度，循环的方式输出到下游算子的每个实例。这里有点难以理解，假设上游并行度为2，编号为A和B。下游并行度为4，编号为1，2，3，4。那么A则把数据循环发送给1和2，B则把数据循环发送给3和4。假设上游并行度为4，编号为A，B，C，D。下游并行度为2，编号为1，2。那么A和B则把数据发送给1，C和D则把数据发送给2。</p>\n<p>BroadcastPartitioner&nbsp;广播分区会将上游数据输出到下游算子的每个实例中。适合于大数据集和小数据集做Jion的场景。</p>\n<p>ForwardPartitioner&nbsp;ForwardPartitioner 用于将记录输出到下游本地的算子实例。它要求上下游算子并行度一样。简单的说，ForwardPartitioner用来做数据的控制台打印。</p>\n<p>KeyGroupStreamPartitioner&nbsp;Hash分区器。会将数据按 Key 的 Hash 值输出到下游算子实例中。</p>\n<p>CustomPartitionerWrapper&nbsp;用户自定义分区器。需要用户自己实现Partitioner接口，来定义自己的分区逻辑。例如：</p>\n<div class=\"language-text line-numbers-mode\" data-ext=\"text\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div></div></div><p>十一、Flink的并行度了解吗？Flink的并行度设置是怎样的？</p>\n<p>Flink中的任务被分为多个并行任务来执行，其中每个并行的实例处理一部分数据。这些并行实例的数量被称为并行度。</p>\n<p>我们在实际生产环境中可以从四个不同层面设置并行度：</p>\n<ul>\n<li>\n<p>操作算子层面(Operator Level)</p>\n</li>\n<li>\n<p>执行环境层面(Execution Environment Level)</p>\n</li>\n<li>\n<p>客户端层面(Client Level)</p>\n</li>\n<li>\n<p>系统层面(System Level)</p>\n</li>\n</ul>\n<p>需要注意的优先级：算子层面&gt;环境层面&gt;客户端层面&gt;系统层面。</p>\n<p>十二、Flink的Slot和parallelism有什么区别？</p>\n<p>官网上十分经典的图：</p>\n<figure><img src=\"https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X2pwZy9VZEs5QnlmTVQyT0tvRHA3T3VRUUUwZmNjUVFyTllYTVZnU0hMTWE4cEdLY3BkTExRcHlYbHdRRlowQ1g0Y2ZzSFV1dE9OdDJEc3F5VGRMcm42YUw5US82NDA?x-oss-process=image/format,png\" alt=\"\" tabindex=\"0\" loading=\"lazy\"><figcaption></figcaption></figure>\n<p>slot是指taskmanager的并发执行能力，假设我们将 taskmanager.numberOfTaskSlots 配置为3 那么每一个 taskmanager 中分配3个 TaskSlot, 3个 taskmanager 一共有9个TaskSlot。</p>\n<figure><img src=\"https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X2pwZy9VZEs5QnlmTVQyT0tvRHA3T3VRUUUwZmNjUVFyTllYTVZocWpkcExTSlRpYTVxUXA4ZHpBYjVLWlRCTUttTEtDbkpmdWliTmthaWNNSnFZVGVIcXJiMU5ldy82NDA?x-oss-process=image/format,png\" alt=\"\" tabindex=\"0\" loading=\"lazy\"><figcaption></figcaption></figure>\n<p>parallelism是指taskmanager实际使用的并发能力。假设我们把 parallelism.default 设置为1，那么9个 TaskSlot 只能用1个，有8个空闲。</p>\n<p>十三、Flink有没有重启策略？说说有哪几种？</p>\n<p>Flink 实现了多种重启策略。</p>\n<ul>\n<li>\n<p>固定延迟重启策略（Fixed Delay Restart Strategy）</p>\n</li>\n<li>\n<p>故障率重启策略（Failure Rate Restart Strategy）</p>\n</li>\n<li>\n<p>没有重启策略（No Restart Strategy）</p>\n</li>\n<li>\n<p>Fallback重启策略（Fallback Restart Strategy）</p>\n</li>\n</ul>\n<p>十四、用过Flink中的分布式缓存吗？如何使用？</p>\n<p>Flink实现的分布式缓存和Hadoop有异曲同工之妙。目的是在本地读取文件，并把他放在 taskmanager 节点中，防止task重复拉取。</p>\n<div class=\"language-text line-numbers-mode\" data-ext=\"text\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div></div></div><p>十五、说说Flink中的广播变量，使用时需要注意什么？</p>\n<p>我们知道Flink是并行的，计算过程可能不在一个 Slot 中进行，那么有一种情况即：当我们需要访问同一份数据。那么Flink中的广播变量就是为了解决这种情况。</p>\n<p>我们可以把广播变量理解为是一个公共的共享变量，我们可以把一个dataset 数据集广播出去，然后不同的task在节点上都能够获取到，这个数据在每个节点上只会存在一份。</p>\n<p>十六、说说Flink中的窗口？</p>\n<p>来一张官网经典的图：</p>\n<figure><img src=\"https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X2pwZy9VZEs5QnlmTVQyT0tvRHA3T3VRUUUwZmNjUVFyTllYTXlKVlJKUGlhWEJPZTlWclBSWllxU0tuYjdFb1BrRlo2bGpCNVpKZjdJNHY1QTZUdmVXTkREd0EvNjQw?x-oss-process=image/format,png\" alt=\"\" tabindex=\"0\" loading=\"lazy\"><figcaption></figcaption></figure>\n<p>Flink 支持两种划分窗口的方式，按照time和count。如果根据时间划分窗口，那么它就是一个time-window 如果根据数据划分窗口，那么它就是一个count-window。</p>\n<p>flink支持窗口的两个重要属性（size和interval）</p>\n<p>如果size=interval,那么就会形成tumbling-window(无重叠数据) 如果size&gt;interval,那么就会形成sliding-window(有重叠数据) 如果size&lt; interval, 那么这种窗口将会丢失数据。比如每5秒钟，统计过去3秒的通过路口汽车的数据，将会漏掉2秒钟的数据。</p>\n<p>通过组合可以得出四种基本窗口：</p>\n<ul>\n<li>\n<p>time-tumbling-window 无重叠数据的时间窗口，设置方式举例：timeWindow(Time.seconds(5))</p>\n</li>\n<li>\n<p>time-sliding-window 有重叠数据的时间窗口，设置方式举例：timeWindow(Time.seconds(5), Time.seconds(3))</p>\n</li>\n<li>\n<p>count-tumbling-window无重叠数据的数量窗口，设置方式举例：countWindow(5)</p>\n</li>\n<li>\n<p>count-sliding-window 有重叠数据的数量窗口，设置方式举例：countWindow(5,3)</p>\n</li>\n</ul>\n<p>十七、说说Flink中的状态存储？</p>\n<p>Flink在做计算的过程中经常需要存储中间状态，来避免数据丢失和状态恢复。选择的状态存储策略不同，会影响状态持久化如何和 checkpoint 交互。</p>\n<p>Flink提供了三种状态存储方式：MemoryStateBackend、FsStateBackend、RocksDBStateBackend。</p>\n<p>十八、Flink 中的时间有哪几类</p>\n<p>Flink 中的时间和其他流式计算系统的时间一样分为三类：事件时间，摄入时间，处理时间三种。</p>\n<p>如果以 EventTime 为基准来定义时间窗口将形成EventTimeWindow,要求消息本身就应该携带EventTime。如果以 IngesingtTime 为基准来定义时间窗口将形成 IngestingTimeWindow,以 source 的systemTime为准。如果以 ProcessingTime 基准来定义时间窗口将形成 ProcessingTimeWindow，以 operator 的systemTime 为准。</p>\n<p>十九、Flink 中水印是什么概念，起到什么作用？</p>\n<p>Watermark 是 Apache Flink 为了处理 EventTime 窗口计算提出的一种机制, 本质上是一种时间戳。一般来讲Watermark经常和Window一起被用来处理乱序事件。</p>\n<p>二十、Flink Table &amp; SQL 熟悉吗？TableEnvironment这个类有什么作用</p>\n<p>TableEnvironment是Table API和SQL集成的核心概念。</p>\n<p>这个类主要用来：</p>\n<ul>\n<li>\n<p>在内部catalog中注册表</p>\n</li>\n<li>\n<p>注册外部catalog</p>\n</li>\n<li>\n<p>执行SQL查询</p>\n</li>\n<li>\n<p>注册用户定义（标量，表或聚合）函数</p>\n</li>\n<li>\n<p>将DataStream或DataSet转换为表</p>\n</li>\n<li>\n<p>持有对ExecutionEnvironment或StreamExecutionEnvironment的引用</p>\n</li>\n</ul>\n<p>二十、Flink SQL的实现原理是什么？是如何实现 SQL 解析的呢？</p>\n<p>首先大家要知道 Flink 的SQL解析是基于Apache Calcite这个开源框架。</p>\n<figure><img src=\"https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X2pwZy9VZEs5QnlmTVQyT0tvRHA3T3VRUUUwZmNjUVFyTllYTUZFVTZ6eFFDVmIxQWpQQzJhT1BoOW53TFFocXZBbnRYRkE1ZUt1WlZaaWJKQmliZWZOQ1JqaWF2dy82NDA?x-oss-process=image/format,png\" alt=\"\" tabindex=\"0\" loading=\"lazy\"><figcaption></figcaption></figure>\n<p>基于此，一次完整的SQL解析过程如下：</p>\n<ul>\n<li>\n<p>用户使用对外提供Stream SQL的语法开发业务应用</p>\n</li>\n<li>\n<p>用calcite对StreamSQL进行语法检验，语法检验通过后，转换成calcite的逻辑树节点；最终形成calcite的逻辑计划</p>\n</li>\n<li>\n<p>采用Flink自定义的优化规则和calcite火山模型、启发式模型共同对逻辑树进行优化，生成最优的Flink物理计划</p>\n</li>\n<li>\n<p>对物理计划采用janino codegen生成代码，生成用低阶API DataStream 描述的流应用，提交到Flink平台执行</p>\n</li>\n</ul>\n<h2> 第二部分：Flink 面试进阶篇</h2>\n<p>一、Flink是如何支持批流一体的？</p>\n<figure><img src=\"https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X2pwZy9VZEs5QnlmTVQyT0tvRHA3T3VRUUUwZmNjUVFyTllYTXlBb0VCZFFqQUZMUElkT3pJbWliS0RTNTIxaWFrYlQ1bm9rVG0xZXR4T3cwWkxvZUFFMGQ1cFJnLzY0MA?x-oss-process=image/format,png\" alt=\"\" tabindex=\"0\" loading=\"lazy\"><figcaption></figcaption></figure>\n<p>本道面试题考察的其实就是一句话：Flink的开发者认为批处理是流处理的一种特殊情况。批处理是有限的流处理。Flink 使用一个引擎支持了DataSet API 和 DataStream API。</p>\n<p>二、Flink是如何做到高效的数据交换的？</p>\n<p>在一个Flink Job中，数据需要在不同的task中进行交换，整个数据交换是有 TaskManager 负责的，TaskManager 的网络组件首先从缓冲buffer中收集records，然后再发送。Records 并不是一个一个被发送的，二是积累一个批次再发送，batch 技术可以更加高效的利用网络资源。</p>\n<p>三、Flink是如何做容错的？</p>\n<p>Flink 实现容错主要靠强大的CheckPoint机制和State机制。Checkpoint 负责定时制作分布式快照、对程序中的状态进行备份；State 用来存储计算过程中的中间状态。</p>\n<p>四、Flink 分布式快照的原理是什么？</p>\n<p>Flink的分布式快照是根据Chandy-Lamport算法量身定做的。简单来说就是持续创建分布式数据流及其状态的一致快照。</p>\n<figure><img src=\"https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X2pwZy9VZEs5QnlmTVQyT0tvRHA3T3VRUUUwZmNjUVFyTllYTURsSHVGakdKMlRKUk1TS2FtY2lhcUVQRGtWcXUxbTM5a281NkNuVTNERXFpYmxYRGt6dUJueDZ3LzY0MA?x-oss-process=image/format,png\" alt=\"\" tabindex=\"0\" loading=\"lazy\"><figcaption></figcaption></figure>\n<p>核心思想是在 input source 端插入 barrier，控制 barrier 的同步来实现 snapshot 的备份和 exactly-once 语义。</p>\n<p>五、Flink 是如何保证Exactly-once语义的？</p>\n<p>Flink通过实现两阶段提交和状态保存来实现端到端的一致性语义。分为以下几个步骤：</p>\n<ul>\n<li>\n<p>开始事务（beginTransaction）创建一个临时文件夹，来写把数据写入到这个文件夹里面</p>\n</li>\n<li>\n<p>预提交（preCommit）将内存中缓存的数据写入文件并关闭</p>\n</li>\n<li>\n<p>正式提交（commit）将之前写完的临时文件放入目标目录下。这代表着最终的数据会有一些延迟</p>\n</li>\n<li>\n<p>丢弃（abort）丢弃临时文件</p>\n</li>\n</ul>\n<p>若失败发生在预提交成功后，正式提交前。可以根据状态来提交预提交的数据，也可删除预提交的数据。</p>\n<p>六、Flink 的 kafka 连接器有什么特别的地方？</p>\n<p>Flink源码中有一个独立的connector模块，所有的其他connector都依赖于此模块，Flink 在1.9版本发布的全新kafka连接器，摒弃了之前连接不同版本的kafka集群需要依赖不同版本的connector这种做法，只需要依赖一个connector即可。</p>\n<p>七、说说 Flink的内存管理是如何做的?</p>\n<p>Flink 并不是将大量对象存在堆上，而是将对象都序列化到一个预分配的内存块上。此外，Flink大量的使用了堆外内存。如果需要处理的数据超出了内存限制，则会将部分数据存储到硬盘上。Flink 为了直接操作二进制数据实现了自己的序列化框架。</p>\n<p>理论上Flink的内存管理分为三部分：</p>\n<ul>\n<li>\n<p>Network Buffers：这个是在TaskManager启动的时候分配的，这是一组用于缓存网络数据的内存，每个块是32K，默认分配2048个，可以通过“taskmanager.network.numberOfBuffers”修改</p>\n</li>\n<li>\n<p>Memory Manage pool：大量的Memory Segment块，用于运行时的算法（Sort/Join/Shuffle等），这部分启动的时候就会分配。下面这段代码，根据配置文件中的各种参数来计算内存的分配方法。（heap or off-heap，这个放到下节谈），内存的分配支持预分配和lazy load，默认懒加载的方式。</p>\n</li>\n<li>\n<p>User Code，这部分是除了Memory Manager之外的内存用于User code和TaskManager本身的数据结构。</p>\n</li>\n</ul>\n<p>八、说说 Flink的序列化如何做的?</p>\n<p>Java本身自带的序列化和反序列化的功能，但是辅助信息占用空间比较大，在序列化对象时记录了过多的类信息。</p>\n<p>Apache Flink摒弃了Java原生的序列化方法，以独特的方式处理数据类型和序列化，包含自己的类型描述符，泛型类型提取和类型序列化框架。</p>\n<p>TypeInformation 是所有类型描述符的基类。它揭示了该类型的一些基本属性，并且可以生成序列化器。TypeInformation 支持以下几种类型：</p>\n<ul>\n<li>\n<p>BasicTypeInfo: 任意Java 基本类型或 String 类型</p>\n</li>\n<li>\n<p>BasicArrayTypeInfo: 任意Java基本类型数组或 String 数组</p>\n</li>\n<li>\n<p>WritableTypeInfo: 任意 Hadoop Writable 接口的实现类</p>\n</li>\n<li>\n<p>TupleTypeInfo: 任意的 Flink Tuple 类型(支持Tuple1 to Tuple25)。Flink tuples 是固定长度固定类型的Java Tuple实现</p>\n</li>\n<li>\n<p>CaseClassTypeInfo: 任意的 Scala CaseClass(包括 Scala tuples)</p>\n</li>\n<li>\n<p>PojoTypeInfo: 任意的 POJO (Java or Scala)，例如，Java对象的所有成员变量，要么是 public 修饰符定义，要么有 getter/setter 方法</p>\n</li>\n<li>\n<p>GenericTypeInfo: 任意无法匹配之前几种类型的类</p>\n</li>\n</ul>\n<p>针对前六种类型数据集，Flink皆可以自动生成对应的TypeSerializer，能非常高效地对数据集进行序列化和反序列化。</p>\n<p>九、 Flink中的Window出现了数据倾斜，你有什么解决办法？</p>\n<p>window产生数据倾斜指的是数据在不同的窗口内堆积的数据量相差过多。本质上产生这种情况的原因是数据源头发送的数据量速度不同导致的。出现这种情况一般通过两种方式来解决：</p>\n<ul>\n<li>\n<p>在数据进入窗口前做预聚合</p>\n</li>\n<li>\n<p>重新设计窗口聚合的key</p>\n</li>\n</ul>\n<p>十、 Flink中在使用聚合函数 GroupBy、Distinct、KeyBy 等函数时出现数据热点该如何解决？</p>\n<p>数据倾斜和数据热点是所有大数据框架绕不过去的问题。处理这类问题主要从3个方面入手：</p>\n<ul>\n<li>在业务上规避这类问题</li>\n</ul>\n<p>例如一个假设订单场景，北京和上海两个城市订单量增长几十倍，其余城市的数据量不变。这时候我们在进行聚合的时候，北京和上海就会出现数据堆积，我们可以单独数据北京和上海的数据。</p>\n<ul>\n<li>Key的设计上</li>\n</ul>\n<p>把热key进行拆分，比如上个例子中的北京和上海，可以把北京和上海按照地区进行拆分聚合。</p>\n<ul>\n<li>参数设置</li>\n</ul>\n<p>Flink 1.9.0 SQL(Blink Planner) 性能优化中一项重要的改进就是升级了微批模型，即 MiniBatch。原理是缓存一定的数据后再触发处理，以减少对State的访问，从而提升吞吐和减少数据的输出量。</p>\n<p>十一、Flink任务延迟高，想解决这个问题，你会如何入手？</p>\n<p>在Flink的后台任务管理中，我们可以看到Flink的哪个算子和task出现了反压。最主要的手段是资源调优和算子调优。资源调优即是对作业中的Operator的并发数（parallelism）、CPU（core）、堆内存（heap_memory）等参数进行调优。作业参数调优包括：并行度的设置，State的设置，checkpoint的设置。</p>\n<p>十二、Flink是如何处理反压的？</p>\n<p>Flink 内部是基于 producer-consumer 模型来进行消息传递的，Flink的反压设计也是基于这个模型。Flink 使用了高效有界的分布式阻塞队列，就像 Java 通用的阻塞队列（BlockingQueue）一样。下游消费者消费变慢，上游就会受到阻塞。</p>\n<p>十三、Flink的反压和Strom有哪些不同？</p>\n<p>Storm 是通过监控 Bolt 中的接收队列负载情况，如果超过高水位值就会将反压信息写到 Zookeeper ，Zookeeper 上的 watch 会通知该拓扑的所有 Worker 都进入反压状态，最后 Spout 停止发送 tuple。</p>\n<p>Flink中的反压使用了高效有界的分布式阻塞队列，下游消费变慢会导致发送端阻塞。</p>\n<p>二者最大的区别是Flink是逐级反压，而Storm是直接从源头降速。</p>\n<p>十四、 Operator Chains（算子链）这个概念你了解吗？</p>\n<p>为了更高效地分布式执行，Flink会尽可能地将operator的subtask链接（chain）在一起形成task。每个task在一个线程中执行。将operators链接成task是非常有效的优化：它能减少线程之间的切换，减少消息的序列化/反序列化，减少数据在缓冲区的交换，减少了延迟的同时提高整体的吞吐量。这就是我们所说的算子链。</p>\n<p>十五、 Flink什么情况下才会把Operator chain在一起形成算子链？</p>\n<p>两个operator chain在一起的的条件：</p>\n<ul>\n<li>\n<p>上下游的并行度一致</p>\n</li>\n<li>\n<p>下游节点的入度为1 （也就是说下游节点没有来自其他节点的输入）</p>\n</li>\n<li>\n<p>上下游节点都在同一个 slot group 中（下面会解释 slot group）</p>\n</li>\n<li>\n<p>下游节点的 chain 策略为 ALWAYS（可以与上下游链接，map、flatmap、filter等默认是ALWAYS）</p>\n</li>\n<li>\n<p>上游节点的 chain 策略为 ALWAYS 或 HEAD（只能与下游链接，不能与上游链接，Source默认是HEAD）</p>\n</li>\n<li>\n<p>两个节点间数据分区方式是 forward（参考理解数据流的分区）</p>\n</li>\n<li>\n<p>用户没有禁用 chain</p>\n</li>\n</ul>\n<p>十六、 说说Flink1.9的新特性？</p>\n<ul>\n<li>\n<p>支持hive读写，支持UDF</p>\n</li>\n<li>\n<p>Flink SQL TopN和GroupBy等优化</p>\n</li>\n<li>\n<p>Checkpoint跟savepoint针对实际业务场景做了优化</p>\n</li>\n<li>\n<p>Flink state查询</p>\n</li>\n</ul>\n<p>十七、消费kafka数据的时候，如何处理脏数据？</p>\n<p>可以在处理前加一个fliter算子，将不符合规则的数据过滤出去。</p>\n<h2> 第三部分：Flink 面试源码篇</h2>\n<p>一、Flink Job的提交流程&nbsp;用户提交的Flink Job会被转化成一个DAG任务运行，分别是：StreamGraph、JobGraph、ExecutionGraph，Flink中JobManager与TaskManager，JobManager与Client的交互是基于Akka工具包的，是通过消息驱动。整个Flink Job的提交还包含着ActorSystem的创建，JobManager的启动，TaskManager的启动和注册。</p>\n<p>二、Flink所谓\"三层图\"结构是哪几个\"图\"？</p>\n<p>一个Flink任务的DAG生成计算图大致经历以下三个过程：</p>\n<ul>\n<li>\n<p>StreamGraph 最接近代码所表达的逻辑层面的计算拓扑结构，按照用户代码的执行顺序向StreamExecutionEnvironment添加StreamTransformation构成流式图。</p>\n</li>\n<li>\n<p>JobGraph 从StreamGraph生成，将可以串联合并的节点进行合并，设置节点之间的边，安排资源共享slot槽位和放置相关联的节点，上传任务所需的文件，设置检查点配置等。相当于经过部分初始化和优化处理的任务图。</p>\n</li>\n<li>\n<p>ExecutionGraph 由JobGraph转换而来，包含了任务具体执行所需的内容，是最贴近底层实现的执行图。</p>\n</li>\n</ul>\n<p>三、JobManger在集群中扮演了什么角色？</p>\n<p>JobManager 负责整个 Flink 集群任务的调度以及资源的管理，从客户端中获取提交的应用，然后根据集群中 TaskManager 上 TaskSlot 的使用情况，为提交的应用分配相应的 TaskSlot 资源并命令 TaskManager 启动从客户端中获取的应用。</p>\n<p>JobManager 相当于整个集群的 Master 节点，且整个集群有且只有一个活跃的 JobManager ，负责整个集群的任务管理和资源管理。</p>\n<p>JobManager 和 TaskManager 之间通过 Actor System 进行通信，获取任务执行的情况并通过 Actor System 将应用的任务执行情况发送给客户端。</p>\n<p>同时在任务执行的过程中，Flink JobManager 会触发 Checkpoint 操作，每个 TaskManager 节点 收到 Checkpoint 触发指令后，完成 Checkpoint 操作，所有的 Checkpoint 协调过程都是在 Fink JobManager 中完成。</p>\n<p>当任务完成后，Flink 会将任务执行的信息反馈给客户端，并且释放掉 TaskManager 中的资源以供下一次提交任务使用。</p>\n<p>四、JobManger在集群启动过程中起到什么作用？</p>\n<p>JobManager的职责主要是接收Flink作业，调度Task，收集作业状态和管理TaskManager。它包含一个Actor，并且做如下操作：</p>\n<ul>\n<li>\n<p>RegisterTaskManager: 它由想要注册到JobManager的TaskManager发送。注册成功会通过AcknowledgeRegistration消息进行Ack。</p>\n</li>\n<li>\n<p>SubmitJob: 由提交作业到系统的Client发送。提交的信息是JobGraph形式的作业描述信息。</p>\n</li>\n<li>\n<p>CancelJob: 请求取消指定id的作业。成功会返回CancellationSuccess，否则返回CancellationFailure。</p>\n</li>\n<li>\n<p>UpdateTaskExecutionState: 由TaskManager发送，用来更新执行节点(ExecutionVertex)的状态。成功则返回true，否则返回false。</p>\n</li>\n<li>\n<p>RequestNextInputSplit: TaskManager上的Task请求下一个输入split，成功则返回NextInputSplit，否则返回null。</p>\n</li>\n<li>\n<p>JobStatusChanged：它意味着作业的状态(RUNNING, CANCELING, FINISHED,等)发生变化。这个消息由ExecutionGraph发送。</p>\n</li>\n</ul>\n<p>五、TaskManager在集群中扮演了什么角色？</p>\n<p>TaskManager 相当于整个集群的 Slave 节点，负责具体的任务执行和对应任务在每个节点上的资源申请和管理。</p>\n<p>客户端通过将编写好的 Flink 应用编译打包，提交到 JobManager，然后 JobManager 会根据已注册在 JobManager 中 TaskManager 的资源情况，将任务分配给有资源的 TaskManager节点，然后启动并运行任务。</p>\n<p>TaskManager 从 JobManager 接收需要部署的任务，然后使用 Slot 资源启动 Task，建立数据接入的网络连接，接收数据并开始数据处理。同时 TaskManager 之间的数据交互都是通过数据流的方式进行的。</p>\n<p>可以看出，Flink 的任务运行其实是采用多线程的方式，这和 MapReduce 多 JVM 进行的方式有很大的区别，Flink 能够极大提高 CPU 使用效率，在多个任务和 Task 之间通过 TaskSlot 方式共享系统资源，每个 TaskManager 中通过管理多个 TaskSlot 资源池进行对资源进行有效管理。</p>\n<p>六、TaskManager在集群启动过程中起到什么作用？</p>\n<p>TaskManager的启动流程较为简单：启动类：org.apache.flink.runtime.taskmanager.TaskManager 核心启动方法 ：selectNetworkInterfaceAndRunTaskManager 启动后直接向JobManager注册自己，注册完成后，进行部分模块的初始化。</p>\n<p>七、Flink 计算资源的调度是如何实现的？</p>\n<p>TaskManager中最细粒度的资源是Task slot，代表了一个固定大小的资源子集，每个TaskManager会将其所占有的资源平分给它的slot。</p>\n<p>通过调整 task slot 的数量，用户可以定义task之间是如何相互隔离的。每个 TaskManager 有一个slot，也就意味着每个task运行在独立的 JVM 中。每个 TaskManager 有多个slot的话，也就是说多个task运行在同一个JVM中。</p>\n<p>而在同一个JVM进程中的task，可以共享TCP连接（基于多路复用）和心跳消息，可以减少数据的网络传输，也能共享一些数据结构，一定程度上减少了每个task的消耗。每个slot可以接受单个task，也可以接受多个连续task组成的pipeline，如下图所示，FlatMap函数占用一个taskslot，而key Agg函数和sink函数共用一个taskslot：</p>\n<figure><img src=\"https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X2pwZy9VZEs5QnlmTVQyT0tvRHA3T3VRUUUwZmNjUVFyTllYTWdTZjBSQnRGRndFVEw0T3E1eHkzd0lkNGJhSkdDdE0waWJlNm9DeGdHQWVJRUJpYjVLaWI4Tzc0QS82NDA?x-oss-process=image/format,png\" alt=\"\" tabindex=\"0\" loading=\"lazy\"><figcaption></figcaption></figure>\n<p>八、简述Flink的数据抽象及数据交换过程？</p>\n<p>Flink 为了避免JVM的固有缺陷例如java对象存储密度低，FGC影响吞吐和响应等，实现了自主管理内存。MemorySegment就是Flink的内存抽象。默认情况下，一个MemorySegment可以被看做是一个32kb大的内存块的抽象。这块内存既可以是JVM里的一个byte[]，也可以是堆外内存（DirectByteBuffer）。</p>\n<p>在MemorySegment这个抽象之上，Flink在数据从operator内的数据对象在向TaskManager上转移，预备被发给下个节点的过程中，使用的抽象或者说内存对象是Buffer。</p>\n<p>对接从Java对象转为Buffer的中间对象是另一个抽象StreamRecord。</p>\n<p>九、Flink 中的分布式快照机制是如何实现的？</p>\n<p>Flink的容错机制的核心部分是制作分布式数据流和操作算子状态的一致性快照。这些快照充当一致性checkpoint，系统可以在发生故障时回滚。Flink用于制作这些快照的机制在“分布式数据流的轻量级异步快照”中进行了描述。它受到分布式快照的标准Chandy-Lamport算法的启发，专门针对Flink的执行模型而定制。</p>\n<figure><img src=\"https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy9VZEs5QnlmTVQyT0tvRHA3T3VRUUUwZmNjUVFyTllYTTBEY3l5UzdzdWNjVndIV0RMRURaYzZiRzIxeXJHMUk0a1NMV25SZWJWZHk3Zm9jNUlXVDd0QS82NDA?x-oss-process=image/format,png\" alt=\"\" tabindex=\"0\" loading=\"lazy\"><figcaption></figcaption></figure>\n<p>barriers在数据流源处被注入并行数据流中。快照n的barriers被插入的位置（我们称之为Sn）是快照所包含的数据在数据源中最大位置。例如，在Apache Kafka中，此位置将是分区中最后一条记录的偏移量。将该位置Sn报告给checkpoint协调器（Flink的JobManager）。</p>\n<p>然后barriers向下游流动。当一个中间操作算子从其所有输入流中收到快照n的barriers时，它会为快照n发出barriers进入其所有输出流中。一旦sink操作算子（流式DAG的末端）从其所有输入流接收到barriers n，它就向checkpoint协调器确认快照n完成。在所有sink确认快照后，意味快照着已完成。</p>\n<p>一旦完成快照n，job将永远不再向数据源请求Sn之前的记录，因为此时这些记录（及其后续记录）将已经通过整个数据流拓扑，也即是已经被处理结束。</p>\n<p>十、简单说说FlinkSQL的是如何实现的？</p>\n<p>Flink 将 SQL 校验、SQL 解析以及 SQL 优化交给了Apache Calcite。Calcite 在其他很多开源项目里也都应用到了，譬如 Apache Hive, Apache Drill, Apache Kylin, Cascading。Calcite 在新的架构中处于核心的地位，如下图所示。</p>\n<figure><img src=\"https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X2pwZy9VZEs5QnlmTVQyT0tvRHA3T3VRUUUwZmNjUVFyTllYTUZZMGRTVTJoQVVxNERpY2VxSWNPcEIxQmdpYnZQdzNzRTJCbkNVM3pXVkJ0cXdwc2pnZFAweHB3LzY0MA?x-oss-process=image/format,png\" alt=\"\" tabindex=\"0\" loading=\"lazy\"><figcaption></figcaption></figure>\n<p>构建抽象语法树的事情交给了 Calcite 去做。SQL query 会经过 Calcite 解析器转变成 SQL 节点树，通过验证后构建成 Calcite 的抽象语法树（也就是图中的 Logical Plan）。另一边，Table API 上的调用会构建成 Table API 的抽象语法树，并通过 Calcite 提供的 RelBuilder 转变成 Calcite 的抽象语法树。然后依次被转换成逻辑执行计划和物理执行计划。</p>\n<p>在提交任务后会分发到各个 TaskManager 中运行，在运行时会使用 Janino 编译器编译代码后运行。</p>\n<p>猜你喜欢</p>\n<p>1、<a href=\"https://blog.csdn.net/w397090770/article/details/103798230\" target=\"_blank\" rel=\"noopener noreferrer\">过往记忆大数据，2019年原创精选69篇</a></p>\n<p>2、<a href=\"http://mp.weixin.qq.com/s?__biz=MzA5MTc0NTMwNQ%3D%3D&amp;chksm=887ddea9bf0a57bf0b82a548cd9d23c203737e1eb196a6218c6e7abc3a70e0ba369192df31b4&amp;idx=1&amp;mid=2650719199&amp;scene=21&amp;sn=e74631efe48f80f18b497638969b254f#wechat_redirect\" target=\"_blank\" rel=\"noopener noreferrer\">Hadoop 2.7 不停服升级到 3.2 在滴滴的实践</a></p>\n<p>3、<a href=\"http://mp.weixin.qq.com/s?__biz=MzA5MTc0NTMwNQ%3D%3D&amp;chksm=887da293bf0a2b85469c388312c1cba191c5bccf8946db2808cd06a7aa9c56c7ae595f5db2b9&amp;idx=1&amp;mid=2650718181&amp;scene=21&amp;sn=69667c8316358ac66a8f5d5412429135#wechat_redirect\" target=\"_blank\" rel=\"noopener noreferrer\">32 道常见的 Kafka 面试题你都会吗？附答案</a></p>\n<p>4、<a href=\"https://blog.csdn.net/w397090770/article/details/103884239\" target=\"_blank\" rel=\"noopener noreferrer\">OPPO百万级高并发MongoDB集群性能数十倍提升优化实践（下）</a></p>\n<figure><img src=\"https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy8weUJEOWlhclgwbnZDaWI5RWt0QVVJeDdSQVppYUhmNUxuT1E5OHlnWWliMWZ4OFY1dDVXM0hNSjFJTXZmaWFUbEFtcFZPTTJRQXdvWHZkaWJsRmhsWjRNQ2E4QS82NDA?x-oss-process=image/format,png\" alt=\"\" tabindex=\"0\" loading=\"lazy\"><figcaption></figcaption></figure>\n<p>过往记忆大数据微信群，请添加微信：fangzhen0219,备注【进群】</p>\n",
      "image": "https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy9VZEs5QnlmTVQyT0tvRHA3T3VRUUUwZmNjUVFyTllYTWNReWZxN0h6ZnVIV1FCWEF0NlJabjlWejd6cEZoWU5kWnhkNFdrd2ljSmljdFdsQ0JKSGUxSk9RLzY0MA?x-oss-process=image/format,png",
      "date_published": "2022-01-01T00:00:00.000Z",
      "date_modified": "2023-07-13T06:58:32.000Z",
      "authors": [],
      "tags": [
        "组件"
      ]
    },
    {
      "title": "hadoop",
      "url": "https://www.cizai.io/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%BB%84%E4%BB%B6/hadoop.html",
      "id": "https://www.cizai.io/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%BB%84%E4%BB%B6/hadoop.html",
      "summary": "hadoop 常用命令 hadoop fs -ls / hadoop fs -ls /user hadoop fs -ls /kn1 hadoop fs -ls /user/lijicong/warehouse/kn1/kn1_tf_pictures_cut_title_dt -- 查看数据库所在路径 describe database database_name; --获取table的真实hdfs路径 desc formatted my_table; --获取partition的真实hdfs路径 desc formatted my_table(pt='20140804'); Hive查看表所有分区 show partitions t_test_order; hadoop查找文件 hadoop fs -lsr / | grep foods hdfs dfs -put /home/lijicong/tmp/ods_traf_toutiao_search_20161018.txt /user/lijicong/warehouse/ods/ods_traf_toutiao_search/dt=20161018 hdfs dfs -put /home/lijicong/tmp/ods_traf_toutiao_search_20161018.txt /user/lijicong/warehouse/ods/ods_traf_toutiao_search/dt=20161018 hdfs dfs -put /home/lijicong/tmp/ods_traf_toutiao_search_20161018.txt /user/lijicong/warehouse/ods/ods_traf_toutiao_search/dt=20161018/001 alter table test.ods_traf_toutiao_search drop if exists partition (dt='20161018'); alter table test.ods_traf_toutiao_search add partition (dt='20161018') location '/ods/ods_traf_toutiao_search/dt=20161018';",
      "content_html": "<h1> hadoop</h1>\n<h2> 常用命令</h2>\n<div class=\"language-text line-numbers-mode\" data-ext=\"text\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><h2> hdfs 清理28天前数据</h2>\n<div class=\"language-text line-numbers-mode\" data-ext=\"text\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><h2> yarn参数</h2>\n<div class=\"language-text line-numbers-mode\" data-ext=\"text\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div>",
      "date_published": "2022-01-01T00:00:00.000Z",
      "date_modified": "2023-07-13T06:58:32.000Z",
      "authors": [],
      "tags": [
        "组件"
      ]
    },
    {
      "title": "kafka",
      "url": "https://www.cizai.io/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%BB%84%E4%BB%B6/kafka.html",
      "id": "https://www.cizai.io/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%BB%84%E4%BB%B6/kafka.html",
      "summary": "kafka kafka connet sql server从指定位置修 发送一条数据到connect-offsets key： [\"sqlserver-cdc-source-AIS20201114225525\",{\"server\":\"AIS20201114225525\"}] value： {\"transaction_id\":null,\"event_serial_no\":2,\"commit_lsn\":\"000F9F22:00001660:0003\",\"change_lsn\":\"000F9F22:00001220:0003\"}",
      "content_html": "<h1> kafka</h1>\n<h2> kafka connet  sql server从指定位置修</h2>\n<h3> 发送一条数据到connect-offsets</h3>\n<div class=\"language-text line-numbers-mode\" data-ext=\"text\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><h3> 重启相关connector无用，要重启指定任务</h3>\n<ul>\n<li>/connectors/sqlserver-cdc-source-AIS20201114225525/tasks</li>\n<li>/connectors/sqlserver-cdc-source-AIS20201114225525/tasks/0/restart</li>\n</ul>\n<h2> kafka常用命令</h2>\n<p>1、启动kafka服务</p>\n<div class=\"language-text line-numbers-mode\" data-ext=\"text\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div></div></div><p>2、停止kafka服务</p>\n<div class=\"language-text line-numbers-mode\" data-ext=\"text\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div></div></div><p>3、查看所有的话题</p>\n<div class=\"language-text line-numbers-mode\" data-ext=\"text\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div></div></div><p>4、查看所有话题的详细信息</p>\n<div class=\"language-text line-numbers-mode\" data-ext=\"text\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div></div></div><p>5、列出指定话题的详细信息</p>\n<div class=\"language-text line-numbers-mode\" data-ext=\"text\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div></div></div><p>6、删除一个话题</p>\n<div class=\"language-text line-numbers-mode\" data-ext=\"text\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div></div></div><p>7、创建一个叫test的话题，有两个分区，每个分区3个副本</p>\n<div class=\"language-text line-numbers-mode\" data-ext=\"text\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div></div></div><p>8、测试kafka发送和接收消息（启动两个终端）</p>\n<div class=\"language-text line-numbers-mode\" data-ext=\"text\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div><div class=\"line-number\"></div></div></div><p>9、查看某个topic对应的消息数量</p>\n<div class=\"language-text line-numbers-mode\" data-ext=\"text\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div></div></div><p>10、显示所有消费者</p>\n<div class=\"language-text line-numbers-mode\" data-ext=\"text\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div></div></div><p>11、获取正在消费的topic（console-consumer-63307）的group的offset</p>\n<div class=\"language-text line-numbers-mode\" data-ext=\"text\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div></div></div><p>11、显示消费者</p>\n<div class=\"language-text line-numbers-mode\" data-ext=\"text\"><div class=\"line-numbers\" aria-hidden=\"true\"><div class=\"line-number\"></div></div></div>",
      "date_published": "2022-01-01T00:00:00.000Z",
      "date_modified": "2023-07-13T06:58:32.000Z",
      "authors": [],
      "tags": [
        "组件"
      ]
    },
    {
      "title": "spark",
      "url": "https://www.cizai.io/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%BB%84%E4%BB%B6/spark.html",
      "id": "https://www.cizai.io/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%BB%84%E4%BB%B6/spark.html",
      "summary": "spark spark面试问题 1、spark中的RDD是什么，有哪些特性 RDD（Resilient Distributed Dataset）叫做分布式数据集，是Spark中最基本的数据抽象，它代表一个不可变、可分区、里面的元素可并行计算的集合。 *Dataset：就是一个集合，用于存放数据的 *Distributed：分布式，可以并行在集群计算 *Resilient：表示弹性的 *弹性表示 *1、RDD中的数据可以存储在内存或者是磁盘 *2、RDD中的分区是可以改变的 五大特性： *A list of partitions 一个分区列表，RDD中的数据都存在一个分区列表里面 *A function for computing each split 作用在每一个分区中的函数 *A list of dependencies on other RDDs 一个RDD依赖于其他多个RDD，这个点很重要，RDD的容错机制就是依据这个特性而来的 *Optionally, a Partitioner for key-value RDDs (e.g. to say that the RDD ishash-partitioned) 可选的，针对于kv类型的RDD才具有这个特性，作用是决定了数据的来源以及数据处理后的去向 *Optionally, a list of preferred locations to compute each split on (e.g. blocklocations for an HDFS file) 可选项，数据本地性，数据位置最优",
      "content_html": "<h1> spark</h1>\n<h2> spark面试问题</h2>\n<h3> 1、spark中的RDD是什么，有哪些特性</h3>\n<ul>\n<li>\n\n</li>\n<li>\n\n</li>\n</ul>\n<h3> 2、概述一下spark中的常用算子区别（map、mapPartitions、foreach、foreachPartition）</h3>\n<ul>\n<li>\n<p>map：用于遍历RDD,将函数f应用于每一个元素，返回新的RDD(transformation算子)。</p>\n</li>\n<li>\n<p>foreach:用于遍历RDD,将函数f应用于每一个元素，无返回值(action算子)。</p>\n</li>\n<li>\n<p>mapPartitions:用于遍历操作RDD中的每一个分区，返回生成一个新的RDD（transformation算子）。</p>\n</li>\n<li>\n<p>foreachPartition: 用于遍历操作RDD中的每一个分区。无返回值(action算子)。</p>\n</li>\n<li>\n<p>总结：一般使用mapPartitions或者foreachPartition算子比map和foreach更加高效，推荐使用。</p>\n</li>\n</ul>\n<h3> 3、谈谈spark中的宽窄依赖</h3>\n<ul>\n<li>RDD和它依赖的父RDD（s）的关系有两种不同的类型，即窄依赖（narrow dependency）和宽依赖（wide dependency）。</li>\n<li>宽依赖：指的是多个子RDD的Partition会依赖同一个父RDD的Partition</li>\n<li>窄依赖：指的是每一个父RDD的Partition最多被子RDD的一个Partition使用。</li>\n</ul>\n<h3> 4、spark中如何划分stage</h3>\n<ul>\n<li>\n<p>1.Spark Application中可以因为不同的Action触发众多的job，一个Application中可以有很多的job，每个job是由一个或者多个Stage构成的，后面的Stage依赖于前面的Stage，也就是说只有前面依赖的Stage计算完毕后，后面的Stage才会运行。</p>\n</li>\n<li>\n<p>2.Stage划分的依据就是宽依赖，何时产生宽依赖，例如reduceByKey,groupByKey的算子，会导致宽依赖的产生。</p>\n</li>\n<li>\n<p>3.由Action（例如collect）导致了SparkContext.runJob的执行，最终导致了DAGScheduler中的submitJob的执行，其核心是通过发送一个case class JobSubmitted对象给eventProcessLoop。<br>\neventProcessLoop是DAGSchedulerEventProcessLoop的具体实例，而DAGSchedulerEventProcessLoop是eventLoop的子类，具体实现EventLoop的onReceive方法，onReceive方法转过来回调doOnReceive</p>\n</li>\n<li>\n<p>4.在doOnReceive中通过模式匹配的方法把执行路由到</p>\n</li>\n<li>\n<p>5.在handleJobSubmitted中首先创建finalStage，创建finalStage时候会建立父Stage的依赖链条</p>\n</li>\n<li>\n<p>总结：以来是从代码的逻辑层面上来展开说的，可以简单点说：写介绍什么是RDD中的宽窄依赖，然后在根据DAG有向无环图进行划分，从当前job的最后一个算子往前推，遇到宽依赖，那么当前在这个批次中的所有算子操作都划分成一个stage,然后继续按照这种方式在继续往前推，如在遇到宽依赖，又划分成一个stage,一直到最前面的一个算子。最后整个job会被划分成多个stage,而stage之间又存在依赖关系，后面的stage依赖于前面的stage。</p>\n</li>\n</ul>\n<h3> 5、spark-submit的时候如何引入外部jar包</h3>\n<ul>\n<li>在通过spark-submit提交任务时，可以通过添加配置参数来指定<br>\n*--driver-class-path 外部jar包<br>\n*--jars 外部jar包</li>\n</ul>\n<h3> 6、spark 如何防止内存溢出</h3>\n<ul>\n<li>\n<p>driver端的内存溢出<br>\n*可以增大driver的内存参数：spark.driver.memory(default 1g)<br>\n*这个参数用来设置Driver的内存。在Spark程序中，SparkContext，DAGScheduler都是运行在Driver端的。对应rdd的Stage切分也是在Driver端运行，如果用户自己写的程序有过多的步骤，切分出过多的Stage，这部分信息消耗的是Driver的内存，这个时候就需要调大Driver的内存。</p>\n</li>\n<li>\n<p>map过程产生大量对象导致内存溢出<br>\n*  这种溢出的原因是在单个map中产生了大量的对象导致的，例如：rdd.map(x=&gt;for(i &lt;- 1 to 10000) yield i.toString)，这个操作在rdd中，每个对象都产生了10000个对象，这肯定很容易产生内存溢出的问题。针对这种问题，在不增加内存的情况下，可以通过减少每个Task的大小，以便达到每个Task即使产生大量的对象Executor的内存也能够装得下。具体做法可以在会产生大量对象的map操作之前调用repartition方法，分区成更小的块传入map。例如：rdd.repartition(10000).map(x=&gt;for(i &lt;- 1 to 10000) yieldi.toString)。<br>\n面对这种问题注意，不能使用rdd.coalesce方法，这个方法只能减少分区，不能增加分区，不会有shuffle的过程。</p>\n</li>\n<li>\n<p>数据不平衡导致内存溢出<br>\n*  数据不平衡除了有可能导致内存溢出外，也有可能导致性能的问题，解决方法和上面说的类似，就是调用repartition重新分区。这里就不再累赘了。</p>\n</li>\n<li>\n<p>shuffle后内存溢出<br>\n*  shuffle内存溢出的情况可以说都是shuffle后，单个文件过大导致的。在Spark中，join，reduceByKey这一类型的过程，都会有shuffle的过程，在shuffle的使用，需要传入一个partitioner，大部分Spark中的shuffle操作，默认的partitioner都是HashPatitioner，默认值是父RDD中最大的分区数,这个参数通过spark.default.parallelism控制(在spark-sql中用spark.sql.shuffle.partitions)， spark.default.parallelism参数只对HashPartitioner有效，所以如果是别的Partitioner或者自己实现的Partitioner就不能使用spark.default.parallelism这个参数来控制shuffle的并发量了。如果是别的partitioner导致的shuffle内存溢出，就需要从partitioner的代码增加partitions的数量。</p>\n</li>\n<li>\n<p>standalone模式下资源分配不均匀导致内存溢出<br>\n*在standalone的模式下如果配置了--total-executor-cores和 --executor-memory 这两个参数，但是没有配置--executor-cores这个参数的话，就有可能导致，每个Executor的memory是一样的，但是cores的数量不同，那么在cores数量多的Executor中，由于能够同时执行多个Task，就容易导致内存溢出的情况。这种情况的解决方法就是同时配置--executor-cores或者spark.executor.cores参数，确保Executor资源分配均匀。</p>\n</li>\n<li>\n<p>使用rdd.persist(StorageLevel.MEMORY_AND_DISK_SER)代替rdd.cache()<br>\n*rdd.cache()和rdd.persist(Storage.MEMORY_ONLY)是等价的，在内存不足的时候rdd.cache()的数据会丢失，再次使用的时候会重算，而rdd.persist(StorageLevel.MEMORY_AND_DISK_SER)在内存不足的时候会存储在磁盘，避免重算，只是消耗点IO时间。</p>\n</li>\n</ul>\n<h3> 7、spark中cache和persist的区别</h3>\n<ul>\n<li>cache：缓存数据，默认是缓存在内存中，其本质还是调用persist</li>\n<li>persist:缓存数据，有丰富的数据缓存策略。数据可以保存在内存也可以保存在磁盘中，使用的时候指定对应的缓存级别就可以了。</li>\n</ul>\n<h3> 8、简要描述Spark分布式集群搭建的步骤</h3>\n<ul>\n<li>地球人都知道</li>\n<li>这里可以概述下如何搭建高可用的spark集群（HA）<br>\n*主要是引入了zookeeper</li>\n</ul>\n<h3> 9、spark中的数据倾斜的现象、原因、后果</h3>\n<ul>\n<li>(1)、数据倾斜的现象<br>\n*多数task执行速度较快,少数task执行时间非常长，或者等待很长时间后提示你内存不足，执行失败。</li>\n<li>(2)、数据倾斜的原因<br>\n*数据问题<br>\n*1、key本身分布不均衡（包括大量的key为空）<br>\n*2、key的设置不合理<br>\n*spark使用问题<br>\n*1、shuffle时的并发度不够<br>\n*2、计算方式有误</li>\n<li>(3)、数据倾斜的后果<br>\n*1、spark中的stage的执行时间受限于最后那个执行完成的task,因此运行缓慢的任务会拖垮整个程序的运行速度（分布式程序运行的速度是由最慢的那个task决定的）。<br>\n*2、过多的数据在同一个task中运行，将会把executor撑爆。</li>\n</ul>\n<h3> 10、如何解决spark中的数据倾斜问题</h3>\n<ul>\n<li>\n<p>发现数据倾斜的时候，不要急于提高executor的资源，修改参数或是修改程序，首先要检查数据本身，是否存在异常数据。<br>\n*1、数据问题造成的数据倾斜<br>\n*找出异常的key<br>\n*如果任务长时间卡在最后最后1个(几个)任务，首先要对key进行抽样分析，判断是哪些key造成的。<br>\n选取key，对数据进行抽样，统计出现的次数，根据出现次数大小排序取出前几个。<br>\n*比如:df.select(\"key\").sample(false,0.1).(k=&gt;(k,1)).reduceBykey(<em>+</em>).map(k=&gt;(k._2,k._1)).sortByKey(false).take(10)<br>\n*如果发现多数数据分布都较为平均，而个别数据比其他数据大上若干个数量级，则说明发生了数据倾斜。<br>\n*经过分析，倾斜的数据主要有以下三种情况:<br>\n*1、null（空值）或是一些无意义的信息()之类的,大多是这个原因引起。<br>\n*2、无效数据，大量重复的测试数据或是对结果影响不大的有效数据。<br>\n*3、有效数据，业务导致的正常数据分布。<br>\n*解决办法<br>\n*第1，2种情况，直接对数据进行过滤即可（因为该数据对当前业务不会产生影响）。<br>\n*第3种情况则需要进行一些特殊操作，常见的有以下几种做法<br>\n*(1) 隔离执行，将异常的key过滤出来单独处理，最后与正常数据的处理结果进行union操作。<br>\n*(2) 对key先添加随机值，进行操作后，去掉随机值，再进行一次操作。<br>\n*(3) 使用reduceByKey 代替 groupByKey(reduceByKey用于对每个key对应的多个value进行merge操作，最重要的是它能够在本地先进行merge操作，并且merge操作可以通过函数自定义.)<br>\n*(4) 使用map join。<br>\n*案例<br>\n*如果使用reduceByKey因为数据倾斜造成运行失败的问题。具体操作流程如下:<br>\n*(1) 将原始的 key 转化为 key + 随机值(例如Random.nextInt)<br>\n*(2) 对数据进行 reduceByKey(func)<br>\n*(3) 将 key + 随机值 转成 key<br>\n*(4) 再对数据进行 reduceByKey(func)<br>\n*案例操作流程分析：<br>\n*假设说有倾斜的Key，我们给所有的Key加上一个随机数，然后进行reduceByKey操作；此时同一个Key会有不同的随机数前缀，在进行reduceByKey操作的时候原来的一个非常大的倾斜的Key就分而治之变成若干个更小的Key，不过此时结果和原来不一样，怎么破？进行map操作，目的是把随机数前缀去掉，然后再次进行reduceByKey操作。（当然，如果你很无聊，可以再次做随机数前缀），这样我们就可以把原本倾斜的Key通过分而治之方案分散开来，最后又进行了全局聚合<br>\n*注意1: 如果此时依旧存在问题，建议筛选出倾斜的数据单独处理。最后将这份数据与正常的数据进行union即可。<br>\n*注意2: 单独处理异常数据时，可以配合使用Map Join解决。</p>\n\n</li>\n</ul>\n<h3> 11、flume整合sparkStreaming问题</h3>\n<ul>\n<li>\n<p>(1)、如何实现sparkStreaming读取flume中的数据<br>\n*可以这样说：<br>\n*前期经过技术调研，查看官网相关资料，发现sparkStreaming整合flume有2种模式，一种是拉模式，一种是推模式，然后在简单的聊聊这2种模式的特点，以及如何部署实现，需要做哪些事情，最后对比两种模式的特点，选择那种模式更好。<br>\n*推模式：Flume将数据Push推给Spark Streaming<br>\n*拉模式：Spark Streaming从flume 中Poll拉取数据</p>\n</li>\n<li>\n<p>(2)、在实际开发的时候是如何保证数据不丢失的<br>\n*可以这样说：<br>\n*flume那边采用的channel是将数据落地到磁盘中，保证数据源端安全性（可以在补充一下，flume在这里的channel可以设置为memory内存中，提高数据接收处理的效率，但是由于数据在内存中，安全机制保证不了，故选择channel为磁盘存储。整个流程运行有一点的延迟性）<br>\n*sparkStreaming通过拉模式整合的时候，使用了FlumeUtils这样一个类，该类是需要依赖一个额外的jar包（spark-streaming-flume_2.10）<br>\n*要想保证数据不丢失，数据的准确性，可以在构建StreamingConext的时候，利用StreamingContext.getOrCreate（checkpoint,creatingFunc: () =&gt; StreamingContext）来创建一个StreamingContext,使用StreamingContext.getOrCreate来创建StreamingContext对象，传入的第一个参数是checkpoint的存放目录，第二参数是生成StreamingContext对象的用户自定义函数。如果checkpoint的存放目录存在，则从这个目录中生成StreamingContext对象；如果不存在，才会调用第二个函数来生成新的StreamingContext对象。在creatingFunc函数中，除了生成一个新的StreamingContext操作，还需要完成各种操作，然后调用ssc.checkpoint(checkpointDirectory)来初始化checkpoint功能，最后再返回StreamingContext对象。<br>\n这样，在StreamingContext.getOrCreate之后，就可以直接调用start()函数来启动（或者是从中断点继续运行）流式应用了。如果有其他在启动或继续运行都要做的工作，可以在start()调用前执行。<br>\n*流失计算中使用checkpoint的作用：<br>\n*   保存元数据，包括流式应用的配置、流式没崩溃之前定义的各种操作、未完成所有操作的batch。元数据被存储到容忍失败的存储系统上，如HDFS。这种ckeckpoint主要针对driver失败后的修复。<br>\n*   保存流式数据，也是存储到容忍失败的存储系统上，如HDFS。这种ckeckpoint主要针对window operation、有状态的操作。无论是driver失败了，还是worker失败了，这种checkpoint都够快速恢复，而不需要将很长的历史数据都重新计算一遍（以便得到当前的状态）。<br>\n*设置流式数据checkpoint的周期<br>\n*对于一个需要做checkpoint的DStream结构，可以通过调用DStream.checkpoint(checkpointInterval)来设置ckeckpoint的周期，经验上一般将这个checkpoint周期设置成batch周期的5至10倍。<br>\n*使用write ahead logs功能<br>\n*这是一个可选功能，建议加上。这个功能将使得输入数据写入之前配置的checkpoint目录。这样有状态的数据可以从上一个checkpoint开始计算。开启的方法是把spark.streaming.receiver.writeAheadLogs.enable这个property设置为true。另外，由于输入RDD的默认StorageLevel是MEMORY_AND_DISK_2，即数据会在两台worker上做replication。实际上，Spark Streaming模式下，任何从网络输入数据的Receiver（如kafka、flume、socket）都会在两台机器上做数据备份。如果开启了write ahead logs的功能，建议把StorageLevel改成MEMORY_AND_DISK_SER。修改的方法是，在创建RDD时由参数传入。<br>\n*使用以上的checkpoint机制，确实可以保证数据0丢失。但是一个前提条件是，数据发送端必须要有缓存功能，这样才能保证在spark应用重启期间，数据发送端不会因为spark streaming服务不可用而把数据丢弃。而flume具备这种特性，同样kafka也具备。</p>\n</li>\n<li>\n<p>(3)Spark Streaming的数据可靠性<br>\n*有了checkpoint机制、write ahead log机制、Receiver缓存机器、可靠的Receiver（即数据接收并备份成功后会发送ack），可以保证无论是worker失效还是driver失效，都是数据0丢失。原因是：如果没有Receiver服务的worker失效了，RDD数据可以依赖血统来重新计算；如果Receiver所在worker失败了，由于Reciever是可靠的，并有write ahead log机制，则收到的数据可以保证不丢；如果driver失败了，可以从checkpoint中恢复数据重新构建。</p>\n</li>\n</ul>\n<h3> 12、kafka整合sparkStreaming问题</h3>\n<ul>\n<li>\n<p>(1)、如何实现sparkStreaming读取kafka中的数据<br>\n*可以这样说：在kafka0.10版本之前有二种方式与sparkStreaming整合，一种是基于receiver，一种是direct,然后分别阐述这2种方式分别是什么<br>\n*receiver：是采用了kafka高级api,利用receiver接收器来接受kafka topic中的数据，从kafka接收来的数据会存储在spark的executor中，之后spark streaming提交的job会处理这些数据，kafka中topic的偏移量是保存在zk中的。<br>\n*基本使用： val kafkaStream =KafkaUtils.createStream(streamingContext,<br>\n[ZK quorum], [consumer group id], [per-topic number of Kafka partitionsto consume])<br>\n*还有几个需要注意的点：<br>\n*在Receiver的方式中，Spark中的partition和kafka中的partition并不是相关的，所以如果我们加大每个topic的partition数量，仅仅是增加线程来处理由单一Receiver消费的主题。但是这并没有增加Spark在处理数据上的并行度.<br>\n*对于不同的Group和topic我们可以使用多个Receiver创建不同的Dstream来并行接收数据，之后可以利用union来统一成一个Dstream。<br>\n*在默认配置下，这种方式可能会因为底层的失败而丢失数据. 因为receiver一直在接收数据,在其已经通知zookeeper数据接收完成但是还没有处理的时候,executor突然挂掉(或是driver挂掉通知executor关闭),缓存在其中的数据就会丢失. 如果希望做到高可靠, 让数据零丢失,如果我们启用了Write Ahead Logs(spark.streaming.receiver.writeAheadLog.enable=true）该机制会同步地将接收到的Kafka数据写入分布式文件系统(比如HDFS)上的预写日志中. 所以, 即使底层节点出现了失败, 也可以使用预写日志中的数据进行恢复. 复制到文件系统如HDFS，那么storagelevel需要设置成 StorageLevel.MEMORY_AND_DISK_SER，也就是KafkaUtils.createStream(..., StorageLevel.MEMORY_AND_DISK_SER)<br>\n*direct:在spark1.3之后，引入了Direct方式。不同于Receiver的方式，Direct方式没有receiver这一层，其会周期性的获取Kafka中每个topic的每个partition中的最新offsets，之后根据设定的maxRatePerPartition来处理每个batch。（设置spark.streaming.kafka.maxRatePerPartition=10000。限制每秒钟从topic的每个partition最多消费的消息条数）。</p>\n</li>\n<li>\n<p>(2) 对比这2中方式的优缺点：<br>\n*采用receiver方式：这种方式可以保证数据不丢失，但是无法保证数据只被处理一次，WAL实现的是At-least-once语义（至少被处理一次），如果在写入到外部存储的数据还没有将offset更新到zookeeper就挂掉,这些数据将会被反复消费. 同时,降低了程序的吞吐量。<br>\n*采用direct方式:相比Receiver模式而言能够确保机制更加健壮. 区别于使用Receiver来被动接收数据, Direct模式会周期性地主动查询Kafka, 来获得每个topic+partition的最新的offset, 从而定义每个batch的offset的范围. 当处理数据的job启动时, 就会使用Kafka的简单consumer api来获取Kafka指定offset范围的数据。<br>\n*优点：<br>\n*1、简化并行读取<br>\n*如果要读取多个partition, 不需要创建多个输入DStream然后对它们进行union操作. Spark会创建跟Kafkapartition一样多的RDD partition, 并且会并行从Kafka中读取数据. 所以在Kafkapartition和RDD partition之间, 有一个一对一的映射关系.<br>\n*2、高性能<br>\n*如果要保证零数据丢失, 在基于receiver的方式中, 需要开启WAL机制. 这种方式其实效率低下, 因为数据实际上被复制了两份, Kafka自己本身就有高可靠的机制, 会对数据复制一份, 而这里又会复制一份到WAL中. 而基于direct的方式, 不依赖Receiver, 不需要开启WAL机制, 只要Kafka中作了数据的复制, 那么就可以通过Kafka的副本进行恢复.<br>\n*3、一次且仅一次的事务机制<br>\n*基于receiver的方式, 是使用Kafka的高阶API来在ZooKeeper中保存消费过的offset的. 这是消费Kafka数据的传统方式. 这种方式配合着WAL机制可以保证数据零丢失的高可靠性, 但是却无法保证数据被处理一次且仅一次, 可能会处理两次. 因为Spark和ZooKeeper之间可能是不同步的. 基于direct的方式, 使用kafka的简单api, Spark Streaming自己就负责追踪消费的offset, 并保存在checkpoint中. Spark自己一定是同步的, 因此可以保证数据是消费一次且仅消费一次。不过需要自己完成将offset写入zk的过程,在官方文档中都有相应介绍.<br>\n*简单代码实例：<br>\n*messages.foreachRDD(rdd=&gt;{<br>\nvalmessage = rdd.map(_._2)//对数据进行一些操作<br>\nmessage.map(method)//更新zk上的offset (自己实现)<br>\nupdateZKOffsets(rdd)<br>\n})<br>\n*sparkStreaming程序自己消费完成后，自己主动去更新zk上面的偏移量。也可以将zk中的偏移量保存在mysql或者redis数据库中，下次重启的时候，直接读取mysql或者redis中的偏移量，获取到上次消费的偏移量，接着读取数据。</p>\n</li>\n</ul>\n<h3> 13、利用scala语言实现排序</h3>\n<ul>\n<li>\n<p>(1)冒泡排序：<br>\n*package cn.itcast.sort<br>\n*//冒泡排序<br>\n*class BubbleSort {<br>\n*  def main(args: Array[String]): Unit = {<br>\n*   val list = List(3, 12, 43, 23, 7, 1, 2, 0)<br>\n*    println(sort(list))<br>\n*}<br>\n*//定义一个方法，传入的参数是要进行排序的List集合，输出的是排序后的List集合<br>\n*  def sort(list: List[Int]): List[Int] = listmatch {<br>\n*    case List() =&gt; List()<br>\n*    case head :: tail =&gt; compute(head,sort(tail))<br>\n*  }<br>\n*  def compute(data: Int, dataSet: List[Int]):List[Int] = dataSet match {<br>\n*    case List() =&gt; List(data)<br>\n*    case head :: tail =&gt; if (data &lt;=head) data :: dataSet else *  head ::compute(data, tail)<br>\n*  }<br>\n*}</p>\n</li>\n<li>\n<p>(2) 快读排序<br>\n*   packagecn.itcast.sort<br>\n*      //快速排序<br>\n*  object QuickSort {</p>\n<ul>\n<li>def main(args: Array[String]): Unit = {</li>\n<li>\n\n</li>\n<li>\n\n<ul>\n<li></li>\n<li>}</li>\n<li>//定义一个方法，传入的参数是要进行排序的List集合，输出的是排序后的List集合</li>\n<li>def quickSort(list: List[Int]): List[Int] ={<br>\n*//对输入参数list进行模式匹配<br>\n*list match {</li>\n</ul>\n</li>\n<li>//如果是空，返回nil</li>\n<li>case Nil =&gt; Nil</li>\n<li>case List() =&gt; List()</li>\n<li>//不为空从list中提取出首元素和剩余元素组成的列表分别到head和tail中</li>\n<li>case head :: tail =&gt;</li>\n<li>//对剩余元素列表调用partition方法，这个方法会将列表分为两部分。</li>\n<li>// 划分依据接受的参数，这个参数是一个函数(这里是(_ &lt; x))。</li>\n<li>// partition方法会对每个元素调用这个函数，根据返回的true,false分成两部分。</li>\n<li>// 这里'<em>&lt; x'是一个匿名函数(又称lambda),'</em>'关键字是函数输入参数的占位符，</li>\n<li>// 输入参数这里是列表中的每个元素。</li>\n<li>val (left, right) =tail.partition(_ &lt; head)</li>\n<li>//最后对划分好的两部分递归调用quickSort</li>\n<li>//其中head::quickSort(right)  这里::是List定义的一个方法，用于将两部分合成一个列表</li>\n<li>quickSort(left) ++ (head ::quickSort(right))<br>\n*     }<br>\n*  }<br>\n*}</li>\n</ul>\n</li>\n</ul>\n",
      "date_published": "2022-01-01T00:00:00.000Z",
      "date_modified": "2023-07-13T06:58:32.000Z",
      "authors": [],
      "tags": [
        "组件"
      ]
    }
  ]
}